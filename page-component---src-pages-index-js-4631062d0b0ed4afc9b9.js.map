{"version":3,"sources":["webpack:///page-component---src-pages-index-js-4631062d0b0ed4afc9b9.js","webpack:///./~/classnames/index.js","webpack:///./~/graphql-tag/lib/graphql-tag.umd.js","webpack:///./~/graphql/error/GraphQLError.js","webpack:///./~/graphql/error/formatError.js","webpack:///./~/graphql/error/index.js","webpack:///./~/graphql/error/locatedError.js","webpack:///./~/graphql/error/syntaxError.js","webpack:///./~/graphql/jsutils/invariant.js","webpack:///./~/graphql/language/kinds.js","webpack:///./~/graphql/language/lexer.js","webpack:///./~/graphql/language/location.js","webpack:///./~/graphql/language/parser.js","webpack:///./~/graphql/language/source.js","webpack:///./src/components/Header.js","webpack:///./src/pages/index.js"],"names":["webpackJsonp","./node_modules/classnames/index.js","module","exports","__webpack_require__","__WEBPACK_AMD_DEFINE_ARRAY__","__WEBPACK_AMD_DEFINE_RESULT__","classNames","classes","i","arguments","length","arg","argType","push","Array","isArray","apply","key","hasOwn","call","join","hasOwnProperty","undefined","./node_modules/graphql-tag/lib/graphql-tag.umd.js","global","factory","this","normalize","string","replace","trim","cacheKeyFromLoc","loc","source","body","substring","start","end","resetCaches","docCache","fragmentSourceMap","processFragments","ast","astFragmentMap","definitions","fragmentDefinition","kind","fragmentName","name","value","sourceKey","printFragmentWarnings","console","warn","disableFragmentWarnings","stripLoc","doc","removeLocAtThisLevel","docType","Object","prototype","toString","map","d","Error","startToken","endToken","valueType","keys","parseDocument","cacheKey","parsed","parse","gql","args","slice","literals","result","parser","default","./node_modules/graphql/error/GraphQLError.js","GraphQLError","message","nodes","positions","path","originalError","_source","node","_positions","filter","Boolean","_locations","_source2","pos","_location","getLocation","defineProperties","enumerable","writable","locations","stack","defineProperty","configurable","captureStackTrace","create","constructor","./node_modules/graphql/error/formatError.js","_interopRequireDefault","obj","__esModule","formatError","error","_invariant2","_invariant","./node_modules/graphql/error/index.js","_GraphQLError","get","_syntaxError","syntaxError","_locatedError","locatedError","_formatError","./node_modules/graphql/error/locatedError.js","String","./node_modules/graphql/error/syntaxError.js","position","description","location","line","locationOffset","columnOffset","getColumnOffset","column","highlightSourceAtLocation","lineOffset","contextLine","prevLineNum","lineNum","nextLineNum","padLen","lines","split","whitespace","lpad","len","str","./node_modules/graphql/jsutils/invariant.js","invariant","condition","./node_modules/graphql/language/kinds.js","NAME","DOCUMENT","OPERATION_DEFINITION","VARIABLE_DEFINITION","VARIABLE","SELECTION_SET","FIELD","ARGUMENT","FRAGMENT_SPREAD","INLINE_FRAGMENT","FRAGMENT_DEFINITION","INT","FLOAT","STRING","BOOLEAN","NULL","ENUM","LIST","OBJECT","OBJECT_FIELD","DIRECTIVE","NAMED_TYPE","LIST_TYPE","NON_NULL_TYPE","SCHEMA_DEFINITION","OPERATION_TYPE_DEFINITION","SCALAR_TYPE_DEFINITION","OBJECT_TYPE_DEFINITION","FIELD_DEFINITION","INPUT_VALUE_DEFINITION","INTERFACE_TYPE_DEFINITION","UNION_TYPE_DEFINITION","ENUM_TYPE_DEFINITION","ENUM_VALUE_DEFINITION","INPUT_OBJECT_TYPE_DEFINITION","TYPE_EXTENSION_DEFINITION","DIRECTIVE_DEFINITION","./node_modules/graphql/language/lexer.js","createLexer","options","startOfFileToken","Tok","SOF","lexer","lastToken","token","lineStart","advance","advanceLexer","EOF","next","readToken","COMMENT","getTokenDesc","prev","printCharCode","code","isNaN","JSON","stringify","fromCharCode","toUpperCase","bodyLength","positionAfterWhitespace","col","charCodeAt","_error","BANG","readComment","DOLLAR","PAREN_L","PAREN_R","SPREAD","COLON","EQUALS","AT","BRACKET_L","BRACKET_R","BRACE_L","PIPE","BRACE_R","readName","readNumber","readString","unexpectedCharacterMessage","startPosition","firstCode","isFloat","readDigits","chunkStart","charCode","uniCharCode","a","b","c","char2hex","TokenKind","toJSON","inspect","./node_modules/graphql/language/location.js","lineRegexp","match","exec","index","./node_modules/graphql/language/parser.js","sourceObj","Source","TypeError","_lexer","parseValue","expect","parseValueLiteral","parseType","type","parseTypeReference","parseName","_kinds","parseDefinition","skip","peek","parseOperationDefinition","parseFragmentDefinition","parseTypeSystemDefinition","unexpected","operation","variableDefinitions","directives","selectionSet","parseSelectionSet","parseOperationType","parseVariableDefinitions","parseDirectives","operationToken","many","parseVariableDefinition","variable","parseVariable","defaultValue","selections","parseSelection","parseFragment","parseField","nameOrAlias","alias","parseArguments","parseArgument","parseFragmentName","typeCondition","parseNamedType","expectKeyword","isConst","parseList","parseObject","parseConstValue","parseValueValue","item","values","any","fields","parseObjectField","parseDirective","parseSchemaDefinition","parseScalarTypeDefinition","parseObjectTypeDefinition","parseInterfaceTypeDefinition","parseUnionTypeDefinition","parseEnumTypeDefinition","parseInputObjectTypeDefinition","parseTypeExtensionDefinition","parseDirectiveDefinition","operationTypes","parseOperationTypeDefinition","interfaces","parseImplementsInterfaces","parseFieldDefinition","types","parseArgumentDefs","parseInputValueDef","parseUnionMembers","members","parseEnumValueDefinition","definition","parseDirectiveLocations","noLocation","Loc","atToken","openKind","parseFn","closeKind","./node_modules/graphql/language/source.js","_classCallCheck","instance","Constructor","./src/components/Header.js","_react","_react2","_propTypes","_propTypes2","_classnames","_classnames2","Header","_ref","title","byline","createElement","className","header__title--with-byline","propTypes","isRequired","defaultProps","./node_modules/babel-loader/lib/index.js?{\"plugins\":[\"/home/travis/build/HackBattles/hackbattl.es/node_modules/gatsby/dist/utils/babel-plugin-extract-graphql.js\",\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-plugin-add-module-exports/lib/index.js\",\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-plugin-add-module-exports/lib/index.js\",\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-plugin-transform-object-assign/lib/index.js\"],\"presets\":[\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-preset-env/lib/index.js\",\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-preset-stage-0/lib/index.js\",\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-preset-react/lib/index.js\"],\"cacheDirectory\":true}!./src/pages/index.js","pageQuery","_graphqlTag","_Header","_Header2","Index","data","site","siteMetadata","href","shape"],"mappings":"AAAAA,cAAc,qBAERC,qCACA,SAAUC,EAAQC,EAASC,GCHjC,GAAAC,GAAAC,GAOA,WACA,YAIA,SAAAC,KAGA,OAFAC,MAEAC,EAAA,EAAiBA,EAAAC,UAAAC,OAAsBF,IAAA,CACvC,GAAAG,GAAAF,UAAAD,EACA,IAAAG,EAAA,CAEA,GAAAC,SAAAD,EAEA,eAAAC,GAAA,WAAAA,EACAL,EAAAM,KAAAF,OACI,IAAAG,MAAAC,QAAAJ,GACJJ,EAAAM,KAAAP,EAAAU,MAAA,KAAAL,QACI,eAAAC,EACJ,OAAAK,KAAAN,GACAO,EAAAC,KAAAR,EAAAM,IAAAN,EAAAM,IACAV,EAAAM,KAAAI,IAMA,MAAAV,GAAAa,KAAA,KAxBA,GAAAF,MAAgBG,cA2BhB,oBAAApB,MAAAC,QACAD,EAAAC,QAAAI,GAGAF,KAAAC,EAAA,WACA,MAAAC,IACGU,MAAAd,EAAAE,KAAAkB,SAAAjB,IAAAJ,EAAAC,QAAAG,SDcGkB,oDACA,SAAUtB,EAAQC,EAASC,IE1DjC,SAAAqB,EAAAC,GACAA,KAGCC,KAAA,WAAqB,YAQtB,SAAAC,GAAAC,GACA,MAAAA,GAAAC,QAAA,eAAAC,OASA,QAAAC,GAAAC,GACA,MAAAL,GAAAK,EAAAC,OAAAC,KAAAC,UAAAH,EAAAI,MAAAJ,EAAAK,MAIA,QAAAC,KACAC,KACAC,KAOA,QAAAC,GAAAC,GAIA,OAHAC,MACAC,KAEApC,EAAA,EAAiBA,EAAAkC,EAAAE,YAAAlC,OAA4BF,IAAA,CAC7C,GAAAqC,GAAAH,EAAAE,YAAApC,EAEA,2BAAAqC,EAAAC,KAAA,CACA,GAAAC,GAAAF,EAAAG,KAAAC,MACAC,EAAAnB,EAAAc,EAAAb,IAGAQ,GAAAnB,eAAA0B,KAAAP,EAAAO,GAAAG,IAIAC,GACAC,QAAAC,KAAA,+BAAAN,EAAA,iMAKAP,EAAAO,GAAAG,IAAA,GAEOV,EAAAnB,eAAA0B,KACPP,EAAAO,MACAP,EAAAO,GAAAG,IAAA,GAGAP,EAAAO,KACAP,EAAAO,IAAA,EACAN,EAAA/B,KAAAgC,QAGAD,GAAA/B,KAAAgC,GAKA,MADAH,GAAAE,cACAF,EAGA,QAAAY,KACAH,GAAA,EAGA,QAAAI,GAAAC,EAAAC,GACA,GAAAC,GAAAC,OAAAC,UAAAC,SAAA1C,KAAAqC,EAEA,uBAAAE,EACA,MAAAF,GAAAM,IAAA,SAAAC,GACA,MAAAR,GAAAQ,EAAAN,IAIA,wBAAAC,EACA,SAAAM,OAAA,oBAKAP,IAAAD,EAAAxB,WACAwB,GAAAxB,IAIAwB,EAAAxB,YACAwB,GAAAxB,IAAAiC,iBACAT,GAAAxB,IAAAkC,SAGA,IACAjD,GACAgC,EACAkB,EAHAC,EAAAT,OAAAS,KAAAZ,EAKA,KAAAvC,IAAAmD,GACAA,EAAA/C,eAAAJ,KACAgC,EAAAO,EAAAY,EAAAnD,IACAkD,EAAAR,OAAAC,UAAAC,SAAA1C,KAAA8B,GAEA,oBAAAkB,GAAA,mBAAAA,IACAX,EAAAY,EAAAnD,IAAAsC,EAAAN,GAAA,IAKA,OAAAO,GAGA,QAAAa,GAAAb,GACA,GAAAc,GAAA3C,EAAA6B,EAEA,IAAAjB,EAAA+B,GACA,MAAA/B,GAAA+B,EAGA,IAAAC,GAAAC,EAAAhB,EACA,KAAAe,GAAA,aAAAA,EAAAzB,KACA,SAAAkB,OAAA,gCASA,OAJAO,GAAA9B,EAAA8B,GACAA,EAAAhB,EAAAgB,GAAA,GACAhC,EAAA+B,GAAAC,EAEAA,EAIA,QAAAE,KAQA,OAPAC,GAAA5D,MAAA8C,UAAAe,MAAAxD,KAAAV,WAEAmE,EAAAF,EAAA,GAGAG,EAAA,mBAAAD,IAAA,GAEApE,EAAA,EAAiBA,EAAAkE,EAAAhE,OAAiBF,IAElCqE,GADAH,EAAAlE,IAAAkE,EAAAlE,GAAAsC,MAAA,aAAA4B,EAAAlE,GAAAsC,KACA4B,EAAAlE,GAAAwB,IAAAC,OAAAC,KAEAwC,EAAAlE,GAGAqE,GAAAD,EAAApE,EAGA,OAAA6D,GAAAQ,GAhKA,GAAAC,GAAA3E,EAAA,6CAEAqE,EAAAM,EAAAN,MASAjC,KAGAC,KAeAW,GAAA,CAuIAsB,GAAAM,QAAAN,EACAA,EAAAnC,cACAmC,EAAAnB,0BAEArD,EAAAC,QAAAuE,KFoEMO,+CACA,SAAU/E,EAAQC,EAASC,GGnPjC,YAeA,SAAA8E,GACAC,EAAAC,EAAAlD,EAAAmD,EAAAC,EAAAC,GAEA,GAAAC,GAAAtD,CACA,KAAAsD,GAAAJ,KAAAzE,OAAA,GACA,GAAA8E,GAAAL,EAAA,EACAI,GAAAC,KAAAxD,KAAAwD,EAAAxD,IAAAC,OAGA,GAAAwD,GAAAL,GACAK,GAAAN,IACAM,EAAAN,EAAAO,OAAA,SAAAF,GACA,MAAAG,SAAAH,EAAAxD,OACK8B,IAAA,SAAA0B,GACL,MAAAA,GAAAxD,IAAAI,SAGAqD,GAAA,IAAAA,EAAA/E,SACA+E,EAAAnE,OAGA,IAAAsE,GAAA,OACAC,EAAAN,CACAM,IAAAJ,IACAG,EAAAH,EAAA3B,IAAA,SAAAgC,GACA,SAAAC,EAAAC,aAAAH,EAAAC,MAIAnC,OAAAsC,iBAAAvE,MACAwD,SACAjC,MAAAiC,EAIAgB,YAAA,EACAC,UAAA,GAEAC,WAGAnD,MAAA2C,GAAAtE,OAIA4E,YAAA,GAEAb,MAGApC,MAAAoC,GAAA/D,OAIA4E,YAAA,GAEAf,OACAlC,MAAAkC,GAAA7D,QAEAW,QACAgB,MAAAsC,GAAAjE,QAEA8D,WACAnC,MAAAwC,GAAAnE,QAEAgE,eACArC,MAAAqC,KAKAA,KAAAe,MACA1C,OAAA2C,eAAA5E,KAAA,SACAuB,MAAAqC,EAAAe,MACAF,UAAA,EACAI,cAAA,IAEGvC,MAAAwC,kBACHxC,MAAAwC,kBAAA9E,KAAAuD,GAEAtB,OAAA2C,eAAA5E,KAAA,SACAuB,MAAAe,QAAAqC,MACAF,UAAA,EACAI,cAAA,IAhGA5C,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAA+E,cAEA,IAAAc,GAAA5F,EAAA,8CAwGA8E,GAAArB,UAAAD,OAAA8C,OAAAzC,MAAAJ,WACA8C,aAAgBzD,MAAAgC,GAChBjC,MAASC,MAAA,mBH0PH0D,8CACA,SAAU1G,EAAQC,EAASC,GI5WjC,YAWA,SAAAyG,GAAAC,GAAsC,MAAAA,MAAAC,WAAAD,GAAuC9B,QAAA8B,GAM7E,QAAAE,GAAAC,GAEA,MADAA,GAAA,UAAAC,EAAAlC,SAAA,wCAEAG,QAAA8B,EAAA9B,QACAkB,UAAAY,EAAAZ,UACAf,KAAA2B,EAAA3B,MApBA1B,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAA6G,aAEA,IAAAG,GAAA/G,EAAA,+CAEA8G,EAAAL,EAAAM,IJyYMC,wCACA,SAAUlH,EAAQC,EAASC,GKnZjC,YAEAwD,QAAA2C,eAAApG,EAAA,cACA+C,OAAA,GAGA,IAAAmE,GAAAjH,EAAA,+CAEAwD,QAAA2C,eAAApG,EAAA,gBACAgG,YAAA,EACAmB,IAAA,WACA,MAAAD,GAAAnC,eAIA,IAAAqC,GAAAnH,EAAA,8CAEAwD,QAAA2C,eAAApG,EAAA,eACAgG,YAAA,EACAmB,IAAA,WACA,MAAAC,GAAAC,cAIA,IAAAC,GAAArH,EAAA,+CAEAwD,QAAA2C,eAAApG,EAAA,gBACAgG,YAAA,EACAmB,IAAA,WACA,MAAAG,GAAAC,eAIA,IAAAC,GAAAvH,EAAA,8CAEAwD,QAAA2C,eAAApG,EAAA,eACAgG,YAAA,EACAmB,IAAA,WACA,MAAAK,GAAAX,gBL2ZMY,+CACA,SAAU1H,EAAQC,EAASC,GMlcjC,YAcA,SAAAsH,GAAAnC,EAAAH,EAAAE,GAGA,GAAAC,KAAAD,KACA,MAAAC,EAGA,IAAAJ,GAAAI,IAAAJ,SAAA0C,OAAAtC,GAAA,4BACA,WAAA8B,GAAAnC,aAAAC,EAAAI,KAAAH,SAAAG,KAAArD,OAAAqD,KAAAF,UAAAC,EAAAC,GApBA3B,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAAuH,cAEA,IAAAL,GAAAjH,EAAA,iDNgeM0H,8CACA,SAAU5H,EAAQC,EAASC,GOxejC,YAyBA,SAAAoH,GAAAtF,EAAA6F,EAAAC,GACA,GAAAC,IAAA,EAAAjC,EAAAC,aAAA/D,EAAA6F,GACAG,EAAAD,EAAAC,KAAAhG,EAAAiG,eAAAD,KAAA,EACAE,EAAAC,EAAAnG,EAAA+F,GACAK,EAAAL,EAAAK,OAAAF,EACAnB,EAAA,GAAAI,GAAAnC,aAAA,gBAAAhD,EAAAe,KAAA,KAAAiF,EAAA,IAAAI,EAAA,KAAAN,EAAA,OAAAO,EAAArG,EAAA+F,GAAA1G,OAAAW,GAAA6F,GACA,OAAAd,GAOA,QAAAsB,GAAArG,EAAA+F,GACA,GAAAC,GAAAD,EAAAC,KACAM,EAAAtG,EAAAiG,eAAAD,KAAA,EACAE,EAAAC,EAAAnG,EAAA+F,GACAQ,EAAAP,EAAAM,EACAE,GAAAD,EAAA,GAAA3E,WACA6E,EAAAF,EAAA3E,WACA8E,GAAAH,EAAA,GAAA3E,WACA+E,EAAAD,EAAAjI,OACAmI,EAAA5G,EAAAC,KAAA4G,MAAA,eAEA,OADAD,GAAA,GAAAE,EAAA9G,EAAAiG,eAAAG,OAAA,GAAAQ,EAAA,IACAZ,GAAA,EAAAe,EAAAJ,EAAAH,GAAA,KAAAI,EAAAZ,EAAA,YAAAe,EAAAJ,EAAAF,GAAA,KAAAG,EAAAZ,EAAA,QAAAc,EAAA,EAAAH,EAAAZ,EAAAK,OAAA,EAAAF,GAAA,OAAAF,EAAAY,EAAAnI,OAAAsI,EAAAJ,EAAAD,GAAA,KAAAE,EAAAZ,GAAA,SAGA,QAAAG,GAAAnG,EAAA+F,GACA,WAAAA,EAAAC,KAAAhG,EAAAiG,eAAAG,OAAA,IAGA,QAAAU,GAAAE,GACA,MAAAnI,OAAAmI,EAAA,GAAA7H,KAAA,KAGA,QAAA4H,GAAAC,EAAAC,GACA,MAAAH,GAAAE,EAAAC,EAAAxI,QAAAwI,EA3DAvF,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAAqH,aAEA,IAAAxB,GAAA5F,EAAA,+CAEAiH,EAAAjH,EAAA,iDPmiBMgJ,8CACA,SAAUlJ,EAAQC,GQ7iBxB,YAgBA,SAAAkJ,GAAAC,EAAAnE,GACA,IAAAmE,EACA,SAAArF,OAAAkB,GAhBAvB,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAA6E,QAAAqE,GRkkBME,2CACA,SAAUrJ,EAAQC,GSxkBxB,YAEAyD,QAAA2C,eAAApG,EAAA,cACA+C,OAAA,GAcA/C,GAAAqJ,KAAA,OAIArJ,EAAAsJ,SAAA,WACAtJ,EAAAuJ,qBAAA,sBACAvJ,EAAAwJ,oBAAA,qBACAxJ,EAAAyJ,SAAA,WACAzJ,EAAA0J,cAAA,eACA1J,EAAA2J,MAAA,QACA3J,EAAA4J,SAAA,WAIA5J,EAAA6J,gBAAA,iBACA7J,EAAA8J,gBAAA,iBACA9J,EAAA+J,oBAAA,qBAIA/J,EAAAgK,IAAA,WACAhK,EAAAiK,MAAA,aACAjK,EAAAkK,OAAA,cACAlK,EAAAmK,QAAA,eACAnK,EAAAoK,KAAA,YACApK,EAAAqK,KAAA,YACArK,EAAAsK,KAAA,YACAtK,EAAAuK,OAAA,cACAvK,EAAAwK,aAAA,cAIAxK,EAAAyK,UAAA,YAIAzK,EAAA0K,WAAA,YACA1K,EAAA2K,UAAA,WACA3K,EAAA4K,cAAA,cAIA5K,EAAA6K,kBAAA,mBACA7K,EAAA8K,0BAAA,0BAIA9K,EAAA+K,uBAAA,uBACA/K,EAAAgL,uBAAA,uBACAhL,EAAAiL,iBAAA,kBACAjL,EAAAkL,uBAAA,uBACAlL,EAAAmL,0BAAA,0BACAnL,EAAAoL,sBAAA,sBACApL,EAAAqL,qBAAA,qBACArL,EAAAsL,sBAAA,sBACAtL,EAAAuL,6BAAA,4BAIAvL,EAAAwL,0BAAA,0BAIAxL,EAAAyL,qBAAA,uBT8kBMC,2CACA,SAAU3L,EAAQC,EAASC,GU/pBjC,YAmBA,SAAA0L,GAAA5J,EAAA6J,GACA,GAAAC,GAAA,GAAAC,GAAAC,EAAA,cACAC,GACAjK,SACA6J,UACAK,UAAAJ,EACAK,MAAAL,EACA9D,KAAA,EACAoE,UAAA,EACAC,QAAAC,EAEA,OAAAL,GAWA,QAAAK,KACA,GAAAH,GAAA1K,KAAAyK,UAAAzK,KAAA0K,KACA,IAAAA,EAAAtJ,OAAA0J,EAAA,CACA,EACAJ,KAAAK,KAAAC,EAAAhL,KAAA0K,SACKA,EAAAtJ,OAAA6J,EACLjL,MAAA0K,QAEA,MAAAA,GA4DA,QAAAQ,GAAAR,GACA,GAAAnJ,GAAAmJ,EAAAnJ,KACA,OAAAA,GAAAmJ,EAAAtJ,KAAA,KAAAG,EAAA,IAAAmJ,EAAAtJ,KASA,QAAAkJ,GAAAlJ,EAAAV,EAAAC,EAAA4F,EAAAI,EAAAwE,EAAA5J,GACAvB,KAAAoB,OACApB,KAAAU,QACAV,KAAAW,MACAX,KAAAuG,OACAvG,KAAA2G,SACA3G,KAAAuB,QACAvB,KAAAmL,OACAnL,KAAA+K,KAAA,KAaA,QAAAK,GAAAC,GACA,MAEAC,OAAAD,GAAAP,EAEAO,EAAA,IAAAE,KAAAC,UAAAtF,OAAAuF,aAAAJ,IAEA,aAAAA,EAAAlJ,SAAA,IAAAuJ,eAAAzI,OAAA,OAWA,QAAA+H,GAAAR,EAAAW,GACA,GAAA5K,GAAAiK,EAAAjK,OACAC,EAAAD,EAAAC,KACAmL,EAAAnL,EAAAxB,OAEAoH,EAAAwF,EAAApL,EAAA2K,EAAAxK,IAAA6J,GACAjE,EAAAiE,EAAAjE,KACAsF,EAAA,EAAAzF,EAAAoE,EAAAG,SAEA,IAAAvE,GAAAuF,EACA,UAAArB,GAAAQ,EAAAa,IAAApF,EAAAsF,EAAAV,EAGA,IAAAE,GAAAS,EAAArM,KAAAe,EAAA4F,EAGA,IAAAiF,EAAA,QAAAA,GAAA,KAAAA,GAAA,KAAAA,EACA,QAAAU,EAAAlG,aAAAtF,EAAA6F,EAAA,wCAAAgF,EAAAC,GAAA,IAGA,QAAAA,GAEA,QACA,UAAAf,GAAA0B,EAAA5F,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,SACA,MAAAc,GAAA1L,EAAA6F,EAAAG,EAAAsF,EAAAV,EAEA,SACA,UAAAb,GAAA4B,EAAA9F,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,SACA,UAAAb,GAAA6B,EAAA/F,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,SACA,UAAAb,GAAA8B,EAAAhG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,SACA,QAAAW,EAAArM,KAAAe,EAAA4F,EAAA,SAAA0F,EAAArM,KAAAe,EAAA4F,EAAA,GACA,UAAAkE,GAAA+B,EAAAjG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,MAEA,SACA,UAAAb,GAAAgC,EAAAlG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,SACA,UAAAb,GAAAiC,EAAAnG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,SACA,UAAAb,GAAAkC,EAAApG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,SACA,UAAAb,GAAAmC,EAAArG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,SACA,UAAAb,GAAAoC,EAAAtG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,UACA,UAAAb,GAAAqC,EAAAvG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,UACA,UAAAb,GAAAsC,EAAAxG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,UACA,UAAAb,GAAAuC,EAAAzG,IAAA,EAAAG,EAAAsF,EAAAV,EAEA,iEACA,gEACA,gEACA,gBACA,QACA,qEACA,+DACA,+DACA,oCACA,MAAA2B,GAAAvM,EAAA6F,EAAAG,EAAAsF,EAAAV,EAEA,SACA,wCACA,wCACA,MAAA4B,GAAAxM,EAAA6F,EAAAiF,EAAA9E,EAAAsF,EAAAV,EAEA,SACA,MAAA6B,GAAAzM,EAAA6F,EAAAG,EAAAsF,EAAAV,GAGA,QAAAY,EAAAlG,aAAAtF,EAAA6F,EAAA6G,EAAA5B,IAMA,QAAA4B,GAAA5B,GACA,YAAAA,EAEA,kFAGA,yCAAAD,EAAAC,GAAA,IAQA,QAAAO,GAAApL,EAAA0M,EAAA1C,GAGA,IAFA,GAAAmB,GAAAnL,EAAAxB,OACAoH,EAAA8G,EACA9G,EAAAuF,GAAA,CACA,GAAAN,GAAAS,EAAArM,KAAAe,EAAA4F,EAEA,QAAAiF,GAAA,KAAAA,GAAA,KAAAA,GAAA,QAAAA,IACAjF,MACK,SAAAiF,IAELjF,IACAoE,EAAAjE,KACAiE,EAAAG,UAAAvE,MACK,SAAAiF,EAUL,KARA,MAAAS,EAAArM,KAAAe,EAAA4F,EAAA,GACAA,GAAA,IAEAA,IAEAoE,EAAAjE,KACAiE,EAAAG,UAAAvE,GAKA,MAAAA,GAQA,QAAA6F,GAAA1L,EAAAG,EAAA6F,EAAAsF,EAAAV,GACA,GAAA3K,GAAAD,EAAAC,KACA6K,EAAA,OACAjF,EAAA1F,CAEA,GACA2K,GAAAS,EAAArM,KAAAe,IAAA4F,SACG,OAAAiF,IAEHA,EAAA,QAAAA,GAEA,WAAAf,GAAAW,EAAAvK,EAAA0F,EAAAG,EAAAsF,EAAAV,EAAAlI,EAAAxD,KAAAe,EAAAE,EAAA,EAAA0F,IAUA,QAAA2G,GAAAxM,EAAAG,EAAAyM,EAAA5G,EAAAsF,EAAAV,GACA,GAAA3K,GAAAD,EAAAC,KACA6K,EAAA8B,EACA/G,EAAA1F,EACA0M,GAAA,CAOA,IALA,KAAA/B,IAEAA,EAAAS,EAAArM,KAAAe,IAAA4F,IAGA,KAAAiF,GAGA,GADAA,EAAAS,EAAArM,KAAAe,IAAA4F,GACAiF,GAAA,IAAAA,GAAA,GACA,QAAAU,EAAAlG,aAAAtF,EAAA6F,EAAA,6CAAAgF,EAAAC,GAAA,SAGAjF,GAAAiH,EAAA9M,EAAA6F,EAAAiF,GACAA,EAAAS,EAAArM,KAAAe,EAAA4F,EAwBA,OArBA,MAAAiF,IAEA+B,GAAA,EAEA/B,EAAAS,EAAArM,KAAAe,IAAA4F,GACAA,EAAAiH,EAAA9M,EAAA6F,EAAAiF,GACAA,EAAAS,EAAArM,KAAAe,EAAA4F,IAGA,KAAAiF,GAAA,MAAAA,IAEA+B,GAAA,EAEA/B,EAAAS,EAAArM,KAAAe,IAAA4F,GACA,KAAAiF,GAAA,KAAAA,IAEAA,EAAAS,EAAArM,KAAAe,IAAA4F,IAEAA,EAAAiH,EAAA9M,EAAA6F,EAAAiF,IAGA,GAAAf,GAAA8C,EAAA3E,EAAAD,EAAA9H,EAAA0F,EAAAG,EAAAsF,EAAAV,EAAAlI,EAAAxD,KAAAe,EAAAE,EAAA0F,IAMA,QAAAiH,GAAA9M,EAAAG,EAAAyM,GACA,GAAA3M,GAAAD,EAAAC,KACA4F,EAAA1F,EACA2K,EAAA8B,CACA,IAAA9B,GAAA,IAAAA,GAAA,IAEA,EACAA,GAAAS,EAAArM,KAAAe,IAAA4F,SACKiF,GAAA,IAAAA,GAAA,GACL,OAAAjF,GAEA,QAAA2F,EAAAlG,aAAAtF,EAAA6F,EAAA,2CAAAgF,EAAAC,GAAA,KAQA,QAAA2B,GAAAzM,EAAAG,EAAA6F,EAAAsF,EAAAV,GAOA,IANA,GAAA3K,GAAAD,EAAAC,KACA4F,EAAA1F,EAAA,EACA4M,EAAAlH,EACAiF,EAAA,EACA9J,EAAA,GAEA6E,EAAA5F,EAAAxB,QAAA,QAAAqM,EAAAS,EAAArM,KAAAe,EAAA4F,KAEA,KAAAiF,GAAA,KAAAA,GAEA,KAAAA,GAAA,CAEA,GAAAA,EAAA,QAAAA,EACA,QAAAU,EAAAlG,aAAAtF,EAAA6F,EAAA,oCAAAgF,EAAAC,GAAA,IAIA,MADAjF,EACA,KAAAiF,EAAA,CAIA,OAFA9J,GAAA0B,EAAAxD,KAAAe,EAAA8M,EAAAlH,EAAA,GACAiF,EAAAS,EAAArM,KAAAe,EAAA4F,IAEA,QACA7E,GAAA,GAAuB,MACvB,SACAA,GAAA,GAAuB,MACvB,SACAA,GAAA,IAAwB,MACxB,SACAA,GAAA,IAAwB,MACxB,UACAA,GAAA,IAAwB,MACxB,UACAA,GAAA,IAAwB,MACxB,UACAA,GAAA,IAAwB,MACxB,UACAA,GAAA,IAAwB,MACxB,UAEA,GAAAgM,GAAAC,EAAA1B,EAAArM,KAAAe,EAAA4F,EAAA,GAAA0F,EAAArM,KAAAe,EAAA4F,EAAA,GAAA0F,EAAArM,KAAAe,EAAA4F,EAAA,GAAA0F,EAAArM,KAAAe,EAAA4F,EAAA,GACA,IAAAmH,EAAA,EACA,QAAAxB,EAAAlG,aAAAtF,EAAA6F,EAAA,6CAAA5F,EAAAyC,MAAAmD,EAAA,EAAAA,EAAA,QAEA7E,IAAA2E,OAAAuF,aAAA8B,GACAnH,GAAA,CACA,MACA,SACA,QAAA2F,EAAAlG,aAAAtF,EAAA6F,EAAA,wCAAAF,OAAAuF,aAAAJ,GAAA,OAEAjF,EACAkH,EAAAlH,GAIA,QAAAiF,EAEA,QAAAU,EAAAlG,aAAAtF,EAAA6F,EAAA,uBAIA,OADA7E,IAAA0B,EAAAxD,KAAAe,EAAA8M,EAAAlH,GACA,GAAAkE,GAAA5B,EAAAhI,EAAA0F,EAAA,EAAAG,EAAAsF,EAAAV,EAAA5J,GAaA,QAAAiM,GAAAC,EAAAC,EAAAC,EAAAtL,GACA,MAAAuL,GAAAH,IAAA,GAAAG,EAAAF,IAAA,EAAAE,EAAAD,IAAA,EAAAC,EAAAvL,GAWA,QAAAuL,GAAAH,GACA,MAAAA,IAAA,IAAAA,GAAA,GAAAA,EAAA,GACAA,GAAA,IAAAA,GAAA,GAAAA,EAAA,GACAA,GAAA,IAAAA,GAAA,IAAAA,EAAA,IACA,EAQA,QAAAX,GAAAvM,EAAA6F,EAAAG,EAAAsF,EAAAV,GAKA,IAJA,GAAA3K,GAAAD,EAAAC,KACAmL,EAAAnL,EAAAxB,OACA2B,EAAAyF,EAAA,EACAiF,EAAA,EACA1K,IAAAgL,GAAA,QAAAN,EAAAS,EAAArM,KAAAe,EAAAG,MAAA,KAAA0K,GACAA,GAAA,IAAAA,GAAA,IACAA,GAAA,IAAAA,GAAA,IACAA,GAAA,IAAAA,GAAA,QAEA1K,CAEA,WAAA2J,GAAAzC,EAAAzB,EAAAzF,EAAA4F,EAAAsF,EAAAV,EAAAlI,EAAAxD,KAAAe,EAAA4F,EAAAzF,IAlfAsB,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAAqP,UAAAjO,OACApB,EAAA2L,cACA3L,EAAA0M,cAEA,IAAAa,GAAAtN,EAAA,yCAiDA8L,EAAA,QACAO,EAAA,QACAkB,EAAA,IACAE,EAAA,IACAC,EAAA,IACAC,EAAA,IACAC,EAAA,MACAC,EAAA,IACAC,EAAA,IACAC,EAAA,IACAC,EAAA,IACAC,EAAA,IACAC,EAAA,IACAC,EAAA,IACAC,EAAA,IACAhF,EAAA,OACAW,EAAA,MACAC,EAAA,QACAC,EAAA,SACAuC,EAAA,UAqCAa,GA/BAtN,EAAAqP,WACAtD,MACAO,MACAkB,OACAE,SACAC,UACAC,UACAC,SACAC,QACAC,SACAC,KACAC,YACAC,YACAC,UACAC,OACAC,UACAhF,OACAW,MACAC,QACAC,SACAuC,WAWA/E,OAAAhE,UAAA4J,YACA7I,EAAAiD,OAAAhE,UAAAe,KAiBAqH,GAAApI,UAAA4L,OAAAxD,EAAApI,UAAA6L,QAAA,WACA,OACA3M,KAAApB,KAAAoB,KACAG,MAAAvB,KAAAuB,MACAgF,KAAAvG,KAAAuG,KACAI,OAAA3G,KAAA2G,UVihCMqH,8CACA,SAAUzP,EAAQC,GW3pCxB,YAsBA,SAAA8F,GAAA/D,EAAA6F,GAKA,IAJA,GAAA6H,GAAA,eACA1H,EAAA,EACAI,EAAAP,EAAA,EACA8H,EAAA,QACAA,EAAAD,EAAAE,KAAA5N,EAAAC,QAAA0N,EAAAE,MAAAhI,GACAG,GAAA,EACAI,EAAAP,EAAA,GAAA8H,EAAAE,MAAAF,EAAA,GAAAlP,OAEA,QAAUuH,OAAAI,UA7BV1E,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAA8F,eXgsCM+J,4CACA,SAAU9P,EAAQC,EAASC,GYtsCjC,YAuCA,SAAAqE,GAAAvC,EAAA6J,GACA,GAAAkE,GAAA,gBAAA/N,GAAA,GAAAsD,IAAA0K,OAAAhO,IACA,MAAA+N,YAAAzK,IAAA0K,QACA,SAAAC,WAAA,kCAAAtI,OAAAoI,GAEA,IAAA9D,IAAA,EAAAiE,GAAAtE,aAAAmE,EAAAlE,MACA,OAAAzH,GAAA6H,GAaA,QAAAkE,GAAAnO,EAAA6J,GACA,GAAAkE,GAAA,gBAAA/N,GAAA,GAAAsD,IAAA0K,OAAAhO,KACAiK,GAAA,EAAAiE,GAAAtE,aAAAmE,EAAAlE,MACAuE,IAAAnE,EAAAiE,GAAAZ,UAAAtD,IACA,IAAAhJ,GAAAqN,EAAApE,GAAA,EAEA,OADAmE,IAAAnE,EAAAiE,GAAAZ,UAAA/C,KACAvJ,EAaA,QAAAsN,GAAAtO,EAAA6J,GACA,GAAAkE,GAAA,gBAAA/N,GAAA,GAAAsD,IAAA0K,OAAAhO,KACAiK,GAAA,EAAAiE,GAAAtE,aAAAmE,EAAAlE,MACAuE,IAAAnE,EAAAiE,GAAAZ,UAAAtD,IACA,IAAAuE,GAAAC,EAAAvE,EAEA,OADAmE,IAAAnE,EAAAiE,GAAAZ,UAAA/C,KACAgE,EAMA,QAAAE,GAAAxE,GACA,GAAAE,GAAAiE,GAAAnE,EAAAiE,GAAAZ,UAAAhG,KACA,QACAzG,KAAA6N,GAAApH,KACAtG,MAAAmJ,EAAAnJ,MACAjB,MAAAkK,EAAAE,IASA,QAAA/H,GAAA6H,GACA,GAAA9J,GAAA8J,EAAAE,KACAiE,IAAAnE,EAAAiE,GAAAZ,UAAAtD,IACA,IAAArJ,KACA,GACAA,GAAA/B,KAAA+P,EAAA1E,WACG2E,EAAA3E,EAAAiE,GAAAZ,UAAA/C,KAEH,QACA1J,KAAA6N,GAAAnH,SACA5G,cACAZ,MAAAkK,EAAA9J,IAUA,QAAAwO,GAAA1E,GACA,GAAA4E,EAAA5E,EAAAiE,GAAAZ,UAAAlB,SACA,MAAA0C,GAAA7E,EAGA,IAAA4E,EAAA5E,EAAAiE,GAAAZ,UAAAhG,MACA,OAAA2C,EAAAE,MAAAnJ,OAEA,YACA,eACA,mBACA,MAAA8N,GAAA7E,EAEA,gBACA,MAAA8E,GAAA9E,EAGA,cACA,aACA,WACA,gBACA,YACA,WACA,YACA,aACA,gBACA,MAAA+E,GAAA/E,GAIA,KAAAgF,IAAAhF,GAUA,QAAA6E,GAAA7E,GACA,GAAA9J,GAAA8J,EAAAE,KACA,IAAA0E,EAAA5E,EAAAiE,GAAAZ,UAAAlB,SACA,OACAvL,KAAA6N,GAAAlH,qBACA0H,UAAA,QACAnO,KAAA,KACAoO,oBAAA,KACAC,cACAC,aAAAC,EAAArF,GACAlK,MAAAkK,EAAA9J,GAGA,IAAA+O,GAAAK,EAAAtF,GACAlJ,EAAA,MAIA,OAHA8N,GAAA5E,EAAAiE,GAAAZ,UAAAhG,QACAvG,EAAA0N,EAAAxE,KAGApJ,KAAA6N,GAAAlH,qBACA0H,YACAnO,OACAoO,oBAAAK,EAAAvF,GACAmF,WAAAK,EAAAxF,GACAoF,aAAAC,EAAArF,GACAlK,MAAAkK,EAAA9J,IAOA,QAAAoP,GAAAtF,GACA,GAAAyF,GAAAtB,GAAAnE,EAAAiE,GAAAZ,UAAAhG,KACA,QAAAoI,EAAA1O,OACA,YACA,aACA,gBACA,gBAEA,oBACA,qBAGA,KAAAiO,IAAAhF,EAAAyF,GAMA,QAAAF,GAAAvF,GACA,MAAA4E,GAAA5E,EAAAiE,GAAAZ,UAAA1B,SAAA+D,GAAA1F,EAAAiE,GAAAZ,UAAA1B,QAAAgE,EAAA1B,GAAAZ,UAAAzB,YAMA,QAAA+D,GAAA3F,GACA,GAAA9J,GAAA8J,EAAAE,KACA,QACAtJ,KAAA6N,GAAAjH,oBACAoI,SAAAC,EAAA7F,GACAsE,MAAAH,GAAAnE,EAAAiE,GAAAZ,UAAAvB,OAAAyC,EAAAvE,IACA8F,aAAAnB,EAAA3E,EAAAiE,GAAAZ,UAAAtB,QAAAqC,EAAApE,GAAA,QACAlK,MAAAkK,EAAA9J,IAOA,QAAA2P,GAAA7F,GACA,GAAA9J,GAAA8J,EAAAE,KAEA,OADAiE,IAAAnE,EAAAiE,GAAAZ,UAAA3B,SAEA9K,KAAA6N,GAAAhH,SACA3G,KAAA0N,EAAAxE,GACAlK,MAAAkK,EAAA9J,IAOA,QAAAmP,GAAArF,GACA,GAAA9J,GAAA8J,EAAAE,KACA,QACAtJ,KAAA6N,GAAA/G,cACAqI,WAAAL,GAAA1F,EAAAiE,GAAAZ,UAAAlB,QAAA6D,EAAA/B,GAAAZ,UAAAhB,SACAvM,MAAAkK,EAAA9J,IAUA,QAAA8P,GAAAhG,GACA,MAAA4E,GAAA5E,EAAAiE,GAAAZ,UAAAxB,QAAAoE,EAAAjG,GAAAkG,EAAAlG,GAQA,QAAAkG,GAAAlG,GACA,GAAA9J,GAAA8J,EAAAE,MAEAiG,EAAA3B,EAAAxE,GACAoG,EAAA,OACAtP,EAAA,MASA,OARA6N,GAAA3E,EAAAiE,GAAAZ,UAAAvB,QACAsE,EAAAD,EACArP,EAAA0N,EAAAxE,KAEAoG,EAAA,KACAtP,EAAAqP,IAIAvP,KAAA6N,GAAA9G,MACAyI,QACAtP,OACAvC,UAAA8R,EAAArG,GACAmF,WAAAK,EAAAxF,GACAoF,aAAAR,EAAA5E,EAAAiE,GAAAZ,UAAAlB,SAAAkD,EAAArF,GAAA,KACAlK,MAAAkK,EAAA9J,IAOA,QAAAmQ,GAAArG,GACA,MAAA4E,GAAA5E,EAAAiE,GAAAZ,UAAA1B,SAAA+D,GAAA1F,EAAAiE,GAAAZ,UAAA1B,QAAA2E,EAAArC,GAAAZ,UAAAzB,YAMA,QAAA0E,GAAAtG,GACA,GAAA9J,GAAA8J,EAAAE,KACA,QACAtJ,KAAA6N,GAAA7G,SACA9G,KAAA0N,EAAAxE,GACAjJ,OAAAoN,GAAAnE,EAAAiE,GAAAZ,UAAAvB,OAAAsC,EAAApE,GAAA,IACAlK,MAAAkK,EAAA9J,IAaA,QAAA+P,GAAAjG,GACA,GAAA9J,GAAA8J,EAAAE,KAEA,IADAiE,GAAAnE,EAAAiE,GAAAZ,UAAAxB,QACA+C,EAAA5E,EAAAiE,GAAAZ,UAAAhG,OAAA,OAAA2C,EAAAE,MAAAnJ,MACA,OACAH,KAAA6N,GAAA5G,gBACA/G,KAAAyP,EAAAvG,GACAmF,WAAAK,EAAAxF,GACAlK,MAAAkK,EAAA9J,GAGA,IAAAsQ,GAAA,IAKA,OAJA,OAAAxG,EAAAE,MAAAnJ,QACAiJ,EAAAI,UACAoG,EAAAC,EAAAzG,KAGApJ,KAAA6N,GAAA3G,gBACA0I,gBACArB,WAAAK,EAAAxF,GACAoF,aAAAC,EAAArF,GACAlK,MAAAkK,EAAA9J,IAUA,QAAA4O,GAAA9E,GACA,GAAA9J,GAAA8J,EAAAE,KAEA,OADAwG,IAAA1G,EAAA,aAEApJ,KAAA6N,GAAA1G,oBACAjH,KAAAyP,EAAAvG,GACAwG,eAAAE,GAAA1G,EAAA,MAAAyG,EAAAzG,IACAmF,WAAAK,EAAAxF,GACAoF,aAAAC,EAAArF,GACAlK,MAAAkK,EAAA9J,IAOA,QAAAqQ,GAAAvG,GACA,UAAAA,EAAAE,MAAAnJ,MACA,KAAAiO,IAAAhF,EAEA,OAAAwE,GAAAxE,GAuBA,QAAAoE,GAAApE,EAAA2G,GACA,GAAAzG,GAAAF,EAAAE,KACA,QAAAA,EAAAtJ,MACA,IAAAqN,IAAAZ,UAAApB,UACA,MAAA2E,GAAA5G,EAAA2G,EACA,KAAA1C,IAAAZ,UAAAlB,QACA,MAAA0E,GAAA7G,EAAA2G,EACA,KAAA1C,IAAAZ,UAAArF,IAEA,MADAgC,GAAAI,WAEAxJ,KAAA6N,GAAAzG,IACAjH,MAAAmJ,EAAAnJ,MACAjB,MAAAkK,EAAAE,GAEA,KAAA+D,IAAAZ,UAAApF,MAEA,MADA+B,GAAAI,WAEAxJ,KAAA6N,GAAAxG,MACAlH,MAAAmJ,EAAAnJ,MACAjB,MAAAkK,EAAAE,GAEA,KAAA+D,IAAAZ,UAAAnF,OAEA,MADA8B,GAAAI,WAEAxJ,KAAA6N,GAAAvG,OACAnH,MAAAmJ,EAAAnJ,MACAjB,MAAAkK,EAAAE,GAEA,KAAA+D,IAAAZ,UAAAhG,KACA,eAAA6C,EAAAnJ,OAAA,UAAAmJ,EAAAnJ,OACAiJ,EAAAI,WAEAxJ,KAAA6N,GAAAtG,QACApH,MAAA,SAAAmJ,EAAAnJ,MACAjB,MAAAkK,EAAAE,KAEO,SAAAA,EAAAnJ,OACPiJ,EAAAI,WAEAxJ,KAAA6N,GAAArG,KACAtI,MAAAkK,EAAAE,MAGAF,EAAAI,WAEAxJ,KAAA6N,GAAApG,KACAtH,MAAAmJ,EAAAnJ,MACAjB,MAAAkK,EAAAE,IAEA,KAAA+D,IAAAZ,UAAA3B,OACA,IAAAiF,EACA,MAAAd,GAAA7F,GAIA,KAAAgF,IAAAhF,GAGA,QAAA8G,GAAA9G,GACA,MAAAoE,GAAApE,GAAA,GAGA,QAAA+G,GAAA/G,GACA,MAAAoE,GAAApE,GAAA,GAQA,QAAA4G,GAAA5G,EAAA2G,GACA,GAAAzQ,GAAA8J,EAAAE,MACA8G,EAAAL,EAAAG,EAAAC,CACA,QACAnQ,KAAA6N,GAAAnG,KACA2I,OAAAC,GAAAlH,EAAAiE,GAAAZ,UAAApB,UAAA+E,EAAA/C,GAAAZ,UAAAnB,WACApM,MAAAkK,EAAA9J,IASA,QAAA2Q,GAAA7G,EAAA2G,GACA,GAAAzQ,GAAA8J,EAAAE,KACAiE,IAAAnE,EAAAiE,GAAAZ,UAAAlB,QAEA,KADA,GAAAgF,OACAxC,EAAA3E,EAAAiE,GAAAZ,UAAAhB,UACA8E,EAAAxS,KAAAyS,EAAApH,EAAA2G,GAEA,QACA/P,KAAA6N,GAAAlG,OACA4I,SACArR,MAAAkK,EAAA9J,IAOA,QAAAkR,GAAApH,EAAA2G,GACA,GAAAzQ,GAAA8J,EAAAE,KACA,QACAtJ,KAAA6N,GAAAjG,aACA1H,KAAA0N,EAAAxE,GACAjJ,OAAAoN,GAAAnE,EAAAiE,GAAAZ,UAAAvB,OAAAsC,EAAApE,EAAA2G,IACA7Q,MAAAkK,EAAA9J,IASA,QAAAsP,GAAAxF,GAEA,IADA,GAAAmF,MACAP,EAAA5E,EAAAiE,GAAAZ,UAAArB,KACAmD,EAAAxQ,KAAA0S,EAAArH,GAEA,OAAAmF,GAMA,QAAAkC,GAAArH,GACA,GAAA9J,GAAA8J,EAAAE,KAEA,OADAiE,IAAAnE,EAAAiE,GAAAZ,UAAArB,KAEApL,KAAA6N,GAAAhG,UACA3H,KAAA0N,EAAAxE,GACAzL,UAAA8R,EAAArG,GACAlK,MAAAkK,EAAA9J,IAYA,QAAAqO,GAAAvE,GACA,GAAA9J,GAAA8J,EAAAE,MACAoE,EAAA,MAYA,OAXAK,GAAA3E,EAAAiE,GAAAZ,UAAApB,YACAqC,EAAAC,EAAAvE,GACAmE,GAAAnE,EAAAiE,GAAAZ,UAAAnB,WACAoC,GACA1N,KAAA6N,GAAA9F,UACA2F,OACAxO,MAAAkK,EAAA9J,KAGAoO,EAAAmC,EAAAzG,GAEA2E,EAAA3E,EAAAiE,GAAAZ,UAAA7B,OAEA5K,KAAA6N,GAAA7F,cACA0F,OACAxO,MAAAkK,EAAA9J,IAGAoO,EAMA,QAAAmC,GAAAzG,GACA,GAAA9J,GAAA8J,EAAAE,KACA,QACAtJ,KAAA6N,GAAA/F,WACA5H,KAAA0N,EAAAxE,GACAlK,MAAAkK,EAAA9J,IAqBA,QAAA6O,GAAA/E,GACA,GAAA4E,EAAA5E,EAAAiE,GAAAZ,UAAAhG,MACA,OAAA2C,EAAAE,MAAAnJ,OACA,aACA,MAAAuQ,GAAAtH,EACA,cACA,MAAAuH,GAAAvH,EACA,YACA,MAAAwH,GAAAxH,EACA,iBACA,MAAAyH,GAAAzH,EACA,aACA,MAAA0H,GAAA1H,EACA,YACA,MAAA2H,GAAA3H,EACA,aACA,MAAA4H,GAAA5H,EACA,cACA,MAAA6H,GAAA7H,EACA,iBACA,MAAA8H,GAAA9H,GAIA,KAAAgF,IAAAhF,GAQA,QAAAsH,GAAAtH,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,SACA,IAAAmF,GAAAK,EAAAxF,GACA+H,EAAArC,GAAA1F,EAAAiE,GAAAZ,UAAAlB,QAAA6F,EAAA/D,GAAAZ,UAAAhB,QACA,QACAzL,KAAA6N,GAAA5F,kBACAsG,aACA4C,iBACAjS,MAAAkK,EAAA9J,IAIA,QAAA8R,GAAAhI,GACA,GAAA9J,GAAA8J,EAAAE,MACA+E,EAAAK,EAAAtF,EACAmE,IAAAnE,EAAAiE,GAAAZ,UAAAvB,MACA,IAAAwC,GAAAmC,EAAAzG,EACA,QACApJ,KAAA6N,GAAA3F,0BACAmG,YACAX,OACAxO,MAAAkK,EAAA9J,IAOA,QAAAqR,GAAAvH,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,SACA,IAAAlJ,GAAA0N,EAAAxE,GACAmF,EAAAK,EAAAxF,EACA,QACApJ,KAAA6N,GAAA1F,uBACAjI,OACAqO,aACArP,MAAAkK,EAAA9J,IAQA,QAAAsR,GAAAxH,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,OACA,IAAAlJ,GAAA0N,EAAAxE,GACAiI,EAAAC,EAAAlI,GACAmF,EAAAK,EAAAxF,GACAmH,EAAAD,GAAAlH,EAAAiE,GAAAZ,UAAAlB,QAAAgG,EAAAlE,GAAAZ,UAAAhB,QACA,QACAzL,KAAA6N,GAAAzF,uBACAlI,OACAmR,aACA9C,aACAgC,SACArR,MAAAkK,EAAA9J,IAOA,QAAAgS,GAAAlI,GACA,GAAAoI,KACA,mBAAApI,EAAAE,MAAAnJ,MAAA,CACAiJ,EAAAI,SACA,GACAgI,GAAAzT,KAAA8R,EAAAzG,UACK4E,EAAA5E,EAAAiE,GAAAZ,UAAAhG,OAEL,MAAA+K,GAMA,QAAAD,GAAAnI,GACA,GAAA9J,GAAA8J,EAAAE,MACApJ,EAAA0N,EAAAxE,GACAxH,EAAA6P,EAAArI,EACAmE,IAAAnE,EAAAiE,GAAAZ,UAAAvB,MACA,IAAAwC,GAAAC,EAAAvE,GACAmF,EAAAK,EAAAxF,EACA,QACApJ,KAAA6N,GAAAxF,iBACAnI,OACAvC,UAAAiE,EACA8L,OACAa,aACArP,MAAAkK,EAAA9J,IAOA,QAAAmS,GAAArI,GACA,MAAA4E,GAAA5E,EAAAiE,GAAAZ,UAAA1B,SAGA+D,GAAA1F,EAAAiE,GAAAZ,UAAA1B,QAAA2G,EAAArE,GAAAZ,UAAAzB,YAMA,QAAA0G,GAAAtI,GACA,GAAA9J,GAAA8J,EAAAE,MACApJ,EAAA0N,EAAAxE,EACAmE,IAAAnE,EAAAiE,GAAAZ,UAAAvB,MACA,IAAAwC,GAAAC,EAAAvE,GACA8F,EAAA,IACAnB,GAAA3E,EAAAiE,GAAAZ,UAAAtB,UACA+D,EAAAgB,EAAA9G,GAEA,IAAAmF,GAAAK,EAAAxF,EACA,QACApJ,KAAA6N,GAAAvF,uBACApI,OACAwN,OACAwB,eACAX,aACArP,MAAAkK,EAAA9J,IAOA,QAAAuR,GAAAzH,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,YACA,IAAAlJ,GAAA0N,EAAAxE,GACAmF,EAAAK,EAAAxF,GACAmH,EAAAD,GAAAlH,EAAAiE,GAAAZ,UAAAlB,QAAAgG,EAAAlE,GAAAZ,UAAAhB,QACA,QACAzL,KAAA6N,GAAAtF,0BACArI,OACAqO,aACAgC,SACArR,MAAAkK,EAAA9J,IAOA,QAAAwR,GAAA1H,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,QACA,IAAAlJ,GAAA0N,EAAAxE,GACAmF,EAAAK,EAAAxF,EACAmE,IAAAnE,EAAAiE,GAAAZ,UAAAtB,OACA,IAAAqG,GAAAG,EAAAvI,EACA,QACApJ,KAAA6N,GAAArF,sBACAtI,OACAqO,aACAiD,QACAtS,MAAAkK,EAAA9J,IASA,QAAAqS,GAAAvI,GAEA2E,EAAA3E,EAAAiE,GAAAZ,UAAAjB,KACA,IAAAoG,KACA,GACAA,GAAA7T,KAAA8R,EAAAzG,UACG2E,EAAA3E,EAAAiE,GAAAZ,UAAAjB,MACH,OAAAoG,GAMA,QAAAb,GAAA3H,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,OACA,IAAAlJ,GAAA0N,EAAAxE,GACAmF,EAAAK,EAAAxF,GACAiH,EAAAvB,GAAA1F,EAAAiE,GAAAZ,UAAAlB,QAAAsG,EAAAxE,GAAAZ,UAAAhB,QACA,QACAzL,KAAA6N,GAAApF,qBACAvI,OACAqO,aACA8B,SACAnR,MAAAkK,EAAA9J,IASA,QAAAuS,GAAAzI,GACA,GAAA9J,GAAA8J,EAAAE,MACApJ,EAAA0N,EAAAxE,GACAmF,EAAAK,EAAAxF,EACA,QACApJ,KAAA6N,GAAAnF,sBACAxI,OACAqO,aACArP,MAAAkK,EAAA9J,IAOA,QAAA0R,GAAA5H,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,QACA,IAAAlJ,GAAA0N,EAAAxE,GACAmF,EAAAK,EAAAxF,GACAmH,EAAAD,GAAAlH,EAAAiE,GAAAZ,UAAAlB,QAAAmG,EAAArE,GAAAZ,UAAAhB,QACA,QACAzL,KAAA6N,GAAAlF,6BACAzI,OACAqO,aACAgC,SACArR,MAAAkK,EAAA9J,IAOA,QAAA2R,GAAA7H,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,SACA,IAAA0I,GAAAlB,EAAAxH,EACA,QACApJ,KAAA6N,GAAAjF,0BACAkJ,aACA5S,MAAAkK,EAAA9J,IAQA,QAAA4R,GAAA9H,GACA,GAAA9J,GAAA8J,EAAAE,KACAwG,IAAA1G,EAAA,aACAmE,GAAAnE,EAAAiE,GAAAZ,UAAArB,GACA,IAAAlL,GAAA0N,EAAAxE,GACAxH,EAAA6P,EAAArI,EACA0G,IAAA1G,EAAA,KACA,IAAA9F,GAAAyO,EAAA3I,EACA,QACApJ,KAAA6N,GAAAhF,qBACA3I,OACAvC,UAAAiE,EACA0B,YACApE,MAAAkK,EAAA9J,IASA,QAAAyS,GAAA3I,GAEA2E,EAAA3E,EAAAiE,GAAAZ,UAAAjB,KACA,IAAAlI,KACA,GACAA,GAAAvF,KAAA6P,EAAAxE,UACG2E,EAAA3E,EAAAiE,GAAAZ,UAAAjB,MACH,OAAAlI,GASA,QAAApE,GAAAkK,EAAAjI,GACA,IAAAiI,EAAAJ,QAAAgJ,WACA,UAAAC,GAAA9Q,EAAAiI,EAAAC,UAAAD,EAAAjK,QAIA,QAAA8S,GAAA9Q,EAAAC,EAAAjC,GACAP,KAAAU,MAAA6B,EAAA7B,MACAV,KAAAW,IAAA6B,EAAA7B,IACAX,KAAAuC,aACAvC,KAAAwC,WACAxC,KAAAO,SAWA,QAAA6O,GAAA5E,EAAApJ,GACA,MAAAoJ,GAAAE,MAAAtJ,SAOA,QAAA+N,GAAA3E,EAAApJ,GACA,GAAA8M,GAAA1D,EAAAE,MAAAtJ,QAIA,OAHA8M,IACA1D,EAAAI,UAEAsD,EAOA,QAAAS,IAAAnE,EAAApJ,GACA,GAAAsJ,GAAAF,EAAAE,KACA,IAAAA,EAAAtJ,SAEA,MADAoJ,GAAAI,UACAF,CAEA,SAAAqB,GAAAlG,aAAA2E,EAAAjK,OAAAmK,EAAAhK,MAAA,YAAAU,EAAA,cAAAqN,GAAAvD,cAAAR,IAQA,QAAAwG,IAAA1G,EAAAjJ,GACA,GAAAmJ,GAAAF,EAAAE,KACA,IAAAA,EAAAtJ,OAAAqN,GAAAZ,UAAAhG,MAAA6C,EAAAnJ,UAEA,MADAiJ,GAAAI,UACAF,CAEA,SAAAqB,GAAAlG,aAAA2E,EAAAjK,OAAAmK,EAAAhK,MAAA,aAAAa,EAAA,eAAAkN,GAAAvD,cAAAR,IAOA,QAAA8E,IAAAhF,EAAA8I,GACA,GAAA5I,GAAA4I,GAAA9I,EAAAE,KACA,UAAAqB,GAAAlG,aAAA2E,EAAAjK,OAAAmK,EAAAhK,MAAA,iBAAA+N,GAAAvD,cAAAR,IASA,QAAAgH,IAAAlH,EAAA+I,EAAAC,EAAAC,GACA9E,GAAAnE,EAAA+I,EAEA,KADA,GAAA9P,OACA0L,EAAA3E,EAAAiJ,IACAhQ,EAAAtE,KAAAqU,EAAAhJ,GAEA,OAAA/G,GASA,QAAAyM,IAAA1F,EAAA+I,EAAAC,EAAAC,GACA9E,GAAAnE,EAAA+I,EAEA,KADA,GAAA9P,IAAA+P,EAAAhJ,KACA2E,EAAA3E,EAAAiJ,IACAhQ,EAAAtE,KAAAqU,EAAAhJ,GAEA,OAAA/G,GA//BAxB,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAAsE,QACAtE,EAAAkQ,aACAlQ,EAAAqQ,YACArQ,EAAA8S,kBACA9S,EAAAuQ,qBACAvQ,EAAAyS,gBAEA,IAAApN,IAAApF,EAAA,6CAEAsN,GAAAtN,EAAA,yCAEAgQ,GAAAhQ,EAAA,4CAEAwQ,GAAAxQ,EAAA,2CAy5BA4U,GAAAnR,UAAA4L,OAAAuF,EAAAnR,UAAA6L,QAAA,WACA,OAAUrN,MAAAV,KAAAU,MAAAC,IAAAX,KAAAW,OZkyCJ+S,4CACA,SAAUnV,EAAQC,EAASC,Ga/sEjC,YAWA,SAAAyG,GAAAC,GAAsC,MAAAA,MAAAC,WAAAD,GAAuC9B,QAAA8B,GAE7E,QAAAwO,GAAAC,EAAAC,GAAiD,KAAAD,YAAAC,IAA0C,SAAArF,WAAA,qCAX3FvM,OAAA2C,eAAApG,EAAA,cACA+C,OAAA,IAEA/C,EAAA+P,OAAA3O,MAEA,IAAA4F,GAAA/G,EAAA,+CAEA8G,EAAAL,EAAAM,EAsBAhH,GAAA+P,OAAA,QAAAA,GAAA/N,EAAAc,EAAAkF,GACAmN,EAAA3T,KAAAuO,GAEAvO,KAAAQ,OACAR,KAAAsB,QAAA,kBACAtB,KAAAwG,mBAA2CD,KAAA,EAAAI,OAAA,GAC3C3G,KAAAwG,eAAAD,KAAA,YAAAhB,EAAAlC,SAAA,8DACArD,KAAAwG,eAAAG,OAAA,YAAApB,EAAAlC,SAAA,kEbstEMyQ,6BACA,SAAUvV,EAAQC,EAASC,GAEhC,YAkBA,SAASyG,GAAuBC,GAAO,MAAOA,IAAOA,EAAIC,WAAaD,GAAQ9B,QAAS8B,GAhBvFlD,OAAO2C,eAAepG,EAAS,cAC7B+C,OAAO,GclwEV,IAAAwS,GAAAtV,EAAA,iCduwEKuV,EAAU9O,EAAuB6O,GctwEtCE,EAAAxV,EAAA,sCd0wEKyV,EAAchP,EAAuB+O,GczwE1CE,EAAA1V,EAAA,sCd6wEK2V,EAAelP,EAAuBiP,Gc3wErCE,EAAS,SAAAC,GAAA,GAAGC,GAAHD,EAAGC,MAAOC,EAAVF,EAAUE,MAAV,OACbR,GAAA3Q,QAAAoR,cAAA,OAAKC,UAAU,UACbV,EAAA3Q,QAAAoR,cAAA,MAAIC,WAAW,EAAAN,EAAA/Q,SACb,iBACEsR,6BAA8BH,EAAOxV,UAEtCuV,GAGDC,EAAOxV,QACLgV,EAAA3Q,QAAAoR,cAAA,KAAGC,UAAU,kBACVF,IAOXH,GAAOO,WACLL,MAAOL,EAAA7Q,QAAUnD,OAAO2U,WACxBL,OAAQN,EAAA7Q,QAAUnD,QAGpBmU,EAAOS,cACLN,OAAQ,IdoxEThW,EAAQ6E,QcjxEMgR,EdkxEd9V,EAAOC,QAAUA,EAAiB,SAI7BuW,2yBACA,SAAUxW,EAAQC,EAASC,GAEhC,YAuBA,SAASyG,GAAuBC,GAAO,MAAOA,IAAOA,EAAIC,WAAaD,GAAQ9B,QAAS8B,GArBvFlD,OAAO2C,eAAepG,EAAS,cAC7B+C,OAAO,IAET/C,EAAQwW,UAAYpV,Me7zErB,IAAAmU,GAAAtV,EAAA,iCfi0EKuV,EAAU9O,EAAuB6O,Geh0EtCkB,EAAAxW,EAAA,qDACAwV,Gfm0EoB/O,EAAuB+P,Gen0E3CxW,EAAA,uCfu0EKyV,EAAchP,EAAuB+O,Ger0E1CiB,EAAAzW,EAAA,8Bfy0EK0W,EAAWjQ,EAAuBgQ,Gev0EjCE,EAAQ,SAAAd,GAAA,GAAGe,GAAHf,EAAGe,IAAH,OACZrB,GAAA3Q,QAAAoR,cAAA,OAAKC,UAAU,WACbV,EAAA3Q,QAAAoR,cAAAU,EAAA9R,SACEkR,MAAOc,EAAKC,KAAKC,aAAahB,MAC9BC,OAAQa,EAAKC,KAAKC,aAAalP,cAEjC2N,EAAA3Q,QAAAoR,cAAA,8BACAT,EAAA3Q,QAAAoR,cAAA,KAAGe,KAAK,gCAAR,qCACAxB,EAAA3Q,QAAAoR,cAAA,8BACAT,EAAA3Q,QAAAoR,cAAA,mDACyCT,EAAA3Q,QAAAoR,cAAA,WADzC,aAEYT,EAAA3Q,QAAAoR,cAAA,KAAGe,KAAK,+CAAR,2BAFZ,sBAOJJ,GAAMR,WACJS,KAAMnB,EAAA7Q,QAAUoS,OACdH,KAAMpB,EAAA7Q,QAAUoS,OACdF,aAAcrB,EAAA7Q,QAAUoS,OACtBlB,MAAOL,EAAA7Q,QAAUnD,OACjBmG,YAAa6N,EAAA7Q,QAAUnD,cAM/BkV,EAAMN,cACJO,MACEC,MACEC,cACEhB,MAAO,GACPlO,YAAa,Ofy2EpB7H,EAAQ6E,Qen2EM+R,CAEFJ","file":"page-component---src-pages-index-js-4631062d0b0ed4afc9b9.js","sourcesContent":["webpackJsonp([4016850265702045000],{\n\n/***/ \"./node_modules/classnames/index.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\tvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*!\n\t  Copyright (c) 2016 Jed Watson.\n\t  Licensed under the MIT License (MIT), see\n\t  http://jedwatson.github.io/classnames\n\t*/\n\t/* global define */\n\t\n\t(function () {\n\t\t'use strict';\n\t\n\t\tvar hasOwn = {}.hasOwnProperty;\n\t\n\t\tfunction classNames () {\n\t\t\tvar classes = [];\n\t\n\t\t\tfor (var i = 0; i < arguments.length; i++) {\n\t\t\t\tvar arg = arguments[i];\n\t\t\t\tif (!arg) continue;\n\t\n\t\t\t\tvar argType = typeof arg;\n\t\n\t\t\t\tif (argType === 'string' || argType === 'number') {\n\t\t\t\t\tclasses.push(arg);\n\t\t\t\t} else if (Array.isArray(arg)) {\n\t\t\t\t\tclasses.push(classNames.apply(null, arg));\n\t\t\t\t} else if (argType === 'object') {\n\t\t\t\t\tfor (var key in arg) {\n\t\t\t\t\t\tif (hasOwn.call(arg, key) && arg[key]) {\n\t\t\t\t\t\t\tclasses.push(key);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\n\t\t\treturn classes.join(' ');\n\t\t}\n\t\n\t\tif (typeof module !== 'undefined' && module.exports) {\n\t\t\tmodule.exports = classNames;\n\t\t} else if (true) {\n\t\t\t// register as 'classnames', consistent with npm package name\n\t\t\t!(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = function () {\n\t\t\t\treturn classNames;\n\t\t\t}.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__), __WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\t\t} else {\n\t\t\twindow.classNames = classNames;\n\t\t}\n\t}());\n\n\n/***/ }),\n\n/***/ \"./node_modules/graphql-tag/lib/graphql-tag.umd.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t(function (global, factory) {\n\t\t true ? factory() :\n\t\ttypeof define === 'function' && define.amd ? define(factory) :\n\t\t(factory());\n\t}(this, (function () { 'use strict';\n\t\n\tvar parser = __webpack_require__(\"./node_modules/graphql/language/parser.js\");\n\t\n\tvar parse = parser.parse;\n\t\n\t// Strip insignificant whitespace\n\t// Note that this could do a lot more, such as reorder fields etc.\n\tfunction normalize(string) {\n\t  return string.replace(/[\\s,]+/g, ' ').trim();\n\t}\n\t\n\t// A map docString -> graphql document\n\tvar docCache = {};\n\t\n\t// A map fragmentName -> [normalized source]\n\tvar fragmentSourceMap = {};\n\t\n\tfunction cacheKeyFromLoc(loc) {\n\t  return normalize(loc.source.body.substring(loc.start, loc.end));\n\t}\n\t\n\t// For testing.\n\tfunction resetCaches() {\n\t  docCache = {};\n\t  fragmentSourceMap = {};\n\t}\n\t\n\t// Take a unstripped parsed document (query/mutation or even fragment), and\n\t// check all fragment definitions, checking for name->source uniqueness.\n\t// We also want to make sure only unique fragments exist in the document.\n\tvar printFragmentWarnings = true;\n\tfunction processFragments(ast) {\n\t  var astFragmentMap = {};\n\t  var definitions = [];\n\t\n\t  for (var i = 0; i < ast.definitions.length; i++) {\n\t    var fragmentDefinition = ast.definitions[i];\n\t\n\t    if (fragmentDefinition.kind === 'FragmentDefinition') {\n\t      var fragmentName = fragmentDefinition.name.value;\n\t      var sourceKey = cacheKeyFromLoc(fragmentDefinition.loc);\n\t\n\t      // We know something about this fragment\n\t      if (fragmentSourceMap.hasOwnProperty(fragmentName) && !fragmentSourceMap[fragmentName][sourceKey]) {\n\t\n\t        // this is a problem because the app developer is trying to register another fragment with\n\t        // the same name as one previously registered. So, we tell them about it.\n\t        if (printFragmentWarnings) {\n\t          console.warn(\"Warning: fragment with name \" + fragmentName + \" already exists.\\n\"\n\t            + \"graphql-tag enforces all fragment names across your application to be unique; read more about\\n\"\n\t            + \"this in the docs: http://dev.apollodata.com/core/fragments.html#unique-names\");\n\t        }\n\t\n\t        fragmentSourceMap[fragmentName][sourceKey] = true;\n\t\n\t      } else if (!fragmentSourceMap.hasOwnProperty(fragmentName)) {\n\t        fragmentSourceMap[fragmentName] = {};\n\t        fragmentSourceMap[fragmentName][sourceKey] = true;\n\t      }\n\t\n\t      if (!astFragmentMap[sourceKey]) {\n\t        astFragmentMap[sourceKey] = true;\n\t        definitions.push(fragmentDefinition);\n\t      }\n\t    } else {\n\t      definitions.push(fragmentDefinition);\n\t    }\n\t  }\n\t\n\t  ast.definitions = definitions;\n\t  return ast;\n\t}\n\t\n\tfunction disableFragmentWarnings() {\n\t  printFragmentWarnings = false;\n\t}\n\t\n\tfunction stripLoc(doc, removeLocAtThisLevel) {\n\t  var docType = Object.prototype.toString.call(doc);\n\t\n\t  if (docType === '[object Array]') {\n\t    return doc.map(function (d) {\n\t      return stripLoc(d, removeLocAtThisLevel);\n\t    });\n\t  }\n\t\n\t  if (docType !== '[object Object]') {\n\t    throw new Error('Unexpected input.');\n\t  }\n\t\n\t  // We don't want to remove the root loc field so we can use it\n\t  // for fragment substitution (see below)\n\t  if (removeLocAtThisLevel && doc.loc) {\n\t    delete doc.loc;\n\t  }\n\t\n\t  // https://github.com/apollographql/graphql-tag/issues/40\n\t  if (doc.loc) {\n\t    delete doc.loc.startToken;\n\t    delete doc.loc.endToken;\n\t  }\n\t\n\t  var keys = Object.keys(doc);\n\t  var key;\n\t  var value;\n\t  var valueType;\n\t\n\t  for (key in keys) {\n\t    if (keys.hasOwnProperty(key)) {\n\t      value = doc[keys[key]];\n\t      valueType = Object.prototype.toString.call(value);\n\t\n\t      if (valueType === '[object Object]' || valueType === '[object Array]') {\n\t        doc[keys[key]] = stripLoc(value, true);\n\t      }\n\t    }\n\t  }\n\t\n\t  return doc;\n\t}\n\t\n\tfunction parseDocument(doc) {\n\t  var cacheKey = normalize(doc);\n\t\n\t  if (docCache[cacheKey]) {\n\t    return docCache[cacheKey];\n\t  }\n\t\n\t  var parsed = parse(doc);\n\t  if (!parsed || parsed.kind !== 'Document') {\n\t    throw new Error('Not a valid GraphQL document.');\n\t  }\n\t\n\t  // check that all \"new\" fragments inside the documents are consistent with\n\t  // existing fragments of the same name\n\t  parsed = processFragments(parsed);\n\t  parsed = stripLoc(parsed, false);\n\t  docCache[cacheKey] = parsed;\n\t\n\t  return parsed;\n\t}\n\t\n\t// XXX This should eventually disallow arbitrary string interpolation, like Relay does\n\tfunction gql(/* arguments */) {\n\t  var args = Array.prototype.slice.call(arguments);\n\t\n\t  var literals = args[0];\n\t\n\t  // We always get literals[0] and then matching post literals for each arg given\n\t  var result = (typeof(literals) === \"string\") ? literals : literals[0];\n\t\n\t  for (var i = 1; i < args.length; i++) {\n\t    if (args[i] && args[i].kind && args[i].kind === 'Document') {\n\t      result += args[i].loc.source.body;\n\t    } else {\n\t      result += args[i];\n\t    }\n\t\n\t    result += literals[i];\n\t  }\n\t\n\t  return parseDocument(result);\n\t}\n\t\n\t// Support typescript, which isn't as nice as Babel about default exports\n\tgql.default = gql;\n\tgql.resetCaches = resetCaches;\n\tgql.disableFragmentWarnings = disableFragmentWarnings;\n\t\n\tmodule.exports = gql;\n\t\n\t})));\n\t//# sourceMappingURL=graphql-tag.umd.js.map\n\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/error/GraphQLError.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.GraphQLError = GraphQLError;\n\t\n\tvar _location = __webpack_require__(\"./node_modules/graphql/language/location.js\");\n\t\n\t/**\n\t * A GraphQLError describes an Error found during the parse, validate, or\n\t * execute phases of performing a GraphQL operation. In addition to a message\n\t * and stack trace, it also includes information about the locations in a\n\t * GraphQL document and/or execution result that correspond to the Error.\n\t */\n\tfunction GraphQLError( // eslint-disable-line no-redeclare\n\tmessage, nodes, source, positions, path, originalError) {\n\t  // Compute locations in the source for the given nodes/positions.\n\t  var _source = source;\n\t  if (!_source && nodes && nodes.length > 0) {\n\t    var node = nodes[0];\n\t    _source = node && node.loc && node.loc.source;\n\t  }\n\t\n\t  var _positions = positions;\n\t  if (!_positions && nodes) {\n\t    _positions = nodes.filter(function (node) {\n\t      return Boolean(node.loc);\n\t    }).map(function (node) {\n\t      return node.loc.start;\n\t    });\n\t  }\n\t  if (_positions && _positions.length === 0) {\n\t    _positions = undefined;\n\t  }\n\t\n\t  var _locations = void 0;\n\t  var _source2 = _source; // seems here Flow need a const to resolve type.\n\t  if (_source2 && _positions) {\n\t    _locations = _positions.map(function (pos) {\n\t      return (0, _location.getLocation)(_source2, pos);\n\t    });\n\t  }\n\t\n\t  Object.defineProperties(this, {\n\t    message: {\n\t      value: message,\n\t      // By being enumerable, JSON.stringify will include `message` in the\n\t      // resulting output. This ensures that the simplest possible GraphQL\n\t      // service adheres to the spec.\n\t      enumerable: true,\n\t      writable: true\n\t    },\n\t    locations: {\n\t      // Coercing falsey values to undefined ensures they will not be included\n\t      // in JSON.stringify() when not provided.\n\t      value: _locations || undefined,\n\t      // By being enumerable, JSON.stringify will include `locations` in the\n\t      // resulting output. This ensures that the simplest possible GraphQL\n\t      // service adheres to the spec.\n\t      enumerable: true\n\t    },\n\t    path: {\n\t      // Coercing falsey values to undefined ensures they will not be included\n\t      // in JSON.stringify() when not provided.\n\t      value: path || undefined,\n\t      // By being enumerable, JSON.stringify will include `path` in the\n\t      // resulting output. This ensures that the simplest possible GraphQL\n\t      // service adheres to the spec.\n\t      enumerable: true\n\t    },\n\t    nodes: {\n\t      value: nodes || undefined\n\t    },\n\t    source: {\n\t      value: _source || undefined\n\t    },\n\t    positions: {\n\t      value: _positions || undefined\n\t    },\n\t    originalError: {\n\t      value: originalError\n\t    }\n\t  });\n\t\n\t  // Include (non-enumerable) stack trace.\n\t  if (originalError && originalError.stack) {\n\t    Object.defineProperty(this, 'stack', {\n\t      value: originalError.stack,\n\t      writable: true,\n\t      configurable: true\n\t    });\n\t  } else if (Error.captureStackTrace) {\n\t    Error.captureStackTrace(this, GraphQLError);\n\t  } else {\n\t    Object.defineProperty(this, 'stack', {\n\t      value: Error().stack,\n\t      writable: true,\n\t      configurable: true\n\t    });\n\t  }\n\t}\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\t\n\tGraphQLError.prototype = Object.create(Error.prototype, {\n\t  constructor: { value: GraphQLError },\n\t  name: { value: 'GraphQLError' }\n\t});\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/error/formatError.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.formatError = formatError;\n\t\n\tvar _invariant = __webpack_require__(\"./node_modules/graphql/jsutils/invariant.js\");\n\t\n\tvar _invariant2 = _interopRequireDefault(_invariant);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\t/**\n\t * Given a GraphQLError, format it according to the rules described by the\n\t * Response Format, Errors section of the GraphQL Specification.\n\t */\n\tfunction formatError(error) {\n\t  !error ? (0, _invariant2.default)(0, 'Received null or undefined error.') : void 0;\n\t  return {\n\t    message: error.message,\n\t    locations: error.locations,\n\t    path: error.path\n\t  };\n\t}\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/error/index.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\t\n\tvar _GraphQLError = __webpack_require__(\"./node_modules/graphql/error/GraphQLError.js\");\n\t\n\tObject.defineProperty(exports, 'GraphQLError', {\n\t  enumerable: true,\n\t  get: function get() {\n\t    return _GraphQLError.GraphQLError;\n\t  }\n\t});\n\t\n\tvar _syntaxError = __webpack_require__(\"./node_modules/graphql/error/syntaxError.js\");\n\t\n\tObject.defineProperty(exports, 'syntaxError', {\n\t  enumerable: true,\n\t  get: function get() {\n\t    return _syntaxError.syntaxError;\n\t  }\n\t});\n\t\n\tvar _locatedError = __webpack_require__(\"./node_modules/graphql/error/locatedError.js\");\n\t\n\tObject.defineProperty(exports, 'locatedError', {\n\t  enumerable: true,\n\t  get: function get() {\n\t    return _locatedError.locatedError;\n\t  }\n\t});\n\t\n\tvar _formatError = __webpack_require__(\"./node_modules/graphql/error/formatError.js\");\n\t\n\tObject.defineProperty(exports, 'formatError', {\n\t  enumerable: true,\n\t  get: function get() {\n\t    return _formatError.formatError;\n\t  }\n\t});\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/error/locatedError.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.locatedError = locatedError;\n\t\n\tvar _GraphQLError = __webpack_require__(\"./node_modules/graphql/error/GraphQLError.js\");\n\t\n\t/**\n\t * Given an arbitrary Error, presumably thrown while attempting to execute a\n\t * GraphQL operation, produce a new GraphQLError aware of the location in the\n\t * document responsible for the original Error.\n\t */\n\tfunction locatedError(originalError, nodes, path) {\n\t  // Note: this uses a brand-check to support GraphQL errors originating from\n\t  // other contexts.\n\t  if (originalError && originalError.path) {\n\t    return originalError;\n\t  }\n\t\n\t  var message = originalError ? originalError.message || String(originalError) : 'An unknown error occurred.';\n\t  return new _GraphQLError.GraphQLError(message, originalError && originalError.nodes || nodes, originalError && originalError.source, originalError && originalError.positions, path, originalError);\n\t}\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/error/syntaxError.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.syntaxError = syntaxError;\n\t\n\tvar _location = __webpack_require__(\"./node_modules/graphql/language/location.js\");\n\t\n\tvar _GraphQLError = __webpack_require__(\"./node_modules/graphql/error/GraphQLError.js\");\n\t\n\t/**\n\t * Produces a GraphQLError representing a syntax error, containing useful\n\t * descriptive information about the syntax error's position in the source.\n\t */\n\t\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\t\n\tfunction syntaxError(source, position, description) {\n\t  var location = (0, _location.getLocation)(source, position);\n\t  var line = location.line + source.locationOffset.line - 1;\n\t  var columnOffset = getColumnOffset(source, location);\n\t  var column = location.column + columnOffset;\n\t  var error = new _GraphQLError.GraphQLError('Syntax Error ' + source.name + ' (' + line + ':' + column + ') ' + description + '\\n\\n' + highlightSourceAtLocation(source, location), undefined, source, [position]);\n\t  return error;\n\t}\n\t\n\t/**\n\t * Render a helpful description of the location of the error in the GraphQL\n\t * Source document.\n\t */\n\tfunction highlightSourceAtLocation(source, location) {\n\t  var line = location.line;\n\t  var lineOffset = source.locationOffset.line - 1;\n\t  var columnOffset = getColumnOffset(source, location);\n\t  var contextLine = line + lineOffset;\n\t  var prevLineNum = (contextLine - 1).toString();\n\t  var lineNum = contextLine.toString();\n\t  var nextLineNum = (contextLine + 1).toString();\n\t  var padLen = nextLineNum.length;\n\t  var lines = source.body.split(/\\r\\n|[\\n\\r]/g);\n\t  lines[0] = whitespace(source.locationOffset.column - 1) + lines[0];\n\t  return (line >= 2 ? lpad(padLen, prevLineNum) + ': ' + lines[line - 2] + '\\n' : '') + lpad(padLen, lineNum) + ': ' + lines[line - 1] + '\\n' + whitespace(2 + padLen + location.column - 1 + columnOffset) + '^\\n' + (line < lines.length ? lpad(padLen, nextLineNum) + ': ' + lines[line] + '\\n' : '');\n\t}\n\t\n\tfunction getColumnOffset(source, location) {\n\t  return location.line === 1 ? source.locationOffset.column - 1 : 0;\n\t}\n\t\n\tfunction whitespace(len) {\n\t  return Array(len + 1).join(' ');\n\t}\n\t\n\tfunction lpad(len, str) {\n\t  return whitespace(len - str.length) + str;\n\t}\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/jsutils/invariant.js\":\n/***/ (function(module, exports) {\n\n\t\"use strict\";\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.default = invariant;\n\t\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\t\n\tfunction invariant(condition, message) {\n\t  if (!condition) {\n\t    throw new Error(message);\n\t  }\n\t}\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/language/kinds.js\":\n/***/ (function(module, exports) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\t\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\t\n\t// Name\n\t\n\tvar NAME = exports.NAME = 'Name';\n\t\n\t// Document\n\t\n\tvar DOCUMENT = exports.DOCUMENT = 'Document';\n\tvar OPERATION_DEFINITION = exports.OPERATION_DEFINITION = 'OperationDefinition';\n\tvar VARIABLE_DEFINITION = exports.VARIABLE_DEFINITION = 'VariableDefinition';\n\tvar VARIABLE = exports.VARIABLE = 'Variable';\n\tvar SELECTION_SET = exports.SELECTION_SET = 'SelectionSet';\n\tvar FIELD = exports.FIELD = 'Field';\n\tvar ARGUMENT = exports.ARGUMENT = 'Argument';\n\t\n\t// Fragments\n\t\n\tvar FRAGMENT_SPREAD = exports.FRAGMENT_SPREAD = 'FragmentSpread';\n\tvar INLINE_FRAGMENT = exports.INLINE_FRAGMENT = 'InlineFragment';\n\tvar FRAGMENT_DEFINITION = exports.FRAGMENT_DEFINITION = 'FragmentDefinition';\n\t\n\t// Values\n\t\n\tvar INT = exports.INT = 'IntValue';\n\tvar FLOAT = exports.FLOAT = 'FloatValue';\n\tvar STRING = exports.STRING = 'StringValue';\n\tvar BOOLEAN = exports.BOOLEAN = 'BooleanValue';\n\tvar NULL = exports.NULL = 'NullValue';\n\tvar ENUM = exports.ENUM = 'EnumValue';\n\tvar LIST = exports.LIST = 'ListValue';\n\tvar OBJECT = exports.OBJECT = 'ObjectValue';\n\tvar OBJECT_FIELD = exports.OBJECT_FIELD = 'ObjectField';\n\t\n\t// Directives\n\t\n\tvar DIRECTIVE = exports.DIRECTIVE = 'Directive';\n\t\n\t// Types\n\t\n\tvar NAMED_TYPE = exports.NAMED_TYPE = 'NamedType';\n\tvar LIST_TYPE = exports.LIST_TYPE = 'ListType';\n\tvar NON_NULL_TYPE = exports.NON_NULL_TYPE = 'NonNullType';\n\t\n\t// Type System Definitions\n\t\n\tvar SCHEMA_DEFINITION = exports.SCHEMA_DEFINITION = 'SchemaDefinition';\n\tvar OPERATION_TYPE_DEFINITION = exports.OPERATION_TYPE_DEFINITION = 'OperationTypeDefinition';\n\t\n\t// Type Definitions\n\t\n\tvar SCALAR_TYPE_DEFINITION = exports.SCALAR_TYPE_DEFINITION = 'ScalarTypeDefinition';\n\tvar OBJECT_TYPE_DEFINITION = exports.OBJECT_TYPE_DEFINITION = 'ObjectTypeDefinition';\n\tvar FIELD_DEFINITION = exports.FIELD_DEFINITION = 'FieldDefinition';\n\tvar INPUT_VALUE_DEFINITION = exports.INPUT_VALUE_DEFINITION = 'InputValueDefinition';\n\tvar INTERFACE_TYPE_DEFINITION = exports.INTERFACE_TYPE_DEFINITION = 'InterfaceTypeDefinition';\n\tvar UNION_TYPE_DEFINITION = exports.UNION_TYPE_DEFINITION = 'UnionTypeDefinition';\n\tvar ENUM_TYPE_DEFINITION = exports.ENUM_TYPE_DEFINITION = 'EnumTypeDefinition';\n\tvar ENUM_VALUE_DEFINITION = exports.ENUM_VALUE_DEFINITION = 'EnumValueDefinition';\n\tvar INPUT_OBJECT_TYPE_DEFINITION = exports.INPUT_OBJECT_TYPE_DEFINITION = 'InputObjectTypeDefinition';\n\t\n\t// Type Extensions\n\t\n\tvar TYPE_EXTENSION_DEFINITION = exports.TYPE_EXTENSION_DEFINITION = 'TypeExtensionDefinition';\n\t\n\t// Directive Definitions\n\t\n\tvar DIRECTIVE_DEFINITION = exports.DIRECTIVE_DEFINITION = 'DirectiveDefinition';\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/language/lexer.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.TokenKind = undefined;\n\texports.createLexer = createLexer;\n\texports.getTokenDesc = getTokenDesc;\n\t\n\tvar _error = __webpack_require__(\"./node_modules/graphql/error/index.js\");\n\t\n\t/**\n\t * Given a Source object, this returns a Lexer for that source.\n\t * A Lexer is a stateful stream generator in that every time\n\t * it is advanced, it returns the next token in the Source. Assuming the\n\t * source lexes, the final Token emitted by the lexer will be of kind\n\t * EOF, after which the lexer will repeatedly return the same EOF token\n\t * whenever called.\n\t */\n\tfunction createLexer(source, options) {\n\t  var startOfFileToken = new Tok(SOF, 0, 0, 0, 0, null);\n\t  var lexer = {\n\t    source: source,\n\t    options: options,\n\t    lastToken: startOfFileToken,\n\t    token: startOfFileToken,\n\t    line: 1,\n\t    lineStart: 0,\n\t    advance: advanceLexer\n\t  };\n\t  return lexer;\n\t} /*  /\n\t  /**\n\t   *  Copyright (c) 2015, Facebook, Inc.\n\t   *  All rights reserved.\n\t   *\n\t   *  This source code is licensed under the BSD-style license found in the\n\t   *  LICENSE file in the root directory of this source tree. An additional grant\n\t   *  of patent rights can be found in the PATENTS file in the same directory.\n\t   */\n\t\n\tfunction advanceLexer() {\n\t  var token = this.lastToken = this.token;\n\t  if (token.kind !== EOF) {\n\t    do {\n\t      token = token.next = readToken(this, token);\n\t    } while (token.kind === COMMENT);\n\t    this.token = token;\n\t  }\n\t  return token;\n\t}\n\t\n\t/**\n\t * The return type of createLexer.\n\t */\n\t\n\t\n\t// Each kind of token.\n\tvar SOF = '<SOF>';\n\tvar EOF = '<EOF>';\n\tvar BANG = '!';\n\tvar DOLLAR = '$';\n\tvar PAREN_L = '(';\n\tvar PAREN_R = ')';\n\tvar SPREAD = '...';\n\tvar COLON = ':';\n\tvar EQUALS = '=';\n\tvar AT = '@';\n\tvar BRACKET_L = '[';\n\tvar BRACKET_R = ']';\n\tvar BRACE_L = '{';\n\tvar PIPE = '|';\n\tvar BRACE_R = '}';\n\tvar NAME = 'Name';\n\tvar INT = 'Int';\n\tvar FLOAT = 'Float';\n\tvar STRING = 'String';\n\tvar COMMENT = 'Comment';\n\t\n\t/**\n\t * An exported enum describing the different kinds of tokens that the\n\t * lexer emits.\n\t */\n\tvar TokenKind = exports.TokenKind = {\n\t  SOF: SOF,\n\t  EOF: EOF,\n\t  BANG: BANG,\n\t  DOLLAR: DOLLAR,\n\t  PAREN_L: PAREN_L,\n\t  PAREN_R: PAREN_R,\n\t  SPREAD: SPREAD,\n\t  COLON: COLON,\n\t  EQUALS: EQUALS,\n\t  AT: AT,\n\t  BRACKET_L: BRACKET_L,\n\t  BRACKET_R: BRACKET_R,\n\t  BRACE_L: BRACE_L,\n\t  PIPE: PIPE,\n\t  BRACE_R: BRACE_R,\n\t  NAME: NAME,\n\t  INT: INT,\n\t  FLOAT: FLOAT,\n\t  STRING: STRING,\n\t  COMMENT: COMMENT\n\t};\n\t\n\t/**\n\t * A helper function to describe a token as a string for debugging\n\t */\n\tfunction getTokenDesc(token) {\n\t  var value = token.value;\n\t  return value ? token.kind + ' \"' + value + '\"' : token.kind;\n\t}\n\t\n\tvar charCodeAt = String.prototype.charCodeAt;\n\tvar slice = String.prototype.slice;\n\t\n\t/**\n\t * Helper function for constructing the Token object.\n\t */\n\tfunction Tok(kind, start, end, line, column, prev, value) {\n\t  this.kind = kind;\n\t  this.start = start;\n\t  this.end = end;\n\t  this.line = line;\n\t  this.column = column;\n\t  this.value = value;\n\t  this.prev = prev;\n\t  this.next = null;\n\t}\n\t\n\t// Print a simplified form when appearing in JSON/util.inspect.\n\tTok.prototype.toJSON = Tok.prototype.inspect = function toJSON() {\n\t  return {\n\t    kind: this.kind,\n\t    value: this.value,\n\t    line: this.line,\n\t    column: this.column\n\t  };\n\t};\n\t\n\tfunction printCharCode(code) {\n\t  return (\n\t    // NaN/undefined represents access beyond the end of the file.\n\t    isNaN(code) ? EOF :\n\t    // Trust JSON for ASCII.\n\t    code < 0x007F ? JSON.stringify(String.fromCharCode(code)) :\n\t    // Otherwise print the escaped form.\n\t    '\"\\\\u' + ('00' + code.toString(16).toUpperCase()).slice(-4) + '\"'\n\t  );\n\t}\n\t\n\t/**\n\t * Gets the next token from the source starting at the given position.\n\t *\n\t * This skips over whitespace and comments until it finds the next lexable\n\t * token, then lexes punctuators immediately or calls the appropriate helper\n\t * function for more complicated tokens.\n\t */\n\tfunction readToken(lexer, prev) {\n\t  var source = lexer.source;\n\t  var body = source.body;\n\t  var bodyLength = body.length;\n\t\n\t  var position = positionAfterWhitespace(body, prev.end, lexer);\n\t  var line = lexer.line;\n\t  var col = 1 + position - lexer.lineStart;\n\t\n\t  if (position >= bodyLength) {\n\t    return new Tok(EOF, bodyLength, bodyLength, line, col, prev);\n\t  }\n\t\n\t  var code = charCodeAt.call(body, position);\n\t\n\t  // SourceCharacter\n\t  if (code < 0x0020 && code !== 0x0009 && code !== 0x000A && code !== 0x000D) {\n\t    throw (0, _error.syntaxError)(source, position, 'Cannot contain the invalid character ' + printCharCode(code) + '.');\n\t  }\n\t\n\t  switch (code) {\n\t    // !\n\t    case 33:\n\t      return new Tok(BANG, position, position + 1, line, col, prev);\n\t    // #\n\t    case 35:\n\t      return readComment(source, position, line, col, prev);\n\t    // $\n\t    case 36:\n\t      return new Tok(DOLLAR, position, position + 1, line, col, prev);\n\t    // (\n\t    case 40:\n\t      return new Tok(PAREN_L, position, position + 1, line, col, prev);\n\t    // )\n\t    case 41:\n\t      return new Tok(PAREN_R, position, position + 1, line, col, prev);\n\t    // .\n\t    case 46:\n\t      if (charCodeAt.call(body, position + 1) === 46 && charCodeAt.call(body, position + 2) === 46) {\n\t        return new Tok(SPREAD, position, position + 3, line, col, prev);\n\t      }\n\t      break;\n\t    // :\n\t    case 58:\n\t      return new Tok(COLON, position, position + 1, line, col, prev);\n\t    // =\n\t    case 61:\n\t      return new Tok(EQUALS, position, position + 1, line, col, prev);\n\t    // @\n\t    case 64:\n\t      return new Tok(AT, position, position + 1, line, col, prev);\n\t    // [\n\t    case 91:\n\t      return new Tok(BRACKET_L, position, position + 1, line, col, prev);\n\t    // ]\n\t    case 93:\n\t      return new Tok(BRACKET_R, position, position + 1, line, col, prev);\n\t    // {\n\t    case 123:\n\t      return new Tok(BRACE_L, position, position + 1, line, col, prev);\n\t    // |\n\t    case 124:\n\t      return new Tok(PIPE, position, position + 1, line, col, prev);\n\t    // }\n\t    case 125:\n\t      return new Tok(BRACE_R, position, position + 1, line, col, prev);\n\t    // A-Z _ a-z\n\t    case 65:case 66:case 67:case 68:case 69:case 70:case 71:case 72:\n\t    case 73:case 74:case 75:case 76:case 77:case 78:case 79:case 80:\n\t    case 81:case 82:case 83:case 84:case 85:case 86:case 87:case 88:\n\t    case 89:case 90:\n\t    case 95:\n\t    case 97:case 98:case 99:case 100:case 101:case 102:case 103:case 104:\n\t    case 105:case 106:case 107:case 108:case 109:case 110:case 111:\n\t    case 112:case 113:case 114:case 115:case 116:case 117:case 118:\n\t    case 119:case 120:case 121:case 122:\n\t      return readName(source, position, line, col, prev);\n\t    // - 0-9\n\t    case 45:\n\t    case 48:case 49:case 50:case 51:case 52:\n\t    case 53:case 54:case 55:case 56:case 57:\n\t      return readNumber(source, position, code, line, col, prev);\n\t    // \"\n\t    case 34:\n\t      return readString(source, position, line, col, prev);\n\t  }\n\t\n\t  throw (0, _error.syntaxError)(source, position, unexpectedCharacterMessage(code));\n\t}\n\t\n\t/**\n\t * Report a message that an unexpected character was encountered.\n\t */\n\tfunction unexpectedCharacterMessage(code) {\n\t  if (code === 39) {\n\t    // '\n\t    return 'Unexpected single quote character (\\'), did you mean to use ' + 'a double quote (\")?';\n\t  }\n\t\n\t  return 'Cannot parse the unexpected character ' + printCharCode(code) + '.';\n\t}\n\t\n\t/**\n\t * Reads from body starting at startPosition until it finds a non-whitespace\n\t * or commented character, then returns the position of that character for\n\t * lexing.\n\t */\n\tfunction positionAfterWhitespace(body, startPosition, lexer) {\n\t  var bodyLength = body.length;\n\t  var position = startPosition;\n\t  while (position < bodyLength) {\n\t    var code = charCodeAt.call(body, position);\n\t    // tab | space | comma | BOM\n\t    if (code === 9 || code === 32 || code === 44 || code === 0xFEFF) {\n\t      ++position;\n\t    } else if (code === 10) {\n\t      // new line\n\t      ++position;\n\t      ++lexer.line;\n\t      lexer.lineStart = position;\n\t    } else if (code === 13) {\n\t      // carriage return\n\t      if (charCodeAt.call(body, position + 1) === 10) {\n\t        position += 2;\n\t      } else {\n\t        ++position;\n\t      }\n\t      ++lexer.line;\n\t      lexer.lineStart = position;\n\t    } else {\n\t      break;\n\t    }\n\t  }\n\t  return position;\n\t}\n\t\n\t/**\n\t * Reads a comment token from the source file.\n\t *\n\t * #[\\u0009\\u0020-\\uFFFF]*\n\t */\n\tfunction readComment(source, start, line, col, prev) {\n\t  var body = source.body;\n\t  var code = void 0;\n\t  var position = start;\n\t\n\t  do {\n\t    code = charCodeAt.call(body, ++position);\n\t  } while (code !== null && (\n\t  // SourceCharacter but not LineTerminator\n\t  code > 0x001F || code === 0x0009));\n\t\n\t  return new Tok(COMMENT, start, position, line, col, prev, slice.call(body, start + 1, position));\n\t}\n\t\n\t/**\n\t * Reads a number token from the source file, either a float\n\t * or an int depending on whether a decimal point appears.\n\t *\n\t * Int:   -?(0|[1-9][0-9]*)\n\t * Float: -?(0|[1-9][0-9]*)(\\.[0-9]+)?((E|e)(+|-)?[0-9]+)?\n\t */\n\tfunction readNumber(source, start, firstCode, line, col, prev) {\n\t  var body = source.body;\n\t  var code = firstCode;\n\t  var position = start;\n\t  var isFloat = false;\n\t\n\t  if (code === 45) {\n\t    // -\n\t    code = charCodeAt.call(body, ++position);\n\t  }\n\t\n\t  if (code === 48) {\n\t    // 0\n\t    code = charCodeAt.call(body, ++position);\n\t    if (code >= 48 && code <= 57) {\n\t      throw (0, _error.syntaxError)(source, position, 'Invalid number, unexpected digit after 0: ' + printCharCode(code) + '.');\n\t    }\n\t  } else {\n\t    position = readDigits(source, position, code);\n\t    code = charCodeAt.call(body, position);\n\t  }\n\t\n\t  if (code === 46) {\n\t    // .\n\t    isFloat = true;\n\t\n\t    code = charCodeAt.call(body, ++position);\n\t    position = readDigits(source, position, code);\n\t    code = charCodeAt.call(body, position);\n\t  }\n\t\n\t  if (code === 69 || code === 101) {\n\t    // E e\n\t    isFloat = true;\n\t\n\t    code = charCodeAt.call(body, ++position);\n\t    if (code === 43 || code === 45) {\n\t      // + -\n\t      code = charCodeAt.call(body, ++position);\n\t    }\n\t    position = readDigits(source, position, code);\n\t  }\n\t\n\t  return new Tok(isFloat ? FLOAT : INT, start, position, line, col, prev, slice.call(body, start, position));\n\t}\n\t\n\t/**\n\t * Returns the new position in the source after reading digits.\n\t */\n\tfunction readDigits(source, start, firstCode) {\n\t  var body = source.body;\n\t  var position = start;\n\t  var code = firstCode;\n\t  if (code >= 48 && code <= 57) {\n\t    // 0 - 9\n\t    do {\n\t      code = charCodeAt.call(body, ++position);\n\t    } while (code >= 48 && code <= 57); // 0 - 9\n\t    return position;\n\t  }\n\t  throw (0, _error.syntaxError)(source, position, 'Invalid number, expected digit but got: ' + printCharCode(code) + '.');\n\t}\n\t\n\t/**\n\t * Reads a string token from the source file.\n\t *\n\t * \"([^\"\\\\\\u000A\\u000D]|(\\\\(u[0-9a-fA-F]{4}|[\"\\\\/bfnrt])))*\"\n\t */\n\tfunction readString(source, start, line, col, prev) {\n\t  var body = source.body;\n\t  var position = start + 1;\n\t  var chunkStart = position;\n\t  var code = 0;\n\t  var value = '';\n\t\n\t  while (position < body.length && (code = charCodeAt.call(body, position)) !== null &&\n\t  // not LineTerminator\n\t  code !== 0x000A && code !== 0x000D &&\n\t  // not Quote (\")\n\t  code !== 34) {\n\t    // SourceCharacter\n\t    if (code < 0x0020 && code !== 0x0009) {\n\t      throw (0, _error.syntaxError)(source, position, 'Invalid character within String: ' + printCharCode(code) + '.');\n\t    }\n\t\n\t    ++position;\n\t    if (code === 92) {\n\t      // \\\n\t      value += slice.call(body, chunkStart, position - 1);\n\t      code = charCodeAt.call(body, position);\n\t      switch (code) {\n\t        case 34:\n\t          value += '\"';break;\n\t        case 47:\n\t          value += '/';break;\n\t        case 92:\n\t          value += '\\\\';break;\n\t        case 98:\n\t          value += '\\b';break;\n\t        case 102:\n\t          value += '\\f';break;\n\t        case 110:\n\t          value += '\\n';break;\n\t        case 114:\n\t          value += '\\r';break;\n\t        case 116:\n\t          value += '\\t';break;\n\t        case 117:\n\t          // u\n\t          var charCode = uniCharCode(charCodeAt.call(body, position + 1), charCodeAt.call(body, position + 2), charCodeAt.call(body, position + 3), charCodeAt.call(body, position + 4));\n\t          if (charCode < 0) {\n\t            throw (0, _error.syntaxError)(source, position, 'Invalid character escape sequence: ' + ('\\\\u' + body.slice(position + 1, position + 5) + '.'));\n\t          }\n\t          value += String.fromCharCode(charCode);\n\t          position += 4;\n\t          break;\n\t        default:\n\t          throw (0, _error.syntaxError)(source, position, 'Invalid character escape sequence: \\\\' + String.fromCharCode(code) + '.');\n\t      }\n\t      ++position;\n\t      chunkStart = position;\n\t    }\n\t  }\n\t\n\t  if (code !== 34) {\n\t    // quote (\")\n\t    throw (0, _error.syntaxError)(source, position, 'Unterminated string.');\n\t  }\n\t\n\t  value += slice.call(body, chunkStart, position);\n\t  return new Tok(STRING, start, position + 1, line, col, prev, value);\n\t}\n\t\n\t/**\n\t * Converts four hexidecimal chars to the integer that the\n\t * string represents. For example, uniCharCode('0','0','0','f')\n\t * will return 15, and uniCharCode('0','0','f','f') returns 255.\n\t *\n\t * Returns a negative number on error, if a char was invalid.\n\t *\n\t * This is implemented by noting that char2hex() returns -1 on error,\n\t * which means the result of ORing the char2hex() will also be negative.\n\t */\n\tfunction uniCharCode(a, b, c, d) {\n\t  return char2hex(a) << 12 | char2hex(b) << 8 | char2hex(c) << 4 | char2hex(d);\n\t}\n\t\n\t/**\n\t * Converts a hex character to its integer value.\n\t * '0' becomes 0, '9' becomes 9\n\t * 'A' becomes 10, 'F' becomes 15\n\t * 'a' becomes 10, 'f' becomes 15\n\t *\n\t * Returns -1 on error.\n\t */\n\tfunction char2hex(a) {\n\t  return a >= 48 && a <= 57 ? a - 48 : // 0-9\n\t  a >= 65 && a <= 70 ? a - 55 : // A-F\n\t  a >= 97 && a <= 102 ? a - 87 : // a-f\n\t  -1;\n\t}\n\t\n\t/**\n\t * Reads an alphanumeric + underscore name from the source.\n\t *\n\t * [_A-Za-z][_0-9A-Za-z]*\n\t */\n\tfunction readName(source, position, line, col, prev) {\n\t  var body = source.body;\n\t  var bodyLength = body.length;\n\t  var end = position + 1;\n\t  var code = 0;\n\t  while (end !== bodyLength && (code = charCodeAt.call(body, end)) !== null && (code === 95 || // _\n\t  code >= 48 && code <= 57 || // 0-9\n\t  code >= 65 && code <= 90 || // A-Z\n\t  code >= 97 && code <= 122 // a-z\n\t  )) {\n\t    ++end;\n\t  }\n\t  return new Tok(NAME, position, end, line, col, prev, slice.call(body, position, end));\n\t}\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/language/location.js\":\n/***/ (function(module, exports) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.getLocation = getLocation;\n\t\n\t\n\t/**\n\t * Takes a Source and a UTF-8 character offset, and returns the corresponding\n\t * line and column as a SourceLocation.\n\t */\n\t\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\t\n\tfunction getLocation(source, position) {\n\t  var lineRegexp = /\\r\\n|[\\n\\r]/g;\n\t  var line = 1;\n\t  var column = position + 1;\n\t  var match = void 0;\n\t  while ((match = lineRegexp.exec(source.body)) && match.index < position) {\n\t    line += 1;\n\t    column = position + 1 - (match.index + match[0].length);\n\t  }\n\t  return { line: line, column: column };\n\t}\n\t\n\t/**\n\t * Represents a location in a Source.\n\t */\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/language/parser.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.parse = parse;\n\texports.parseValue = parseValue;\n\texports.parseType = parseType;\n\texports.parseConstValue = parseConstValue;\n\texports.parseTypeReference = parseTypeReference;\n\texports.parseNamedType = parseNamedType;\n\t\n\tvar _source = __webpack_require__(\"./node_modules/graphql/language/source.js\");\n\t\n\tvar _error = __webpack_require__(\"./node_modules/graphql/error/index.js\");\n\t\n\tvar _lexer = __webpack_require__(\"./node_modules/graphql/language/lexer.js\");\n\t\n\tvar _kinds = __webpack_require__(\"./node_modules/graphql/language/kinds.js\");\n\t\n\t/**\n\t * Given a GraphQL source, parses it into a Document.\n\t * Throws GraphQLError if a syntax error is encountered.\n\t */\n\t\n\t\n\t/**\n\t * Configuration options to control parser behavior\n\t */\n\t\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\t\n\tfunction parse(source, options) {\n\t  var sourceObj = typeof source === 'string' ? new _source.Source(source) : source;\n\t  if (!(sourceObj instanceof _source.Source)) {\n\t    throw new TypeError('Must provide Source. Received: ' + String(sourceObj));\n\t  }\n\t  var lexer = (0, _lexer.createLexer)(sourceObj, options || {});\n\t  return parseDocument(lexer);\n\t}\n\t\n\t/**\n\t * Given a string containing a GraphQL value (ex. `[42]`), parse the AST for\n\t * that value.\n\t * Throws GraphQLError if a syntax error is encountered.\n\t *\n\t * This is useful within tools that operate upon GraphQL Values directly and\n\t * in isolation of complete GraphQL documents.\n\t *\n\t * Consider providing the results to the utility function: valueFromAST().\n\t */\n\tfunction parseValue(source, options) {\n\t  var sourceObj = typeof source === 'string' ? new _source.Source(source) : source;\n\t  var lexer = (0, _lexer.createLexer)(sourceObj, options || {});\n\t  expect(lexer, _lexer.TokenKind.SOF);\n\t  var value = parseValueLiteral(lexer, false);\n\t  expect(lexer, _lexer.TokenKind.EOF);\n\t  return value;\n\t}\n\t\n\t/**\n\t * Given a string containing a GraphQL Type (ex. `[Int!]`), parse the AST for\n\t * that type.\n\t * Throws GraphQLError if a syntax error is encountered.\n\t *\n\t * This is useful within tools that operate upon GraphQL Types directly and\n\t * in isolation of complete GraphQL documents.\n\t *\n\t * Consider providing the results to the utility function: typeFromAST().\n\t */\n\tfunction parseType(source, options) {\n\t  var sourceObj = typeof source === 'string' ? new _source.Source(source) : source;\n\t  var lexer = (0, _lexer.createLexer)(sourceObj, options || {});\n\t  expect(lexer, _lexer.TokenKind.SOF);\n\t  var type = parseTypeReference(lexer);\n\t  expect(lexer, _lexer.TokenKind.EOF);\n\t  return type;\n\t}\n\t\n\t/**\n\t * Converts a name lex token into a name parse node.\n\t */\n\tfunction parseName(lexer) {\n\t  var token = expect(lexer, _lexer.TokenKind.NAME);\n\t  return {\n\t    kind: _kinds.NAME,\n\t    value: token.value,\n\t    loc: loc(lexer, token)\n\t  };\n\t}\n\t\n\t// Implements the parsing rules in the Document section.\n\t\n\t/**\n\t * Document : Definition+\n\t */\n\tfunction parseDocument(lexer) {\n\t  var start = lexer.token;\n\t  expect(lexer, _lexer.TokenKind.SOF);\n\t  var definitions = [];\n\t  do {\n\t    definitions.push(parseDefinition(lexer));\n\t  } while (!skip(lexer, _lexer.TokenKind.EOF));\n\t\n\t  return {\n\t    kind: _kinds.DOCUMENT,\n\t    definitions: definitions,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * Definition :\n\t *   - OperationDefinition\n\t *   - FragmentDefinition\n\t *   - TypeSystemDefinition\n\t */\n\tfunction parseDefinition(lexer) {\n\t  if (peek(lexer, _lexer.TokenKind.BRACE_L)) {\n\t    return parseOperationDefinition(lexer);\n\t  }\n\t\n\t  if (peek(lexer, _lexer.TokenKind.NAME)) {\n\t    switch (lexer.token.value) {\n\t      // Note: subscription is an experimental non-spec addition.\n\t      case 'query':\n\t      case 'mutation':\n\t      case 'subscription':\n\t        return parseOperationDefinition(lexer);\n\t\n\t      case 'fragment':\n\t        return parseFragmentDefinition(lexer);\n\t\n\t      // Note: the Type System IDL is an experimental non-spec addition.\n\t      case 'schema':\n\t      case 'scalar':\n\t      case 'type':\n\t      case 'interface':\n\t      case 'union':\n\t      case 'enum':\n\t      case 'input':\n\t      case 'extend':\n\t      case 'directive':\n\t        return parseTypeSystemDefinition(lexer);\n\t    }\n\t  }\n\t\n\t  throw unexpected(lexer);\n\t}\n\t\n\t// Implements the parsing rules in the Operations section.\n\t\n\t/**\n\t * OperationDefinition :\n\t *  - SelectionSet\n\t *  - OperationType Name? VariableDefinitions? Directives? SelectionSet\n\t */\n\tfunction parseOperationDefinition(lexer) {\n\t  var start = lexer.token;\n\t  if (peek(lexer, _lexer.TokenKind.BRACE_L)) {\n\t    return {\n\t      kind: _kinds.OPERATION_DEFINITION,\n\t      operation: 'query',\n\t      name: null,\n\t      variableDefinitions: null,\n\t      directives: [],\n\t      selectionSet: parseSelectionSet(lexer),\n\t      loc: loc(lexer, start)\n\t    };\n\t  }\n\t  var operation = parseOperationType(lexer);\n\t  var name = void 0;\n\t  if (peek(lexer, _lexer.TokenKind.NAME)) {\n\t    name = parseName(lexer);\n\t  }\n\t  return {\n\t    kind: _kinds.OPERATION_DEFINITION,\n\t    operation: operation,\n\t    name: name,\n\t    variableDefinitions: parseVariableDefinitions(lexer),\n\t    directives: parseDirectives(lexer),\n\t    selectionSet: parseSelectionSet(lexer),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * OperationType : one of query mutation subscription\n\t */\n\tfunction parseOperationType(lexer) {\n\t  var operationToken = expect(lexer, _lexer.TokenKind.NAME);\n\t  switch (operationToken.value) {\n\t    case 'query':\n\t      return 'query';\n\t    case 'mutation':\n\t      return 'mutation';\n\t    // Note: subscription is an experimental non-spec addition.\n\t    case 'subscription':\n\t      return 'subscription';\n\t  }\n\t\n\t  throw unexpected(lexer, operationToken);\n\t}\n\t\n\t/**\n\t * VariableDefinitions : ( VariableDefinition+ )\n\t */\n\tfunction parseVariableDefinitions(lexer) {\n\t  return peek(lexer, _lexer.TokenKind.PAREN_L) ? many(lexer, _lexer.TokenKind.PAREN_L, parseVariableDefinition, _lexer.TokenKind.PAREN_R) : [];\n\t}\n\t\n\t/**\n\t * VariableDefinition : Variable : Type DefaultValue?\n\t */\n\tfunction parseVariableDefinition(lexer) {\n\t  var start = lexer.token;\n\t  return {\n\t    kind: _kinds.VARIABLE_DEFINITION,\n\t    variable: parseVariable(lexer),\n\t    type: (expect(lexer, _lexer.TokenKind.COLON), parseTypeReference(lexer)),\n\t    defaultValue: skip(lexer, _lexer.TokenKind.EQUALS) ? parseValueLiteral(lexer, true) : null,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * Variable : $ Name\n\t */\n\tfunction parseVariable(lexer) {\n\t  var start = lexer.token;\n\t  expect(lexer, _lexer.TokenKind.DOLLAR);\n\t  return {\n\t    kind: _kinds.VARIABLE,\n\t    name: parseName(lexer),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * SelectionSet : { Selection+ }\n\t */\n\tfunction parseSelectionSet(lexer) {\n\t  var start = lexer.token;\n\t  return {\n\t    kind: _kinds.SELECTION_SET,\n\t    selections: many(lexer, _lexer.TokenKind.BRACE_L, parseSelection, _lexer.TokenKind.BRACE_R),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * Selection :\n\t *   - Field\n\t *   - FragmentSpread\n\t *   - InlineFragment\n\t */\n\tfunction parseSelection(lexer) {\n\t  return peek(lexer, _lexer.TokenKind.SPREAD) ? parseFragment(lexer) : parseField(lexer);\n\t}\n\t\n\t/**\n\t * Field : Alias? Name Arguments? Directives? SelectionSet?\n\t *\n\t * Alias : Name :\n\t */\n\tfunction parseField(lexer) {\n\t  var start = lexer.token;\n\t\n\t  var nameOrAlias = parseName(lexer);\n\t  var alias = void 0;\n\t  var name = void 0;\n\t  if (skip(lexer, _lexer.TokenKind.COLON)) {\n\t    alias = nameOrAlias;\n\t    name = parseName(lexer);\n\t  } else {\n\t    alias = null;\n\t    name = nameOrAlias;\n\t  }\n\t\n\t  return {\n\t    kind: _kinds.FIELD,\n\t    alias: alias,\n\t    name: name,\n\t    arguments: parseArguments(lexer),\n\t    directives: parseDirectives(lexer),\n\t    selectionSet: peek(lexer, _lexer.TokenKind.BRACE_L) ? parseSelectionSet(lexer) : null,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * Arguments : ( Argument+ )\n\t */\n\tfunction parseArguments(lexer) {\n\t  return peek(lexer, _lexer.TokenKind.PAREN_L) ? many(lexer, _lexer.TokenKind.PAREN_L, parseArgument, _lexer.TokenKind.PAREN_R) : [];\n\t}\n\t\n\t/**\n\t * Argument : Name : Value\n\t */\n\tfunction parseArgument(lexer) {\n\t  var start = lexer.token;\n\t  return {\n\t    kind: _kinds.ARGUMENT,\n\t    name: parseName(lexer),\n\t    value: (expect(lexer, _lexer.TokenKind.COLON), parseValueLiteral(lexer, false)),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t// Implements the parsing rules in the Fragments section.\n\t\n\t/**\n\t * Corresponds to both FragmentSpread and InlineFragment in the spec.\n\t *\n\t * FragmentSpread : ... FragmentName Directives?\n\t *\n\t * InlineFragment : ... TypeCondition? Directives? SelectionSet\n\t */\n\tfunction parseFragment(lexer) {\n\t  var start = lexer.token;\n\t  expect(lexer, _lexer.TokenKind.SPREAD);\n\t  if (peek(lexer, _lexer.TokenKind.NAME) && lexer.token.value !== 'on') {\n\t    return {\n\t      kind: _kinds.FRAGMENT_SPREAD,\n\t      name: parseFragmentName(lexer),\n\t      directives: parseDirectives(lexer),\n\t      loc: loc(lexer, start)\n\t    };\n\t  }\n\t  var typeCondition = null;\n\t  if (lexer.token.value === 'on') {\n\t    lexer.advance();\n\t    typeCondition = parseNamedType(lexer);\n\t  }\n\t  return {\n\t    kind: _kinds.INLINE_FRAGMENT,\n\t    typeCondition: typeCondition,\n\t    directives: parseDirectives(lexer),\n\t    selectionSet: parseSelectionSet(lexer),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * FragmentDefinition :\n\t *   - fragment FragmentName on TypeCondition Directives? SelectionSet\n\t *\n\t * TypeCondition : NamedType\n\t */\n\tfunction parseFragmentDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'fragment');\n\t  return {\n\t    kind: _kinds.FRAGMENT_DEFINITION,\n\t    name: parseFragmentName(lexer),\n\t    typeCondition: (expectKeyword(lexer, 'on'), parseNamedType(lexer)),\n\t    directives: parseDirectives(lexer),\n\t    selectionSet: parseSelectionSet(lexer),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * FragmentName : Name but not `on`\n\t */\n\tfunction parseFragmentName(lexer) {\n\t  if (lexer.token.value === 'on') {\n\t    throw unexpected(lexer);\n\t  }\n\t  return parseName(lexer);\n\t}\n\t\n\t// Implements the parsing rules in the Values section.\n\t\n\t/**\n\t * Value[Const] :\n\t *   - [~Const] Variable\n\t *   - IntValue\n\t *   - FloatValue\n\t *   - StringValue\n\t *   - BooleanValue\n\t *   - NullValue\n\t *   - EnumValue\n\t *   - ListValue[?Const]\n\t *   - ObjectValue[?Const]\n\t *\n\t * BooleanValue : one of `true` `false`\n\t *\n\t * NullValue : `null`\n\t *\n\t * EnumValue : Name but not `true`, `false` or `null`\n\t */\n\tfunction parseValueLiteral(lexer, isConst) {\n\t  var token = lexer.token;\n\t  switch (token.kind) {\n\t    case _lexer.TokenKind.BRACKET_L:\n\t      return parseList(lexer, isConst);\n\t    case _lexer.TokenKind.BRACE_L:\n\t      return parseObject(lexer, isConst);\n\t    case _lexer.TokenKind.INT:\n\t      lexer.advance();\n\t      return {\n\t        kind: _kinds.INT,\n\t        value: token.value,\n\t        loc: loc(lexer, token)\n\t      };\n\t    case _lexer.TokenKind.FLOAT:\n\t      lexer.advance();\n\t      return {\n\t        kind: _kinds.FLOAT,\n\t        value: token.value,\n\t        loc: loc(lexer, token)\n\t      };\n\t    case _lexer.TokenKind.STRING:\n\t      lexer.advance();\n\t      return {\n\t        kind: _kinds.STRING,\n\t        value: token.value,\n\t        loc: loc(lexer, token)\n\t      };\n\t    case _lexer.TokenKind.NAME:\n\t      if (token.value === 'true' || token.value === 'false') {\n\t        lexer.advance();\n\t        return {\n\t          kind: _kinds.BOOLEAN,\n\t          value: token.value === 'true',\n\t          loc: loc(lexer, token)\n\t        };\n\t      } else if (token.value === 'null') {\n\t        lexer.advance();\n\t        return {\n\t          kind: _kinds.NULL,\n\t          loc: loc(lexer, token)\n\t        };\n\t      }\n\t      lexer.advance();\n\t      return {\n\t        kind: _kinds.ENUM,\n\t        value: token.value,\n\t        loc: loc(lexer, token)\n\t      };\n\t    case _lexer.TokenKind.DOLLAR:\n\t      if (!isConst) {\n\t        return parseVariable(lexer);\n\t      }\n\t      break;\n\t  }\n\t  throw unexpected(lexer);\n\t}\n\t\n\tfunction parseConstValue(lexer) {\n\t  return parseValueLiteral(lexer, true);\n\t}\n\t\n\tfunction parseValueValue(lexer) {\n\t  return parseValueLiteral(lexer, false);\n\t}\n\t\n\t/**\n\t * ListValue[Const] :\n\t *   - [ ]\n\t *   - [ Value[?Const]+ ]\n\t */\n\tfunction parseList(lexer, isConst) {\n\t  var start = lexer.token;\n\t  var item = isConst ? parseConstValue : parseValueValue;\n\t  return {\n\t    kind: _kinds.LIST,\n\t    values: any(lexer, _lexer.TokenKind.BRACKET_L, item, _lexer.TokenKind.BRACKET_R),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * ObjectValue[Const] :\n\t *   - { }\n\t *   - { ObjectField[?Const]+ }\n\t */\n\tfunction parseObject(lexer, isConst) {\n\t  var start = lexer.token;\n\t  expect(lexer, _lexer.TokenKind.BRACE_L);\n\t  var fields = [];\n\t  while (!skip(lexer, _lexer.TokenKind.BRACE_R)) {\n\t    fields.push(parseObjectField(lexer, isConst));\n\t  }\n\t  return {\n\t    kind: _kinds.OBJECT,\n\t    fields: fields,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * ObjectField[Const] : Name : Value[?Const]\n\t */\n\tfunction parseObjectField(lexer, isConst) {\n\t  var start = lexer.token;\n\t  return {\n\t    kind: _kinds.OBJECT_FIELD,\n\t    name: parseName(lexer),\n\t    value: (expect(lexer, _lexer.TokenKind.COLON), parseValueLiteral(lexer, isConst)),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t// Implements the parsing rules in the Directives section.\n\t\n\t/**\n\t * Directives : Directive+\n\t */\n\tfunction parseDirectives(lexer) {\n\t  var directives = [];\n\t  while (peek(lexer, _lexer.TokenKind.AT)) {\n\t    directives.push(parseDirective(lexer));\n\t  }\n\t  return directives;\n\t}\n\t\n\t/**\n\t * Directive : @ Name Arguments?\n\t */\n\tfunction parseDirective(lexer) {\n\t  var start = lexer.token;\n\t  expect(lexer, _lexer.TokenKind.AT);\n\t  return {\n\t    kind: _kinds.DIRECTIVE,\n\t    name: parseName(lexer),\n\t    arguments: parseArguments(lexer),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t// Implements the parsing rules in the Types section.\n\t\n\t/**\n\t * Type :\n\t *   - NamedType\n\t *   - ListType\n\t *   - NonNullType\n\t */\n\tfunction parseTypeReference(lexer) {\n\t  var start = lexer.token;\n\t  var type = void 0;\n\t  if (skip(lexer, _lexer.TokenKind.BRACKET_L)) {\n\t    type = parseTypeReference(lexer);\n\t    expect(lexer, _lexer.TokenKind.BRACKET_R);\n\t    type = {\n\t      kind: _kinds.LIST_TYPE,\n\t      type: type,\n\t      loc: loc(lexer, start)\n\t    };\n\t  } else {\n\t    type = parseNamedType(lexer);\n\t  }\n\t  if (skip(lexer, _lexer.TokenKind.BANG)) {\n\t    return {\n\t      kind: _kinds.NON_NULL_TYPE,\n\t      type: type,\n\t      loc: loc(lexer, start)\n\t    };\n\t  }\n\t  return type;\n\t}\n\t\n\t/**\n\t * NamedType : Name\n\t */\n\tfunction parseNamedType(lexer) {\n\t  var start = lexer.token;\n\t  return {\n\t    kind: _kinds.NAMED_TYPE,\n\t    name: parseName(lexer),\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t// Implements the parsing rules in the Type Definition section.\n\t\n\t/**\n\t * TypeSystemDefinition :\n\t *   - SchemaDefinition\n\t *   - TypeDefinition\n\t *   - TypeExtensionDefinition\n\t *   - DirectiveDefinition\n\t *\n\t * TypeDefinition :\n\t *   - ScalarTypeDefinition\n\t *   - ObjectTypeDefinition\n\t *   - InterfaceTypeDefinition\n\t *   - UnionTypeDefinition\n\t *   - EnumTypeDefinition\n\t *   - InputObjectTypeDefinition\n\t */\n\tfunction parseTypeSystemDefinition(lexer) {\n\t  if (peek(lexer, _lexer.TokenKind.NAME)) {\n\t    switch (lexer.token.value) {\n\t      case 'schema':\n\t        return parseSchemaDefinition(lexer);\n\t      case 'scalar':\n\t        return parseScalarTypeDefinition(lexer);\n\t      case 'type':\n\t        return parseObjectTypeDefinition(lexer);\n\t      case 'interface':\n\t        return parseInterfaceTypeDefinition(lexer);\n\t      case 'union':\n\t        return parseUnionTypeDefinition(lexer);\n\t      case 'enum':\n\t        return parseEnumTypeDefinition(lexer);\n\t      case 'input':\n\t        return parseInputObjectTypeDefinition(lexer);\n\t      case 'extend':\n\t        return parseTypeExtensionDefinition(lexer);\n\t      case 'directive':\n\t        return parseDirectiveDefinition(lexer);\n\t    }\n\t  }\n\t\n\t  throw unexpected(lexer);\n\t}\n\t\n\t/**\n\t * SchemaDefinition : schema Directives? { OperationTypeDefinition+ }\n\t *\n\t * OperationTypeDefinition : OperationType : NamedType\n\t */\n\tfunction parseSchemaDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'schema');\n\t  var directives = parseDirectives(lexer);\n\t  var operationTypes = many(lexer, _lexer.TokenKind.BRACE_L, parseOperationTypeDefinition, _lexer.TokenKind.BRACE_R);\n\t  return {\n\t    kind: _kinds.SCHEMA_DEFINITION,\n\t    directives: directives,\n\t    operationTypes: operationTypes,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\tfunction parseOperationTypeDefinition(lexer) {\n\t  var start = lexer.token;\n\t  var operation = parseOperationType(lexer);\n\t  expect(lexer, _lexer.TokenKind.COLON);\n\t  var type = parseNamedType(lexer);\n\t  return {\n\t    kind: _kinds.OPERATION_TYPE_DEFINITION,\n\t    operation: operation,\n\t    type: type,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * ScalarTypeDefinition : scalar Name Directives?\n\t */\n\tfunction parseScalarTypeDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'scalar');\n\t  var name = parseName(lexer);\n\t  var directives = parseDirectives(lexer);\n\t  return {\n\t    kind: _kinds.SCALAR_TYPE_DEFINITION,\n\t    name: name,\n\t    directives: directives,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * ObjectTypeDefinition :\n\t *   - type Name ImplementsInterfaces? Directives? { FieldDefinition+ }\n\t */\n\tfunction parseObjectTypeDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'type');\n\t  var name = parseName(lexer);\n\t  var interfaces = parseImplementsInterfaces(lexer);\n\t  var directives = parseDirectives(lexer);\n\t  var fields = any(lexer, _lexer.TokenKind.BRACE_L, parseFieldDefinition, _lexer.TokenKind.BRACE_R);\n\t  return {\n\t    kind: _kinds.OBJECT_TYPE_DEFINITION,\n\t    name: name,\n\t    interfaces: interfaces,\n\t    directives: directives,\n\t    fields: fields,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * ImplementsInterfaces : implements NamedType+\n\t */\n\tfunction parseImplementsInterfaces(lexer) {\n\t  var types = [];\n\t  if (lexer.token.value === 'implements') {\n\t    lexer.advance();\n\t    do {\n\t      types.push(parseNamedType(lexer));\n\t    } while (peek(lexer, _lexer.TokenKind.NAME));\n\t  }\n\t  return types;\n\t}\n\t\n\t/**\n\t * FieldDefinition : Name ArgumentsDefinition? : Type Directives?\n\t */\n\tfunction parseFieldDefinition(lexer) {\n\t  var start = lexer.token;\n\t  var name = parseName(lexer);\n\t  var args = parseArgumentDefs(lexer);\n\t  expect(lexer, _lexer.TokenKind.COLON);\n\t  var type = parseTypeReference(lexer);\n\t  var directives = parseDirectives(lexer);\n\t  return {\n\t    kind: _kinds.FIELD_DEFINITION,\n\t    name: name,\n\t    arguments: args,\n\t    type: type,\n\t    directives: directives,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * ArgumentsDefinition : ( InputValueDefinition+ )\n\t */\n\tfunction parseArgumentDefs(lexer) {\n\t  if (!peek(lexer, _lexer.TokenKind.PAREN_L)) {\n\t    return [];\n\t  }\n\t  return many(lexer, _lexer.TokenKind.PAREN_L, parseInputValueDef, _lexer.TokenKind.PAREN_R);\n\t}\n\t\n\t/**\n\t * InputValueDefinition : Name : Type DefaultValue? Directives?\n\t */\n\tfunction parseInputValueDef(lexer) {\n\t  var start = lexer.token;\n\t  var name = parseName(lexer);\n\t  expect(lexer, _lexer.TokenKind.COLON);\n\t  var type = parseTypeReference(lexer);\n\t  var defaultValue = null;\n\t  if (skip(lexer, _lexer.TokenKind.EQUALS)) {\n\t    defaultValue = parseConstValue(lexer);\n\t  }\n\t  var directives = parseDirectives(lexer);\n\t  return {\n\t    kind: _kinds.INPUT_VALUE_DEFINITION,\n\t    name: name,\n\t    type: type,\n\t    defaultValue: defaultValue,\n\t    directives: directives,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * InterfaceTypeDefinition : interface Name Directives? { FieldDefinition+ }\n\t */\n\tfunction parseInterfaceTypeDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'interface');\n\t  var name = parseName(lexer);\n\t  var directives = parseDirectives(lexer);\n\t  var fields = any(lexer, _lexer.TokenKind.BRACE_L, parseFieldDefinition, _lexer.TokenKind.BRACE_R);\n\t  return {\n\t    kind: _kinds.INTERFACE_TYPE_DEFINITION,\n\t    name: name,\n\t    directives: directives,\n\t    fields: fields,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * UnionTypeDefinition : union Name Directives? = UnionMembers\n\t */\n\tfunction parseUnionTypeDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'union');\n\t  var name = parseName(lexer);\n\t  var directives = parseDirectives(lexer);\n\t  expect(lexer, _lexer.TokenKind.EQUALS);\n\t  var types = parseUnionMembers(lexer);\n\t  return {\n\t    kind: _kinds.UNION_TYPE_DEFINITION,\n\t    name: name,\n\t    directives: directives,\n\t    types: types,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * UnionMembers :\n\t *   - `|`? NamedType\n\t *   - UnionMembers | NamedType\n\t */\n\tfunction parseUnionMembers(lexer) {\n\t  // Optional leading pipe\n\t  skip(lexer, _lexer.TokenKind.PIPE);\n\t  var members = [];\n\t  do {\n\t    members.push(parseNamedType(lexer));\n\t  } while (skip(lexer, _lexer.TokenKind.PIPE));\n\t  return members;\n\t}\n\t\n\t/**\n\t * EnumTypeDefinition : enum Name Directives? { EnumValueDefinition+ }\n\t */\n\tfunction parseEnumTypeDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'enum');\n\t  var name = parseName(lexer);\n\t  var directives = parseDirectives(lexer);\n\t  var values = many(lexer, _lexer.TokenKind.BRACE_L, parseEnumValueDefinition, _lexer.TokenKind.BRACE_R);\n\t  return {\n\t    kind: _kinds.ENUM_TYPE_DEFINITION,\n\t    name: name,\n\t    directives: directives,\n\t    values: values,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * EnumValueDefinition : EnumValue Directives?\n\t *\n\t * EnumValue : Name\n\t */\n\tfunction parseEnumValueDefinition(lexer) {\n\t  var start = lexer.token;\n\t  var name = parseName(lexer);\n\t  var directives = parseDirectives(lexer);\n\t  return {\n\t    kind: _kinds.ENUM_VALUE_DEFINITION,\n\t    name: name,\n\t    directives: directives,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * InputObjectTypeDefinition : input Name Directives? { InputValueDefinition+ }\n\t */\n\tfunction parseInputObjectTypeDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'input');\n\t  var name = parseName(lexer);\n\t  var directives = parseDirectives(lexer);\n\t  var fields = any(lexer, _lexer.TokenKind.BRACE_L, parseInputValueDef, _lexer.TokenKind.BRACE_R);\n\t  return {\n\t    kind: _kinds.INPUT_OBJECT_TYPE_DEFINITION,\n\t    name: name,\n\t    directives: directives,\n\t    fields: fields,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * TypeExtensionDefinition : extend ObjectTypeDefinition\n\t */\n\tfunction parseTypeExtensionDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'extend');\n\t  var definition = parseObjectTypeDefinition(lexer);\n\t  return {\n\t    kind: _kinds.TYPE_EXTENSION_DEFINITION,\n\t    definition: definition,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * DirectiveDefinition :\n\t *   - directive @ Name ArgumentsDefinition? on DirectiveLocations\n\t */\n\tfunction parseDirectiveDefinition(lexer) {\n\t  var start = lexer.token;\n\t  expectKeyword(lexer, 'directive');\n\t  expect(lexer, _lexer.TokenKind.AT);\n\t  var name = parseName(lexer);\n\t  var args = parseArgumentDefs(lexer);\n\t  expectKeyword(lexer, 'on');\n\t  var locations = parseDirectiveLocations(lexer);\n\t  return {\n\t    kind: _kinds.DIRECTIVE_DEFINITION,\n\t    name: name,\n\t    arguments: args,\n\t    locations: locations,\n\t    loc: loc(lexer, start)\n\t  };\n\t}\n\t\n\t/**\n\t * DirectiveLocations :\n\t *   - `|`? Name\n\t *   - DirectiveLocations | Name\n\t */\n\tfunction parseDirectiveLocations(lexer) {\n\t  // Optional leading pipe\n\t  skip(lexer, _lexer.TokenKind.PIPE);\n\t  var locations = [];\n\t  do {\n\t    locations.push(parseName(lexer));\n\t  } while (skip(lexer, _lexer.TokenKind.PIPE));\n\t  return locations;\n\t}\n\t\n\t// Core parsing utility functions\n\t\n\t/**\n\t * Returns a location object, used to identify the place in\n\t * the source that created a given parsed object.\n\t */\n\tfunction loc(lexer, startToken) {\n\t  if (!lexer.options.noLocation) {\n\t    return new Loc(startToken, lexer.lastToken, lexer.source);\n\t  }\n\t}\n\t\n\tfunction Loc(startToken, endToken, source) {\n\t  this.start = startToken.start;\n\t  this.end = endToken.end;\n\t  this.startToken = startToken;\n\t  this.endToken = endToken;\n\t  this.source = source;\n\t}\n\t\n\t// Print a simplified form when appearing in JSON/util.inspect.\n\tLoc.prototype.toJSON = Loc.prototype.inspect = function toJSON() {\n\t  return { start: this.start, end: this.end };\n\t};\n\t\n\t/**\n\t * Determines if the next token is of a given kind\n\t */\n\tfunction peek(lexer, kind) {\n\t  return lexer.token.kind === kind;\n\t}\n\t\n\t/**\n\t * If the next token is of the given kind, return true after advancing\n\t * the lexer. Otherwise, do not change the parser state and return false.\n\t */\n\tfunction skip(lexer, kind) {\n\t  var match = lexer.token.kind === kind;\n\t  if (match) {\n\t    lexer.advance();\n\t  }\n\t  return match;\n\t}\n\t\n\t/**\n\t * If the next token is of the given kind, return that token after advancing\n\t * the lexer. Otherwise, do not change the parser state and throw an error.\n\t */\n\tfunction expect(lexer, kind) {\n\t  var token = lexer.token;\n\t  if (token.kind === kind) {\n\t    lexer.advance();\n\t    return token;\n\t  }\n\t  throw (0, _error.syntaxError)(lexer.source, token.start, 'Expected ' + kind + ', found ' + (0, _lexer.getTokenDesc)(token));\n\t}\n\t\n\t/**\n\t * If the next token is a keyword with the given value, return that token after\n\t * advancing the lexer. Otherwise, do not change the parser state and return\n\t * false.\n\t */\n\tfunction expectKeyword(lexer, value) {\n\t  var token = lexer.token;\n\t  if (token.kind === _lexer.TokenKind.NAME && token.value === value) {\n\t    lexer.advance();\n\t    return token;\n\t  }\n\t  throw (0, _error.syntaxError)(lexer.source, token.start, 'Expected \"' + value + '\", found ' + (0, _lexer.getTokenDesc)(token));\n\t}\n\t\n\t/**\n\t * Helper function for creating an error when an unexpected lexed token\n\t * is encountered.\n\t */\n\tfunction unexpected(lexer, atToken) {\n\t  var token = atToken || lexer.token;\n\t  return (0, _error.syntaxError)(lexer.source, token.start, 'Unexpected ' + (0, _lexer.getTokenDesc)(token));\n\t}\n\t\n\t/**\n\t * Returns a possibly empty list of parse nodes, determined by\n\t * the parseFn. This list begins with a lex token of openKind\n\t * and ends with a lex token of closeKind. Advances the parser\n\t * to the next lex token after the closing token.\n\t */\n\tfunction any(lexer, openKind, parseFn, closeKind) {\n\t  expect(lexer, openKind);\n\t  var nodes = [];\n\t  while (!skip(lexer, closeKind)) {\n\t    nodes.push(parseFn(lexer));\n\t  }\n\t  return nodes;\n\t}\n\t\n\t/**\n\t * Returns a non-empty list of parse nodes, determined by\n\t * the parseFn. This list begins with a lex token of openKind\n\t * and ends with a lex token of closeKind. Advances the parser\n\t * to the next lex token after the closing token.\n\t */\n\tfunction many(lexer, openKind, parseFn, closeKind) {\n\t  expect(lexer, openKind);\n\t  var nodes = [parseFn(lexer)];\n\t  while (!skip(lexer, closeKind)) {\n\t    nodes.push(parseFn(lexer));\n\t  }\n\t  return nodes;\n\t}\n\n/***/ }),\n\n/***/ \"./node_modules/graphql/language/source.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.Source = undefined;\n\t\n\tvar _invariant = __webpack_require__(\"./node_modules/graphql/jsutils/invariant.js\");\n\t\n\tvar _invariant2 = _interopRequireDefault(_invariant);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\tfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\t/**\n\t *  Copyright (c) 2015, Facebook, Inc.\n\t *  All rights reserved.\n\t *\n\t *  This source code is licensed under the BSD-style license found in the\n\t *  LICENSE file in the root directory of this source tree. An additional grant\n\t *  of patent rights can be found in the PATENTS file in the same directory.\n\t */\n\t\n\t/**\n\t * A representation of source input to GraphQL.\n\t * `name` and `locationOffset` are optional. They are useful for clients who\n\t * store GraphQL documents in source files; for example, if the GraphQL input\n\t * starts at line 40 in a file named Foo.graphql, it might be useful for name to\n\t * be \"Foo.graphql\" and location to be `{ line: 40, column: 0 }`.\n\t * line and column in locationOffset are 1-indexed\n\t */\n\tvar Source = exports.Source = function Source(body, name, locationOffset) {\n\t  _classCallCheck(this, Source);\n\t\n\t  this.body = body;\n\t  this.name = name || 'GraphQL request';\n\t  this.locationOffset = locationOffset || { line: 1, column: 1 };\n\t  !(this.locationOffset.line > 0) ? (0, _invariant2.default)(0, 'line in locationOffset is 1-indexed and must be positive') : void 0;\n\t  !(this.locationOffset.column > 0) ? (0, _invariant2.default)(0, 'column in locationOffset is 1-indexed and must be positive') : void 0;\n\t};\n\n/***/ }),\n\n/***/ \"./src/components/Header.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\t\n\tvar _react = __webpack_require__(\"./node_modules/react/react.js\");\n\t\n\tvar _react2 = _interopRequireDefault(_react);\n\t\n\tvar _propTypes = __webpack_require__(\"./node_modules/prop-types/index.js\");\n\t\n\tvar _propTypes2 = _interopRequireDefault(_propTypes);\n\t\n\tvar _classnames = __webpack_require__(\"./node_modules/classnames/index.js\");\n\t\n\tvar _classnames2 = _interopRequireDefault(_classnames);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\tvar Header = function Header(_ref) {\n\t  var title = _ref.title,\n\t      byline = _ref.byline;\n\t  return _react2.default.createElement(\n\t    'div',\n\t    { className: 'header' },\n\t    _react2.default.createElement(\n\t      'h1',\n\t      { className: (0, _classnames2.default)('header__title', { 'header__title--with-byline': byline.length })\n\t      },\n\t      title\n\t    ),\n\t    byline.length && _react2.default.createElement(\n\t      'p',\n\t      { className: 'header__byline' },\n\t      byline\n\t    )\n\t  );\n\t};\n\t\n\tHeader.propTypes = {\n\t  title: _propTypes2.default.string.isRequired,\n\t  byline: _propTypes2.default.string\n\t};\n\t\n\tHeader.defaultProps = {\n\t  byline: ''\n\t};\n\t\n\texports.default = Header;\n\tmodule.exports = exports['default'];\n\n/***/ }),\n\n/***/ \"./node_modules/babel-loader/lib/index.js?{\\\"plugins\\\":[\\\"/home/travis/build/HackBattles/hackbattl.es/node_modules/gatsby/dist/utils/babel-plugin-extract-graphql.js\\\",\\\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-plugin-add-module-exports/lib/index.js\\\",\\\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-plugin-add-module-exports/lib/index.js\\\",\\\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-plugin-transform-object-assign/lib/index.js\\\"],\\\"presets\\\":[\\\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-preset-env/lib/index.js\\\",\\\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-preset-stage-0/lib/index.js\\\",\\\"/home/travis/build/HackBattles/hackbattl.es/node_modules/babel-preset-react/lib/index.js\\\"],\\\"cacheDirectory\\\":true}!./src/pages/index.js\":\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.pageQuery = undefined;\n\t\n\tvar _react = __webpack_require__(\"./node_modules/react/react.js\");\n\t\n\tvar _react2 = _interopRequireDefault(_react);\n\t\n\tvar _graphqlTag = __webpack_require__(\"./node_modules/graphql-tag/lib/graphql-tag.umd.js\");\n\t\n\tvar _graphqlTag2 = _interopRequireDefault(_graphqlTag);\n\t\n\tvar _propTypes = __webpack_require__(\"./node_modules/prop-types/index.js\");\n\t\n\tvar _propTypes2 = _interopRequireDefault(_propTypes);\n\t\n\tvar _Header = __webpack_require__(\"./src/components/Header.js\");\n\t\n\tvar _Header2 = _interopRequireDefault(_Header);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\tvar Index = function Index(_ref) {\n\t  var data = _ref.data;\n\t  return _react2.default.createElement(\n\t    'div',\n\t    { className: 'content' },\n\t    _react2.default.createElement(_Header2.default, {\n\t      title: data.site.siteMetadata.title,\n\t      byline: data.site.siteMetadata.description\n\t    }),\n\t    _react2.default.createElement(\n\t      'h2',\n\t      null,\n\t      'Upcoming Battles'\n\t    ),\n\t    _react2.default.createElement(\n\t      'a',\n\t      { href: '/fl/gnv/discover-gainesville' },\n\t      'Gainesville, FL - August 26, 2017'\n\t    ),\n\t    _react2.default.createElement(\n\t      'h2',\n\t      null,\n\t      'More Information'\n\t    ),\n\t    _react2.default.createElement(\n\t      'p',\n\t      null,\n\t      'Want to host a HackBattle in your area?',\n\t      _react2.default.createElement('br', null),\n\t      'Visit the ',\n\t      _react2.default.createElement(\n\t        'a',\n\t        { href: 'https://github.com/HackBattles/hackbattl.es' },\n\t        'HackBattles Github repo'\n\t      ),\n\t      ' for information.'\n\t    )\n\t  );\n\t};\n\t\n\tIndex.propTypes = {\n\t  data: _propTypes2.default.shape({\n\t    site: _propTypes2.default.shape({\n\t      siteMetadata: _propTypes2.default.shape({\n\t        title: _propTypes2.default.string,\n\t        description: _propTypes2.default.string\n\t      })\n\t    })\n\t  })\n\t};\n\t\n\tIndex.defaultProps = {\n\t  data: {\n\t    site: {\n\t      siteMetadata: {\n\t        title: '',\n\t        description: ''\n\t      }\n\t    }\n\t  }\n\t};\n\t\n\texports.default = Index;\n\tvar pageQuery = exports.pageQuery = '** extracted graphql fragment **';\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// page-component---src-pages-index-js-4631062d0b0ed4afc9b9.js","/*!\n  Copyright (c) 2016 Jed Watson.\n  Licensed under the MIT License (MIT), see\n  http://jedwatson.github.io/classnames\n*/\n/* global define */\n\n(function () {\n\t'use strict';\n\n\tvar hasOwn = {}.hasOwnProperty;\n\n\tfunction classNames () {\n\t\tvar classes = [];\n\n\t\tfor (var i = 0; i < arguments.length; i++) {\n\t\t\tvar arg = arguments[i];\n\t\t\tif (!arg) continue;\n\n\t\t\tvar argType = typeof arg;\n\n\t\t\tif (argType === 'string' || argType === 'number') {\n\t\t\t\tclasses.push(arg);\n\t\t\t} else if (Array.isArray(arg)) {\n\t\t\t\tclasses.push(classNames.apply(null, arg));\n\t\t\t} else if (argType === 'object') {\n\t\t\t\tfor (var key in arg) {\n\t\t\t\t\tif (hasOwn.call(arg, key) && arg[key]) {\n\t\t\t\t\t\tclasses.push(key);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn classes.join(' ');\n\t}\n\n\tif (typeof module !== 'undefined' && module.exports) {\n\t\tmodule.exports = classNames;\n\t} else if (typeof define === 'function' && typeof define.amd === 'object' && define.amd) {\n\t\t// register as 'classnames', consistent with npm package name\n\t\tdefine('classnames', [], function () {\n\t\t\treturn classNames;\n\t\t});\n\t} else {\n\t\twindow.classNames = classNames;\n\t}\n}());\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/classnames/index.js\n// module id = ./node_modules/classnames/index.js\n// module chunks = 4016850265702045000 6379530823973858000","(function (global, factory) {\n\ttypeof exports === 'object' && typeof module !== 'undefined' ? factory() :\n\ttypeof define === 'function' && define.amd ? define(factory) :\n\t(factory());\n}(this, (function () { 'use strict';\n\nvar parser = require('graphql/language/parser');\n\nvar parse = parser.parse;\n\n// Strip insignificant whitespace\n// Note that this could do a lot more, such as reorder fields etc.\nfunction normalize(string) {\n  return string.replace(/[\\s,]+/g, ' ').trim();\n}\n\n// A map docString -> graphql document\nvar docCache = {};\n\n// A map fragmentName -> [normalized source]\nvar fragmentSourceMap = {};\n\nfunction cacheKeyFromLoc(loc) {\n  return normalize(loc.source.body.substring(loc.start, loc.end));\n}\n\n// For testing.\nfunction resetCaches() {\n  docCache = {};\n  fragmentSourceMap = {};\n}\n\n// Take a unstripped parsed document (query/mutation or even fragment), and\n// check all fragment definitions, checking for name->source uniqueness.\n// We also want to make sure only unique fragments exist in the document.\nvar printFragmentWarnings = true;\nfunction processFragments(ast) {\n  var astFragmentMap = {};\n  var definitions = [];\n\n  for (var i = 0; i < ast.definitions.length; i++) {\n    var fragmentDefinition = ast.definitions[i];\n\n    if (fragmentDefinition.kind === 'FragmentDefinition') {\n      var fragmentName = fragmentDefinition.name.value;\n      var sourceKey = cacheKeyFromLoc(fragmentDefinition.loc);\n\n      // We know something about this fragment\n      if (fragmentSourceMap.hasOwnProperty(fragmentName) && !fragmentSourceMap[fragmentName][sourceKey]) {\n\n        // this is a problem because the app developer is trying to register another fragment with\n        // the same name as one previously registered. So, we tell them about it.\n        if (printFragmentWarnings) {\n          console.warn(\"Warning: fragment with name \" + fragmentName + \" already exists.\\n\"\n            + \"graphql-tag enforces all fragment names across your application to be unique; read more about\\n\"\n            + \"this in the docs: http://dev.apollodata.com/core/fragments.html#unique-names\");\n        }\n\n        fragmentSourceMap[fragmentName][sourceKey] = true;\n\n      } else if (!fragmentSourceMap.hasOwnProperty(fragmentName)) {\n        fragmentSourceMap[fragmentName] = {};\n        fragmentSourceMap[fragmentName][sourceKey] = true;\n      }\n\n      if (!astFragmentMap[sourceKey]) {\n        astFragmentMap[sourceKey] = true;\n        definitions.push(fragmentDefinition);\n      }\n    } else {\n      definitions.push(fragmentDefinition);\n    }\n  }\n\n  ast.definitions = definitions;\n  return ast;\n}\n\nfunction disableFragmentWarnings() {\n  printFragmentWarnings = false;\n}\n\nfunction stripLoc(doc, removeLocAtThisLevel) {\n  var docType = Object.prototype.toString.call(doc);\n\n  if (docType === '[object Array]') {\n    return doc.map(function (d) {\n      return stripLoc(d, removeLocAtThisLevel);\n    });\n  }\n\n  if (docType !== '[object Object]') {\n    throw new Error('Unexpected input.');\n  }\n\n  // We don't want to remove the root loc field so we can use it\n  // for fragment substitution (see below)\n  if (removeLocAtThisLevel && doc.loc) {\n    delete doc.loc;\n  }\n\n  // https://github.com/apollographql/graphql-tag/issues/40\n  if (doc.loc) {\n    delete doc.loc.startToken;\n    delete doc.loc.endToken;\n  }\n\n  var keys = Object.keys(doc);\n  var key;\n  var value;\n  var valueType;\n\n  for (key in keys) {\n    if (keys.hasOwnProperty(key)) {\n      value = doc[keys[key]];\n      valueType = Object.prototype.toString.call(value);\n\n      if (valueType === '[object Object]' || valueType === '[object Array]') {\n        doc[keys[key]] = stripLoc(value, true);\n      }\n    }\n  }\n\n  return doc;\n}\n\nfunction parseDocument(doc) {\n  var cacheKey = normalize(doc);\n\n  if (docCache[cacheKey]) {\n    return docCache[cacheKey];\n  }\n\n  var parsed = parse(doc);\n  if (!parsed || parsed.kind !== 'Document') {\n    throw new Error('Not a valid GraphQL document.');\n  }\n\n  // check that all \"new\" fragments inside the documents are consistent with\n  // existing fragments of the same name\n  parsed = processFragments(parsed);\n  parsed = stripLoc(parsed, false);\n  docCache[cacheKey] = parsed;\n\n  return parsed;\n}\n\n// XXX This should eventually disallow arbitrary string interpolation, like Relay does\nfunction gql(/* arguments */) {\n  var args = Array.prototype.slice.call(arguments);\n\n  var literals = args[0];\n\n  // We always get literals[0] and then matching post literals for each arg given\n  var result = (typeof(literals) === \"string\") ? literals : literals[0];\n\n  for (var i = 1; i < args.length; i++) {\n    if (args[i] && args[i].kind && args[i].kind === 'Document') {\n      result += args[i].loc.source.body;\n    } else {\n      result += args[i];\n    }\n\n    result += literals[i];\n  }\n\n  return parseDocument(result);\n}\n\n// Support typescript, which isn't as nice as Babel about default exports\ngql.default = gql;\ngql.resetCaches = resetCaches;\ngql.disableFragmentWarnings = disableFragmentWarnings;\n\nmodule.exports = gql;\n\n})));\n//# sourceMappingURL=graphql-tag.umd.js.map\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql-tag/lib/graphql-tag.umd.js\n// module id = ./node_modules/graphql-tag/lib/graphql-tag.umd.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GraphQLError = GraphQLError;\n\nvar _location = require('../language/location');\n\n/**\n * A GraphQLError describes an Error found during the parse, validate, or\n * execute phases of performing a GraphQL operation. In addition to a message\n * and stack trace, it also includes information about the locations in a\n * GraphQL document and/or execution result that correspond to the Error.\n */\nfunction GraphQLError( // eslint-disable-line no-redeclare\nmessage, nodes, source, positions, path, originalError) {\n  // Compute locations in the source for the given nodes/positions.\n  var _source = source;\n  if (!_source && nodes && nodes.length > 0) {\n    var node = nodes[0];\n    _source = node && node.loc && node.loc.source;\n  }\n\n  var _positions = positions;\n  if (!_positions && nodes) {\n    _positions = nodes.filter(function (node) {\n      return Boolean(node.loc);\n    }).map(function (node) {\n      return node.loc.start;\n    });\n  }\n  if (_positions && _positions.length === 0) {\n    _positions = undefined;\n  }\n\n  var _locations = void 0;\n  var _source2 = _source; // seems here Flow need a const to resolve type.\n  if (_source2 && _positions) {\n    _locations = _positions.map(function (pos) {\n      return (0, _location.getLocation)(_source2, pos);\n    });\n  }\n\n  Object.defineProperties(this, {\n    message: {\n      value: message,\n      // By being enumerable, JSON.stringify will include `message` in the\n      // resulting output. This ensures that the simplest possible GraphQL\n      // service adheres to the spec.\n      enumerable: true,\n      writable: true\n    },\n    locations: {\n      // Coercing falsey values to undefined ensures they will not be included\n      // in JSON.stringify() when not provided.\n      value: _locations || undefined,\n      // By being enumerable, JSON.stringify will include `locations` in the\n      // resulting output. This ensures that the simplest possible GraphQL\n      // service adheres to the spec.\n      enumerable: true\n    },\n    path: {\n      // Coercing falsey values to undefined ensures they will not be included\n      // in JSON.stringify() when not provided.\n      value: path || undefined,\n      // By being enumerable, JSON.stringify will include `path` in the\n      // resulting output. This ensures that the simplest possible GraphQL\n      // service adheres to the spec.\n      enumerable: true\n    },\n    nodes: {\n      value: nodes || undefined\n    },\n    source: {\n      value: _source || undefined\n    },\n    positions: {\n      value: _positions || undefined\n    },\n    originalError: {\n      value: originalError\n    }\n  });\n\n  // Include (non-enumerable) stack trace.\n  if (originalError && originalError.stack) {\n    Object.defineProperty(this, 'stack', {\n      value: originalError.stack,\n      writable: true,\n      configurable: true\n    });\n  } else if (Error.captureStackTrace) {\n    Error.captureStackTrace(this, GraphQLError);\n  } else {\n    Object.defineProperty(this, 'stack', {\n      value: Error().stack,\n      writable: true,\n      configurable: true\n    });\n  }\n}\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\nGraphQLError.prototype = Object.create(Error.prototype, {\n  constructor: { value: GraphQLError },\n  name: { value: 'GraphQLError' }\n});\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/error/GraphQLError.js\n// module id = ./node_modules/graphql/error/GraphQLError.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.formatError = formatError;\n\nvar _invariant = require('../jsutils/invariant');\n\nvar _invariant2 = _interopRequireDefault(_invariant);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Given a GraphQLError, format it according to the rules described by the\n * Response Format, Errors section of the GraphQL Specification.\n */\nfunction formatError(error) {\n  !error ? (0, _invariant2.default)(0, 'Received null or undefined error.') : void 0;\n  return {\n    message: error.message,\n    locations: error.locations,\n    path: error.path\n  };\n}\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/error/formatError.js\n// module id = ./node_modules/graphql/error/formatError.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _GraphQLError = require('./GraphQLError');\n\nObject.defineProperty(exports, 'GraphQLError', {\n  enumerable: true,\n  get: function get() {\n    return _GraphQLError.GraphQLError;\n  }\n});\n\nvar _syntaxError = require('./syntaxError');\n\nObject.defineProperty(exports, 'syntaxError', {\n  enumerable: true,\n  get: function get() {\n    return _syntaxError.syntaxError;\n  }\n});\n\nvar _locatedError = require('./locatedError');\n\nObject.defineProperty(exports, 'locatedError', {\n  enumerable: true,\n  get: function get() {\n    return _locatedError.locatedError;\n  }\n});\n\nvar _formatError = require('./formatError');\n\nObject.defineProperty(exports, 'formatError', {\n  enumerable: true,\n  get: function get() {\n    return _formatError.formatError;\n  }\n});\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/error/index.js\n// module id = ./node_modules/graphql/error/index.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.locatedError = locatedError;\n\nvar _GraphQLError = require('./GraphQLError');\n\n/**\n * Given an arbitrary Error, presumably thrown while attempting to execute a\n * GraphQL operation, produce a new GraphQLError aware of the location in the\n * document responsible for the original Error.\n */\nfunction locatedError(originalError, nodes, path) {\n  // Note: this uses a brand-check to support GraphQL errors originating from\n  // other contexts.\n  if (originalError && originalError.path) {\n    return originalError;\n  }\n\n  var message = originalError ? originalError.message || String(originalError) : 'An unknown error occurred.';\n  return new _GraphQLError.GraphQLError(message, originalError && originalError.nodes || nodes, originalError && originalError.source, originalError && originalError.positions, path, originalError);\n}\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/error/locatedError.js\n// module id = ./node_modules/graphql/error/locatedError.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.syntaxError = syntaxError;\n\nvar _location = require('../language/location');\n\nvar _GraphQLError = require('./GraphQLError');\n\n/**\n * Produces a GraphQLError representing a syntax error, containing useful\n * descriptive information about the syntax error's position in the source.\n */\n\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\nfunction syntaxError(source, position, description) {\n  var location = (0, _location.getLocation)(source, position);\n  var line = location.line + source.locationOffset.line - 1;\n  var columnOffset = getColumnOffset(source, location);\n  var column = location.column + columnOffset;\n  var error = new _GraphQLError.GraphQLError('Syntax Error ' + source.name + ' (' + line + ':' + column + ') ' + description + '\\n\\n' + highlightSourceAtLocation(source, location), undefined, source, [position]);\n  return error;\n}\n\n/**\n * Render a helpful description of the location of the error in the GraphQL\n * Source document.\n */\nfunction highlightSourceAtLocation(source, location) {\n  var line = location.line;\n  var lineOffset = source.locationOffset.line - 1;\n  var columnOffset = getColumnOffset(source, location);\n  var contextLine = line + lineOffset;\n  var prevLineNum = (contextLine - 1).toString();\n  var lineNum = contextLine.toString();\n  var nextLineNum = (contextLine + 1).toString();\n  var padLen = nextLineNum.length;\n  var lines = source.body.split(/\\r\\n|[\\n\\r]/g);\n  lines[0] = whitespace(source.locationOffset.column - 1) + lines[0];\n  return (line >= 2 ? lpad(padLen, prevLineNum) + ': ' + lines[line - 2] + '\\n' : '') + lpad(padLen, lineNum) + ': ' + lines[line - 1] + '\\n' + whitespace(2 + padLen + location.column - 1 + columnOffset) + '^\\n' + (line < lines.length ? lpad(padLen, nextLineNum) + ': ' + lines[line] + '\\n' : '');\n}\n\nfunction getColumnOffset(source, location) {\n  return location.line === 1 ? source.locationOffset.column - 1 : 0;\n}\n\nfunction whitespace(len) {\n  return Array(len + 1).join(' ');\n}\n\nfunction lpad(len, str) {\n  return whitespace(len - str.length) + str;\n}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/error/syntaxError.js\n// module id = ./node_modules/graphql/error/syntaxError.js\n// module chunks = 4016850265702045000 6379530823973858000","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = invariant;\n\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\nfunction invariant(condition, message) {\n  if (!condition) {\n    throw new Error(message);\n  }\n}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/jsutils/invariant.js\n// module id = ./node_modules/graphql/jsutils/invariant.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\n// Name\n\nvar NAME = exports.NAME = 'Name';\n\n// Document\n\nvar DOCUMENT = exports.DOCUMENT = 'Document';\nvar OPERATION_DEFINITION = exports.OPERATION_DEFINITION = 'OperationDefinition';\nvar VARIABLE_DEFINITION = exports.VARIABLE_DEFINITION = 'VariableDefinition';\nvar VARIABLE = exports.VARIABLE = 'Variable';\nvar SELECTION_SET = exports.SELECTION_SET = 'SelectionSet';\nvar FIELD = exports.FIELD = 'Field';\nvar ARGUMENT = exports.ARGUMENT = 'Argument';\n\n// Fragments\n\nvar FRAGMENT_SPREAD = exports.FRAGMENT_SPREAD = 'FragmentSpread';\nvar INLINE_FRAGMENT = exports.INLINE_FRAGMENT = 'InlineFragment';\nvar FRAGMENT_DEFINITION = exports.FRAGMENT_DEFINITION = 'FragmentDefinition';\n\n// Values\n\nvar INT = exports.INT = 'IntValue';\nvar FLOAT = exports.FLOAT = 'FloatValue';\nvar STRING = exports.STRING = 'StringValue';\nvar BOOLEAN = exports.BOOLEAN = 'BooleanValue';\nvar NULL = exports.NULL = 'NullValue';\nvar ENUM = exports.ENUM = 'EnumValue';\nvar LIST = exports.LIST = 'ListValue';\nvar OBJECT = exports.OBJECT = 'ObjectValue';\nvar OBJECT_FIELD = exports.OBJECT_FIELD = 'ObjectField';\n\n// Directives\n\nvar DIRECTIVE = exports.DIRECTIVE = 'Directive';\n\n// Types\n\nvar NAMED_TYPE = exports.NAMED_TYPE = 'NamedType';\nvar LIST_TYPE = exports.LIST_TYPE = 'ListType';\nvar NON_NULL_TYPE = exports.NON_NULL_TYPE = 'NonNullType';\n\n// Type System Definitions\n\nvar SCHEMA_DEFINITION = exports.SCHEMA_DEFINITION = 'SchemaDefinition';\nvar OPERATION_TYPE_DEFINITION = exports.OPERATION_TYPE_DEFINITION = 'OperationTypeDefinition';\n\n// Type Definitions\n\nvar SCALAR_TYPE_DEFINITION = exports.SCALAR_TYPE_DEFINITION = 'ScalarTypeDefinition';\nvar OBJECT_TYPE_DEFINITION = exports.OBJECT_TYPE_DEFINITION = 'ObjectTypeDefinition';\nvar FIELD_DEFINITION = exports.FIELD_DEFINITION = 'FieldDefinition';\nvar INPUT_VALUE_DEFINITION = exports.INPUT_VALUE_DEFINITION = 'InputValueDefinition';\nvar INTERFACE_TYPE_DEFINITION = exports.INTERFACE_TYPE_DEFINITION = 'InterfaceTypeDefinition';\nvar UNION_TYPE_DEFINITION = exports.UNION_TYPE_DEFINITION = 'UnionTypeDefinition';\nvar ENUM_TYPE_DEFINITION = exports.ENUM_TYPE_DEFINITION = 'EnumTypeDefinition';\nvar ENUM_VALUE_DEFINITION = exports.ENUM_VALUE_DEFINITION = 'EnumValueDefinition';\nvar INPUT_OBJECT_TYPE_DEFINITION = exports.INPUT_OBJECT_TYPE_DEFINITION = 'InputObjectTypeDefinition';\n\n// Type Extensions\n\nvar TYPE_EXTENSION_DEFINITION = exports.TYPE_EXTENSION_DEFINITION = 'TypeExtensionDefinition';\n\n// Directive Definitions\n\nvar DIRECTIVE_DEFINITION = exports.DIRECTIVE_DEFINITION = 'DirectiveDefinition';\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/language/kinds.js\n// module id = ./node_modules/graphql/language/kinds.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.TokenKind = undefined;\nexports.createLexer = createLexer;\nexports.getTokenDesc = getTokenDesc;\n\nvar _error = require('../error');\n\n/**\n * Given a Source object, this returns a Lexer for that source.\n * A Lexer is a stateful stream generator in that every time\n * it is advanced, it returns the next token in the Source. Assuming the\n * source lexes, the final Token emitted by the lexer will be of kind\n * EOF, after which the lexer will repeatedly return the same EOF token\n * whenever called.\n */\nfunction createLexer(source, options) {\n  var startOfFileToken = new Tok(SOF, 0, 0, 0, 0, null);\n  var lexer = {\n    source: source,\n    options: options,\n    lastToken: startOfFileToken,\n    token: startOfFileToken,\n    line: 1,\n    lineStart: 0,\n    advance: advanceLexer\n  };\n  return lexer;\n} /*  /\n  /**\n   *  Copyright (c) 2015, Facebook, Inc.\n   *  All rights reserved.\n   *\n   *  This source code is licensed under the BSD-style license found in the\n   *  LICENSE file in the root directory of this source tree. An additional grant\n   *  of patent rights can be found in the PATENTS file in the same directory.\n   */\n\nfunction advanceLexer() {\n  var token = this.lastToken = this.token;\n  if (token.kind !== EOF) {\n    do {\n      token = token.next = readToken(this, token);\n    } while (token.kind === COMMENT);\n    this.token = token;\n  }\n  return token;\n}\n\n/**\n * The return type of createLexer.\n */\n\n\n// Each kind of token.\nvar SOF = '<SOF>';\nvar EOF = '<EOF>';\nvar BANG = '!';\nvar DOLLAR = '$';\nvar PAREN_L = '(';\nvar PAREN_R = ')';\nvar SPREAD = '...';\nvar COLON = ':';\nvar EQUALS = '=';\nvar AT = '@';\nvar BRACKET_L = '[';\nvar BRACKET_R = ']';\nvar BRACE_L = '{';\nvar PIPE = '|';\nvar BRACE_R = '}';\nvar NAME = 'Name';\nvar INT = 'Int';\nvar FLOAT = 'Float';\nvar STRING = 'String';\nvar COMMENT = 'Comment';\n\n/**\n * An exported enum describing the different kinds of tokens that the\n * lexer emits.\n */\nvar TokenKind = exports.TokenKind = {\n  SOF: SOF,\n  EOF: EOF,\n  BANG: BANG,\n  DOLLAR: DOLLAR,\n  PAREN_L: PAREN_L,\n  PAREN_R: PAREN_R,\n  SPREAD: SPREAD,\n  COLON: COLON,\n  EQUALS: EQUALS,\n  AT: AT,\n  BRACKET_L: BRACKET_L,\n  BRACKET_R: BRACKET_R,\n  BRACE_L: BRACE_L,\n  PIPE: PIPE,\n  BRACE_R: BRACE_R,\n  NAME: NAME,\n  INT: INT,\n  FLOAT: FLOAT,\n  STRING: STRING,\n  COMMENT: COMMENT\n};\n\n/**\n * A helper function to describe a token as a string for debugging\n */\nfunction getTokenDesc(token) {\n  var value = token.value;\n  return value ? token.kind + ' \"' + value + '\"' : token.kind;\n}\n\nvar charCodeAt = String.prototype.charCodeAt;\nvar slice = String.prototype.slice;\n\n/**\n * Helper function for constructing the Token object.\n */\nfunction Tok(kind, start, end, line, column, prev, value) {\n  this.kind = kind;\n  this.start = start;\n  this.end = end;\n  this.line = line;\n  this.column = column;\n  this.value = value;\n  this.prev = prev;\n  this.next = null;\n}\n\n// Print a simplified form when appearing in JSON/util.inspect.\nTok.prototype.toJSON = Tok.prototype.inspect = function toJSON() {\n  return {\n    kind: this.kind,\n    value: this.value,\n    line: this.line,\n    column: this.column\n  };\n};\n\nfunction printCharCode(code) {\n  return (\n    // NaN/undefined represents access beyond the end of the file.\n    isNaN(code) ? EOF :\n    // Trust JSON for ASCII.\n    code < 0x007F ? JSON.stringify(String.fromCharCode(code)) :\n    // Otherwise print the escaped form.\n    '\"\\\\u' + ('00' + code.toString(16).toUpperCase()).slice(-4) + '\"'\n  );\n}\n\n/**\n * Gets the next token from the source starting at the given position.\n *\n * This skips over whitespace and comments until it finds the next lexable\n * token, then lexes punctuators immediately or calls the appropriate helper\n * function for more complicated tokens.\n */\nfunction readToken(lexer, prev) {\n  var source = lexer.source;\n  var body = source.body;\n  var bodyLength = body.length;\n\n  var position = positionAfterWhitespace(body, prev.end, lexer);\n  var line = lexer.line;\n  var col = 1 + position - lexer.lineStart;\n\n  if (position >= bodyLength) {\n    return new Tok(EOF, bodyLength, bodyLength, line, col, prev);\n  }\n\n  var code = charCodeAt.call(body, position);\n\n  // SourceCharacter\n  if (code < 0x0020 && code !== 0x0009 && code !== 0x000A && code !== 0x000D) {\n    throw (0, _error.syntaxError)(source, position, 'Cannot contain the invalid character ' + printCharCode(code) + '.');\n  }\n\n  switch (code) {\n    // !\n    case 33:\n      return new Tok(BANG, position, position + 1, line, col, prev);\n    // #\n    case 35:\n      return readComment(source, position, line, col, prev);\n    // $\n    case 36:\n      return new Tok(DOLLAR, position, position + 1, line, col, prev);\n    // (\n    case 40:\n      return new Tok(PAREN_L, position, position + 1, line, col, prev);\n    // )\n    case 41:\n      return new Tok(PAREN_R, position, position + 1, line, col, prev);\n    // .\n    case 46:\n      if (charCodeAt.call(body, position + 1) === 46 && charCodeAt.call(body, position + 2) === 46) {\n        return new Tok(SPREAD, position, position + 3, line, col, prev);\n      }\n      break;\n    // :\n    case 58:\n      return new Tok(COLON, position, position + 1, line, col, prev);\n    // =\n    case 61:\n      return new Tok(EQUALS, position, position + 1, line, col, prev);\n    // @\n    case 64:\n      return new Tok(AT, position, position + 1, line, col, prev);\n    // [\n    case 91:\n      return new Tok(BRACKET_L, position, position + 1, line, col, prev);\n    // ]\n    case 93:\n      return new Tok(BRACKET_R, position, position + 1, line, col, prev);\n    // {\n    case 123:\n      return new Tok(BRACE_L, position, position + 1, line, col, prev);\n    // |\n    case 124:\n      return new Tok(PIPE, position, position + 1, line, col, prev);\n    // }\n    case 125:\n      return new Tok(BRACE_R, position, position + 1, line, col, prev);\n    // A-Z _ a-z\n    case 65:case 66:case 67:case 68:case 69:case 70:case 71:case 72:\n    case 73:case 74:case 75:case 76:case 77:case 78:case 79:case 80:\n    case 81:case 82:case 83:case 84:case 85:case 86:case 87:case 88:\n    case 89:case 90:\n    case 95:\n    case 97:case 98:case 99:case 100:case 101:case 102:case 103:case 104:\n    case 105:case 106:case 107:case 108:case 109:case 110:case 111:\n    case 112:case 113:case 114:case 115:case 116:case 117:case 118:\n    case 119:case 120:case 121:case 122:\n      return readName(source, position, line, col, prev);\n    // - 0-9\n    case 45:\n    case 48:case 49:case 50:case 51:case 52:\n    case 53:case 54:case 55:case 56:case 57:\n      return readNumber(source, position, code, line, col, prev);\n    // \"\n    case 34:\n      return readString(source, position, line, col, prev);\n  }\n\n  throw (0, _error.syntaxError)(source, position, unexpectedCharacterMessage(code));\n}\n\n/**\n * Report a message that an unexpected character was encountered.\n */\nfunction unexpectedCharacterMessage(code) {\n  if (code === 39) {\n    // '\n    return 'Unexpected single quote character (\\'), did you mean to use ' + 'a double quote (\")?';\n  }\n\n  return 'Cannot parse the unexpected character ' + printCharCode(code) + '.';\n}\n\n/**\n * Reads from body starting at startPosition until it finds a non-whitespace\n * or commented character, then returns the position of that character for\n * lexing.\n */\nfunction positionAfterWhitespace(body, startPosition, lexer) {\n  var bodyLength = body.length;\n  var position = startPosition;\n  while (position < bodyLength) {\n    var code = charCodeAt.call(body, position);\n    // tab | space | comma | BOM\n    if (code === 9 || code === 32 || code === 44 || code === 0xFEFF) {\n      ++position;\n    } else if (code === 10) {\n      // new line\n      ++position;\n      ++lexer.line;\n      lexer.lineStart = position;\n    } else if (code === 13) {\n      // carriage return\n      if (charCodeAt.call(body, position + 1) === 10) {\n        position += 2;\n      } else {\n        ++position;\n      }\n      ++lexer.line;\n      lexer.lineStart = position;\n    } else {\n      break;\n    }\n  }\n  return position;\n}\n\n/**\n * Reads a comment token from the source file.\n *\n * #[\\u0009\\u0020-\\uFFFF]*\n */\nfunction readComment(source, start, line, col, prev) {\n  var body = source.body;\n  var code = void 0;\n  var position = start;\n\n  do {\n    code = charCodeAt.call(body, ++position);\n  } while (code !== null && (\n  // SourceCharacter but not LineTerminator\n  code > 0x001F || code === 0x0009));\n\n  return new Tok(COMMENT, start, position, line, col, prev, slice.call(body, start + 1, position));\n}\n\n/**\n * Reads a number token from the source file, either a float\n * or an int depending on whether a decimal point appears.\n *\n * Int:   -?(0|[1-9][0-9]*)\n * Float: -?(0|[1-9][0-9]*)(\\.[0-9]+)?((E|e)(+|-)?[0-9]+)?\n */\nfunction readNumber(source, start, firstCode, line, col, prev) {\n  var body = source.body;\n  var code = firstCode;\n  var position = start;\n  var isFloat = false;\n\n  if (code === 45) {\n    // -\n    code = charCodeAt.call(body, ++position);\n  }\n\n  if (code === 48) {\n    // 0\n    code = charCodeAt.call(body, ++position);\n    if (code >= 48 && code <= 57) {\n      throw (0, _error.syntaxError)(source, position, 'Invalid number, unexpected digit after 0: ' + printCharCode(code) + '.');\n    }\n  } else {\n    position = readDigits(source, position, code);\n    code = charCodeAt.call(body, position);\n  }\n\n  if (code === 46) {\n    // .\n    isFloat = true;\n\n    code = charCodeAt.call(body, ++position);\n    position = readDigits(source, position, code);\n    code = charCodeAt.call(body, position);\n  }\n\n  if (code === 69 || code === 101) {\n    // E e\n    isFloat = true;\n\n    code = charCodeAt.call(body, ++position);\n    if (code === 43 || code === 45) {\n      // + -\n      code = charCodeAt.call(body, ++position);\n    }\n    position = readDigits(source, position, code);\n  }\n\n  return new Tok(isFloat ? FLOAT : INT, start, position, line, col, prev, slice.call(body, start, position));\n}\n\n/**\n * Returns the new position in the source after reading digits.\n */\nfunction readDigits(source, start, firstCode) {\n  var body = source.body;\n  var position = start;\n  var code = firstCode;\n  if (code >= 48 && code <= 57) {\n    // 0 - 9\n    do {\n      code = charCodeAt.call(body, ++position);\n    } while (code >= 48 && code <= 57); // 0 - 9\n    return position;\n  }\n  throw (0, _error.syntaxError)(source, position, 'Invalid number, expected digit but got: ' + printCharCode(code) + '.');\n}\n\n/**\n * Reads a string token from the source file.\n *\n * \"([^\"\\\\\\u000A\\u000D]|(\\\\(u[0-9a-fA-F]{4}|[\"\\\\/bfnrt])))*\"\n */\nfunction readString(source, start, line, col, prev) {\n  var body = source.body;\n  var position = start + 1;\n  var chunkStart = position;\n  var code = 0;\n  var value = '';\n\n  while (position < body.length && (code = charCodeAt.call(body, position)) !== null &&\n  // not LineTerminator\n  code !== 0x000A && code !== 0x000D &&\n  // not Quote (\")\n  code !== 34) {\n    // SourceCharacter\n    if (code < 0x0020 && code !== 0x0009) {\n      throw (0, _error.syntaxError)(source, position, 'Invalid character within String: ' + printCharCode(code) + '.');\n    }\n\n    ++position;\n    if (code === 92) {\n      // \\\n      value += slice.call(body, chunkStart, position - 1);\n      code = charCodeAt.call(body, position);\n      switch (code) {\n        case 34:\n          value += '\"';break;\n        case 47:\n          value += '/';break;\n        case 92:\n          value += '\\\\';break;\n        case 98:\n          value += '\\b';break;\n        case 102:\n          value += '\\f';break;\n        case 110:\n          value += '\\n';break;\n        case 114:\n          value += '\\r';break;\n        case 116:\n          value += '\\t';break;\n        case 117:\n          // u\n          var charCode = uniCharCode(charCodeAt.call(body, position + 1), charCodeAt.call(body, position + 2), charCodeAt.call(body, position + 3), charCodeAt.call(body, position + 4));\n          if (charCode < 0) {\n            throw (0, _error.syntaxError)(source, position, 'Invalid character escape sequence: ' + ('\\\\u' + body.slice(position + 1, position + 5) + '.'));\n          }\n          value += String.fromCharCode(charCode);\n          position += 4;\n          break;\n        default:\n          throw (0, _error.syntaxError)(source, position, 'Invalid character escape sequence: \\\\' + String.fromCharCode(code) + '.');\n      }\n      ++position;\n      chunkStart = position;\n    }\n  }\n\n  if (code !== 34) {\n    // quote (\")\n    throw (0, _error.syntaxError)(source, position, 'Unterminated string.');\n  }\n\n  value += slice.call(body, chunkStart, position);\n  return new Tok(STRING, start, position + 1, line, col, prev, value);\n}\n\n/**\n * Converts four hexidecimal chars to the integer that the\n * string represents. For example, uniCharCode('0','0','0','f')\n * will return 15, and uniCharCode('0','0','f','f') returns 255.\n *\n * Returns a negative number on error, if a char was invalid.\n *\n * This is implemented by noting that char2hex() returns -1 on error,\n * which means the result of ORing the char2hex() will also be negative.\n */\nfunction uniCharCode(a, b, c, d) {\n  return char2hex(a) << 12 | char2hex(b) << 8 | char2hex(c) << 4 | char2hex(d);\n}\n\n/**\n * Converts a hex character to its integer value.\n * '0' becomes 0, '9' becomes 9\n * 'A' becomes 10, 'F' becomes 15\n * 'a' becomes 10, 'f' becomes 15\n *\n * Returns -1 on error.\n */\nfunction char2hex(a) {\n  return a >= 48 && a <= 57 ? a - 48 : // 0-9\n  a >= 65 && a <= 70 ? a - 55 : // A-F\n  a >= 97 && a <= 102 ? a - 87 : // a-f\n  -1;\n}\n\n/**\n * Reads an alphanumeric + underscore name from the source.\n *\n * [_A-Za-z][_0-9A-Za-z]*\n */\nfunction readName(source, position, line, col, prev) {\n  var body = source.body;\n  var bodyLength = body.length;\n  var end = position + 1;\n  var code = 0;\n  while (end !== bodyLength && (code = charCodeAt.call(body, end)) !== null && (code === 95 || // _\n  code >= 48 && code <= 57 || // 0-9\n  code >= 65 && code <= 90 || // A-Z\n  code >= 97 && code <= 122 // a-z\n  )) {\n    ++end;\n  }\n  return new Tok(NAME, position, end, line, col, prev, slice.call(body, position, end));\n}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/language/lexer.js\n// module id = ./node_modules/graphql/language/lexer.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.getLocation = getLocation;\n\n\n/**\n * Takes a Source and a UTF-8 character offset, and returns the corresponding\n * line and column as a SourceLocation.\n */\n\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\nfunction getLocation(source, position) {\n  var lineRegexp = /\\r\\n|[\\n\\r]/g;\n  var line = 1;\n  var column = position + 1;\n  var match = void 0;\n  while ((match = lineRegexp.exec(source.body)) && match.index < position) {\n    line += 1;\n    column = position + 1 - (match.index + match[0].length);\n  }\n  return { line: line, column: column };\n}\n\n/**\n * Represents a location in a Source.\n */\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/language/location.js\n// module id = ./node_modules/graphql/language/location.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.parse = parse;\nexports.parseValue = parseValue;\nexports.parseType = parseType;\nexports.parseConstValue = parseConstValue;\nexports.parseTypeReference = parseTypeReference;\nexports.parseNamedType = parseNamedType;\n\nvar _source = require('./source');\n\nvar _error = require('../error');\n\nvar _lexer = require('./lexer');\n\nvar _kinds = require('./kinds');\n\n/**\n * Given a GraphQL source, parses it into a Document.\n * Throws GraphQLError if a syntax error is encountered.\n */\n\n\n/**\n * Configuration options to control parser behavior\n */\n\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\nfunction parse(source, options) {\n  var sourceObj = typeof source === 'string' ? new _source.Source(source) : source;\n  if (!(sourceObj instanceof _source.Source)) {\n    throw new TypeError('Must provide Source. Received: ' + String(sourceObj));\n  }\n  var lexer = (0, _lexer.createLexer)(sourceObj, options || {});\n  return parseDocument(lexer);\n}\n\n/**\n * Given a string containing a GraphQL value (ex. `[42]`), parse the AST for\n * that value.\n * Throws GraphQLError if a syntax error is encountered.\n *\n * This is useful within tools that operate upon GraphQL Values directly and\n * in isolation of complete GraphQL documents.\n *\n * Consider providing the results to the utility function: valueFromAST().\n */\nfunction parseValue(source, options) {\n  var sourceObj = typeof source === 'string' ? new _source.Source(source) : source;\n  var lexer = (0, _lexer.createLexer)(sourceObj, options || {});\n  expect(lexer, _lexer.TokenKind.SOF);\n  var value = parseValueLiteral(lexer, false);\n  expect(lexer, _lexer.TokenKind.EOF);\n  return value;\n}\n\n/**\n * Given a string containing a GraphQL Type (ex. `[Int!]`), parse the AST for\n * that type.\n * Throws GraphQLError if a syntax error is encountered.\n *\n * This is useful within tools that operate upon GraphQL Types directly and\n * in isolation of complete GraphQL documents.\n *\n * Consider providing the results to the utility function: typeFromAST().\n */\nfunction parseType(source, options) {\n  var sourceObj = typeof source === 'string' ? new _source.Source(source) : source;\n  var lexer = (0, _lexer.createLexer)(sourceObj, options || {});\n  expect(lexer, _lexer.TokenKind.SOF);\n  var type = parseTypeReference(lexer);\n  expect(lexer, _lexer.TokenKind.EOF);\n  return type;\n}\n\n/**\n * Converts a name lex token into a name parse node.\n */\nfunction parseName(lexer) {\n  var token = expect(lexer, _lexer.TokenKind.NAME);\n  return {\n    kind: _kinds.NAME,\n    value: token.value,\n    loc: loc(lexer, token)\n  };\n}\n\n// Implements the parsing rules in the Document section.\n\n/**\n * Document : Definition+\n */\nfunction parseDocument(lexer) {\n  var start = lexer.token;\n  expect(lexer, _lexer.TokenKind.SOF);\n  var definitions = [];\n  do {\n    definitions.push(parseDefinition(lexer));\n  } while (!skip(lexer, _lexer.TokenKind.EOF));\n\n  return {\n    kind: _kinds.DOCUMENT,\n    definitions: definitions,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * Definition :\n *   - OperationDefinition\n *   - FragmentDefinition\n *   - TypeSystemDefinition\n */\nfunction parseDefinition(lexer) {\n  if (peek(lexer, _lexer.TokenKind.BRACE_L)) {\n    return parseOperationDefinition(lexer);\n  }\n\n  if (peek(lexer, _lexer.TokenKind.NAME)) {\n    switch (lexer.token.value) {\n      // Note: subscription is an experimental non-spec addition.\n      case 'query':\n      case 'mutation':\n      case 'subscription':\n        return parseOperationDefinition(lexer);\n\n      case 'fragment':\n        return parseFragmentDefinition(lexer);\n\n      // Note: the Type System IDL is an experimental non-spec addition.\n      case 'schema':\n      case 'scalar':\n      case 'type':\n      case 'interface':\n      case 'union':\n      case 'enum':\n      case 'input':\n      case 'extend':\n      case 'directive':\n        return parseTypeSystemDefinition(lexer);\n    }\n  }\n\n  throw unexpected(lexer);\n}\n\n// Implements the parsing rules in the Operations section.\n\n/**\n * OperationDefinition :\n *  - SelectionSet\n *  - OperationType Name? VariableDefinitions? Directives? SelectionSet\n */\nfunction parseOperationDefinition(lexer) {\n  var start = lexer.token;\n  if (peek(lexer, _lexer.TokenKind.BRACE_L)) {\n    return {\n      kind: _kinds.OPERATION_DEFINITION,\n      operation: 'query',\n      name: null,\n      variableDefinitions: null,\n      directives: [],\n      selectionSet: parseSelectionSet(lexer),\n      loc: loc(lexer, start)\n    };\n  }\n  var operation = parseOperationType(lexer);\n  var name = void 0;\n  if (peek(lexer, _lexer.TokenKind.NAME)) {\n    name = parseName(lexer);\n  }\n  return {\n    kind: _kinds.OPERATION_DEFINITION,\n    operation: operation,\n    name: name,\n    variableDefinitions: parseVariableDefinitions(lexer),\n    directives: parseDirectives(lexer),\n    selectionSet: parseSelectionSet(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * OperationType : one of query mutation subscription\n */\nfunction parseOperationType(lexer) {\n  var operationToken = expect(lexer, _lexer.TokenKind.NAME);\n  switch (operationToken.value) {\n    case 'query':\n      return 'query';\n    case 'mutation':\n      return 'mutation';\n    // Note: subscription is an experimental non-spec addition.\n    case 'subscription':\n      return 'subscription';\n  }\n\n  throw unexpected(lexer, operationToken);\n}\n\n/**\n * VariableDefinitions : ( VariableDefinition+ )\n */\nfunction parseVariableDefinitions(lexer) {\n  return peek(lexer, _lexer.TokenKind.PAREN_L) ? many(lexer, _lexer.TokenKind.PAREN_L, parseVariableDefinition, _lexer.TokenKind.PAREN_R) : [];\n}\n\n/**\n * VariableDefinition : Variable : Type DefaultValue?\n */\nfunction parseVariableDefinition(lexer) {\n  var start = lexer.token;\n  return {\n    kind: _kinds.VARIABLE_DEFINITION,\n    variable: parseVariable(lexer),\n    type: (expect(lexer, _lexer.TokenKind.COLON), parseTypeReference(lexer)),\n    defaultValue: skip(lexer, _lexer.TokenKind.EQUALS) ? parseValueLiteral(lexer, true) : null,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * Variable : $ Name\n */\nfunction parseVariable(lexer) {\n  var start = lexer.token;\n  expect(lexer, _lexer.TokenKind.DOLLAR);\n  return {\n    kind: _kinds.VARIABLE,\n    name: parseName(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * SelectionSet : { Selection+ }\n */\nfunction parseSelectionSet(lexer) {\n  var start = lexer.token;\n  return {\n    kind: _kinds.SELECTION_SET,\n    selections: many(lexer, _lexer.TokenKind.BRACE_L, parseSelection, _lexer.TokenKind.BRACE_R),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * Selection :\n *   - Field\n *   - FragmentSpread\n *   - InlineFragment\n */\nfunction parseSelection(lexer) {\n  return peek(lexer, _lexer.TokenKind.SPREAD) ? parseFragment(lexer) : parseField(lexer);\n}\n\n/**\n * Field : Alias? Name Arguments? Directives? SelectionSet?\n *\n * Alias : Name :\n */\nfunction parseField(lexer) {\n  var start = lexer.token;\n\n  var nameOrAlias = parseName(lexer);\n  var alias = void 0;\n  var name = void 0;\n  if (skip(lexer, _lexer.TokenKind.COLON)) {\n    alias = nameOrAlias;\n    name = parseName(lexer);\n  } else {\n    alias = null;\n    name = nameOrAlias;\n  }\n\n  return {\n    kind: _kinds.FIELD,\n    alias: alias,\n    name: name,\n    arguments: parseArguments(lexer),\n    directives: parseDirectives(lexer),\n    selectionSet: peek(lexer, _lexer.TokenKind.BRACE_L) ? parseSelectionSet(lexer) : null,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * Arguments : ( Argument+ )\n */\nfunction parseArguments(lexer) {\n  return peek(lexer, _lexer.TokenKind.PAREN_L) ? many(lexer, _lexer.TokenKind.PAREN_L, parseArgument, _lexer.TokenKind.PAREN_R) : [];\n}\n\n/**\n * Argument : Name : Value\n */\nfunction parseArgument(lexer) {\n  var start = lexer.token;\n  return {\n    kind: _kinds.ARGUMENT,\n    name: parseName(lexer),\n    value: (expect(lexer, _lexer.TokenKind.COLON), parseValueLiteral(lexer, false)),\n    loc: loc(lexer, start)\n  };\n}\n\n// Implements the parsing rules in the Fragments section.\n\n/**\n * Corresponds to both FragmentSpread and InlineFragment in the spec.\n *\n * FragmentSpread : ... FragmentName Directives?\n *\n * InlineFragment : ... TypeCondition? Directives? SelectionSet\n */\nfunction parseFragment(lexer) {\n  var start = lexer.token;\n  expect(lexer, _lexer.TokenKind.SPREAD);\n  if (peek(lexer, _lexer.TokenKind.NAME) && lexer.token.value !== 'on') {\n    return {\n      kind: _kinds.FRAGMENT_SPREAD,\n      name: parseFragmentName(lexer),\n      directives: parseDirectives(lexer),\n      loc: loc(lexer, start)\n    };\n  }\n  var typeCondition = null;\n  if (lexer.token.value === 'on') {\n    lexer.advance();\n    typeCondition = parseNamedType(lexer);\n  }\n  return {\n    kind: _kinds.INLINE_FRAGMENT,\n    typeCondition: typeCondition,\n    directives: parseDirectives(lexer),\n    selectionSet: parseSelectionSet(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * FragmentDefinition :\n *   - fragment FragmentName on TypeCondition Directives? SelectionSet\n *\n * TypeCondition : NamedType\n */\nfunction parseFragmentDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'fragment');\n  return {\n    kind: _kinds.FRAGMENT_DEFINITION,\n    name: parseFragmentName(lexer),\n    typeCondition: (expectKeyword(lexer, 'on'), parseNamedType(lexer)),\n    directives: parseDirectives(lexer),\n    selectionSet: parseSelectionSet(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * FragmentName : Name but not `on`\n */\nfunction parseFragmentName(lexer) {\n  if (lexer.token.value === 'on') {\n    throw unexpected(lexer);\n  }\n  return parseName(lexer);\n}\n\n// Implements the parsing rules in the Values section.\n\n/**\n * Value[Const] :\n *   - [~Const] Variable\n *   - IntValue\n *   - FloatValue\n *   - StringValue\n *   - BooleanValue\n *   - NullValue\n *   - EnumValue\n *   - ListValue[?Const]\n *   - ObjectValue[?Const]\n *\n * BooleanValue : one of `true` `false`\n *\n * NullValue : `null`\n *\n * EnumValue : Name but not `true`, `false` or `null`\n */\nfunction parseValueLiteral(lexer, isConst) {\n  var token = lexer.token;\n  switch (token.kind) {\n    case _lexer.TokenKind.BRACKET_L:\n      return parseList(lexer, isConst);\n    case _lexer.TokenKind.BRACE_L:\n      return parseObject(lexer, isConst);\n    case _lexer.TokenKind.INT:\n      lexer.advance();\n      return {\n        kind: _kinds.INT,\n        value: token.value,\n        loc: loc(lexer, token)\n      };\n    case _lexer.TokenKind.FLOAT:\n      lexer.advance();\n      return {\n        kind: _kinds.FLOAT,\n        value: token.value,\n        loc: loc(lexer, token)\n      };\n    case _lexer.TokenKind.STRING:\n      lexer.advance();\n      return {\n        kind: _kinds.STRING,\n        value: token.value,\n        loc: loc(lexer, token)\n      };\n    case _lexer.TokenKind.NAME:\n      if (token.value === 'true' || token.value === 'false') {\n        lexer.advance();\n        return {\n          kind: _kinds.BOOLEAN,\n          value: token.value === 'true',\n          loc: loc(lexer, token)\n        };\n      } else if (token.value === 'null') {\n        lexer.advance();\n        return {\n          kind: _kinds.NULL,\n          loc: loc(lexer, token)\n        };\n      }\n      lexer.advance();\n      return {\n        kind: _kinds.ENUM,\n        value: token.value,\n        loc: loc(lexer, token)\n      };\n    case _lexer.TokenKind.DOLLAR:\n      if (!isConst) {\n        return parseVariable(lexer);\n      }\n      break;\n  }\n  throw unexpected(lexer);\n}\n\nfunction parseConstValue(lexer) {\n  return parseValueLiteral(lexer, true);\n}\n\nfunction parseValueValue(lexer) {\n  return parseValueLiteral(lexer, false);\n}\n\n/**\n * ListValue[Const] :\n *   - [ ]\n *   - [ Value[?Const]+ ]\n */\nfunction parseList(lexer, isConst) {\n  var start = lexer.token;\n  var item = isConst ? parseConstValue : parseValueValue;\n  return {\n    kind: _kinds.LIST,\n    values: any(lexer, _lexer.TokenKind.BRACKET_L, item, _lexer.TokenKind.BRACKET_R),\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ObjectValue[Const] :\n *   - { }\n *   - { ObjectField[?Const]+ }\n */\nfunction parseObject(lexer, isConst) {\n  var start = lexer.token;\n  expect(lexer, _lexer.TokenKind.BRACE_L);\n  var fields = [];\n  while (!skip(lexer, _lexer.TokenKind.BRACE_R)) {\n    fields.push(parseObjectField(lexer, isConst));\n  }\n  return {\n    kind: _kinds.OBJECT,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ObjectField[Const] : Name : Value[?Const]\n */\nfunction parseObjectField(lexer, isConst) {\n  var start = lexer.token;\n  return {\n    kind: _kinds.OBJECT_FIELD,\n    name: parseName(lexer),\n    value: (expect(lexer, _lexer.TokenKind.COLON), parseValueLiteral(lexer, isConst)),\n    loc: loc(lexer, start)\n  };\n}\n\n// Implements the parsing rules in the Directives section.\n\n/**\n * Directives : Directive+\n */\nfunction parseDirectives(lexer) {\n  var directives = [];\n  while (peek(lexer, _lexer.TokenKind.AT)) {\n    directives.push(parseDirective(lexer));\n  }\n  return directives;\n}\n\n/**\n * Directive : @ Name Arguments?\n */\nfunction parseDirective(lexer) {\n  var start = lexer.token;\n  expect(lexer, _lexer.TokenKind.AT);\n  return {\n    kind: _kinds.DIRECTIVE,\n    name: parseName(lexer),\n    arguments: parseArguments(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n// Implements the parsing rules in the Types section.\n\n/**\n * Type :\n *   - NamedType\n *   - ListType\n *   - NonNullType\n */\nfunction parseTypeReference(lexer) {\n  var start = lexer.token;\n  var type = void 0;\n  if (skip(lexer, _lexer.TokenKind.BRACKET_L)) {\n    type = parseTypeReference(lexer);\n    expect(lexer, _lexer.TokenKind.BRACKET_R);\n    type = {\n      kind: _kinds.LIST_TYPE,\n      type: type,\n      loc: loc(lexer, start)\n    };\n  } else {\n    type = parseNamedType(lexer);\n  }\n  if (skip(lexer, _lexer.TokenKind.BANG)) {\n    return {\n      kind: _kinds.NON_NULL_TYPE,\n      type: type,\n      loc: loc(lexer, start)\n    };\n  }\n  return type;\n}\n\n/**\n * NamedType : Name\n */\nfunction parseNamedType(lexer) {\n  var start = lexer.token;\n  return {\n    kind: _kinds.NAMED_TYPE,\n    name: parseName(lexer),\n    loc: loc(lexer, start)\n  };\n}\n\n// Implements the parsing rules in the Type Definition section.\n\n/**\n * TypeSystemDefinition :\n *   - SchemaDefinition\n *   - TypeDefinition\n *   - TypeExtensionDefinition\n *   - DirectiveDefinition\n *\n * TypeDefinition :\n *   - ScalarTypeDefinition\n *   - ObjectTypeDefinition\n *   - InterfaceTypeDefinition\n *   - UnionTypeDefinition\n *   - EnumTypeDefinition\n *   - InputObjectTypeDefinition\n */\nfunction parseTypeSystemDefinition(lexer) {\n  if (peek(lexer, _lexer.TokenKind.NAME)) {\n    switch (lexer.token.value) {\n      case 'schema':\n        return parseSchemaDefinition(lexer);\n      case 'scalar':\n        return parseScalarTypeDefinition(lexer);\n      case 'type':\n        return parseObjectTypeDefinition(lexer);\n      case 'interface':\n        return parseInterfaceTypeDefinition(lexer);\n      case 'union':\n        return parseUnionTypeDefinition(lexer);\n      case 'enum':\n        return parseEnumTypeDefinition(lexer);\n      case 'input':\n        return parseInputObjectTypeDefinition(lexer);\n      case 'extend':\n        return parseTypeExtensionDefinition(lexer);\n      case 'directive':\n        return parseDirectiveDefinition(lexer);\n    }\n  }\n\n  throw unexpected(lexer);\n}\n\n/**\n * SchemaDefinition : schema Directives? { OperationTypeDefinition+ }\n *\n * OperationTypeDefinition : OperationType : NamedType\n */\nfunction parseSchemaDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'schema');\n  var directives = parseDirectives(lexer);\n  var operationTypes = many(lexer, _lexer.TokenKind.BRACE_L, parseOperationTypeDefinition, _lexer.TokenKind.BRACE_R);\n  return {\n    kind: _kinds.SCHEMA_DEFINITION,\n    directives: directives,\n    operationTypes: operationTypes,\n    loc: loc(lexer, start)\n  };\n}\n\nfunction parseOperationTypeDefinition(lexer) {\n  var start = lexer.token;\n  var operation = parseOperationType(lexer);\n  expect(lexer, _lexer.TokenKind.COLON);\n  var type = parseNamedType(lexer);\n  return {\n    kind: _kinds.OPERATION_TYPE_DEFINITION,\n    operation: operation,\n    type: type,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ScalarTypeDefinition : scalar Name Directives?\n */\nfunction parseScalarTypeDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'scalar');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer);\n  return {\n    kind: _kinds.SCALAR_TYPE_DEFINITION,\n    name: name,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ObjectTypeDefinition :\n *   - type Name ImplementsInterfaces? Directives? { FieldDefinition+ }\n */\nfunction parseObjectTypeDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'type');\n  var name = parseName(lexer);\n  var interfaces = parseImplementsInterfaces(lexer);\n  var directives = parseDirectives(lexer);\n  var fields = any(lexer, _lexer.TokenKind.BRACE_L, parseFieldDefinition, _lexer.TokenKind.BRACE_R);\n  return {\n    kind: _kinds.OBJECT_TYPE_DEFINITION,\n    name: name,\n    interfaces: interfaces,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ImplementsInterfaces : implements NamedType+\n */\nfunction parseImplementsInterfaces(lexer) {\n  var types = [];\n  if (lexer.token.value === 'implements') {\n    lexer.advance();\n    do {\n      types.push(parseNamedType(lexer));\n    } while (peek(lexer, _lexer.TokenKind.NAME));\n  }\n  return types;\n}\n\n/**\n * FieldDefinition : Name ArgumentsDefinition? : Type Directives?\n */\nfunction parseFieldDefinition(lexer) {\n  var start = lexer.token;\n  var name = parseName(lexer);\n  var args = parseArgumentDefs(lexer);\n  expect(lexer, _lexer.TokenKind.COLON);\n  var type = parseTypeReference(lexer);\n  var directives = parseDirectives(lexer);\n  return {\n    kind: _kinds.FIELD_DEFINITION,\n    name: name,\n    arguments: args,\n    type: type,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * ArgumentsDefinition : ( InputValueDefinition+ )\n */\nfunction parseArgumentDefs(lexer) {\n  if (!peek(lexer, _lexer.TokenKind.PAREN_L)) {\n    return [];\n  }\n  return many(lexer, _lexer.TokenKind.PAREN_L, parseInputValueDef, _lexer.TokenKind.PAREN_R);\n}\n\n/**\n * InputValueDefinition : Name : Type DefaultValue? Directives?\n */\nfunction parseInputValueDef(lexer) {\n  var start = lexer.token;\n  var name = parseName(lexer);\n  expect(lexer, _lexer.TokenKind.COLON);\n  var type = parseTypeReference(lexer);\n  var defaultValue = null;\n  if (skip(lexer, _lexer.TokenKind.EQUALS)) {\n    defaultValue = parseConstValue(lexer);\n  }\n  var directives = parseDirectives(lexer);\n  return {\n    kind: _kinds.INPUT_VALUE_DEFINITION,\n    name: name,\n    type: type,\n    defaultValue: defaultValue,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * InterfaceTypeDefinition : interface Name Directives? { FieldDefinition+ }\n */\nfunction parseInterfaceTypeDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'interface');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer);\n  var fields = any(lexer, _lexer.TokenKind.BRACE_L, parseFieldDefinition, _lexer.TokenKind.BRACE_R);\n  return {\n    kind: _kinds.INTERFACE_TYPE_DEFINITION,\n    name: name,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * UnionTypeDefinition : union Name Directives? = UnionMembers\n */\nfunction parseUnionTypeDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'union');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer);\n  expect(lexer, _lexer.TokenKind.EQUALS);\n  var types = parseUnionMembers(lexer);\n  return {\n    kind: _kinds.UNION_TYPE_DEFINITION,\n    name: name,\n    directives: directives,\n    types: types,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * UnionMembers :\n *   - `|`? NamedType\n *   - UnionMembers | NamedType\n */\nfunction parseUnionMembers(lexer) {\n  // Optional leading pipe\n  skip(lexer, _lexer.TokenKind.PIPE);\n  var members = [];\n  do {\n    members.push(parseNamedType(lexer));\n  } while (skip(lexer, _lexer.TokenKind.PIPE));\n  return members;\n}\n\n/**\n * EnumTypeDefinition : enum Name Directives? { EnumValueDefinition+ }\n */\nfunction parseEnumTypeDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'enum');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer);\n  var values = many(lexer, _lexer.TokenKind.BRACE_L, parseEnumValueDefinition, _lexer.TokenKind.BRACE_R);\n  return {\n    kind: _kinds.ENUM_TYPE_DEFINITION,\n    name: name,\n    directives: directives,\n    values: values,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * EnumValueDefinition : EnumValue Directives?\n *\n * EnumValue : Name\n */\nfunction parseEnumValueDefinition(lexer) {\n  var start = lexer.token;\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer);\n  return {\n    kind: _kinds.ENUM_VALUE_DEFINITION,\n    name: name,\n    directives: directives,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * InputObjectTypeDefinition : input Name Directives? { InputValueDefinition+ }\n */\nfunction parseInputObjectTypeDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'input');\n  var name = parseName(lexer);\n  var directives = parseDirectives(lexer);\n  var fields = any(lexer, _lexer.TokenKind.BRACE_L, parseInputValueDef, _lexer.TokenKind.BRACE_R);\n  return {\n    kind: _kinds.INPUT_OBJECT_TYPE_DEFINITION,\n    name: name,\n    directives: directives,\n    fields: fields,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * TypeExtensionDefinition : extend ObjectTypeDefinition\n */\nfunction parseTypeExtensionDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'extend');\n  var definition = parseObjectTypeDefinition(lexer);\n  return {\n    kind: _kinds.TYPE_EXTENSION_DEFINITION,\n    definition: definition,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * DirectiveDefinition :\n *   - directive @ Name ArgumentsDefinition? on DirectiveLocations\n */\nfunction parseDirectiveDefinition(lexer) {\n  var start = lexer.token;\n  expectKeyword(lexer, 'directive');\n  expect(lexer, _lexer.TokenKind.AT);\n  var name = parseName(lexer);\n  var args = parseArgumentDefs(lexer);\n  expectKeyword(lexer, 'on');\n  var locations = parseDirectiveLocations(lexer);\n  return {\n    kind: _kinds.DIRECTIVE_DEFINITION,\n    name: name,\n    arguments: args,\n    locations: locations,\n    loc: loc(lexer, start)\n  };\n}\n\n/**\n * DirectiveLocations :\n *   - `|`? Name\n *   - DirectiveLocations | Name\n */\nfunction parseDirectiveLocations(lexer) {\n  // Optional leading pipe\n  skip(lexer, _lexer.TokenKind.PIPE);\n  var locations = [];\n  do {\n    locations.push(parseName(lexer));\n  } while (skip(lexer, _lexer.TokenKind.PIPE));\n  return locations;\n}\n\n// Core parsing utility functions\n\n/**\n * Returns a location object, used to identify the place in\n * the source that created a given parsed object.\n */\nfunction loc(lexer, startToken) {\n  if (!lexer.options.noLocation) {\n    return new Loc(startToken, lexer.lastToken, lexer.source);\n  }\n}\n\nfunction Loc(startToken, endToken, source) {\n  this.start = startToken.start;\n  this.end = endToken.end;\n  this.startToken = startToken;\n  this.endToken = endToken;\n  this.source = source;\n}\n\n// Print a simplified form when appearing in JSON/util.inspect.\nLoc.prototype.toJSON = Loc.prototype.inspect = function toJSON() {\n  return { start: this.start, end: this.end };\n};\n\n/**\n * Determines if the next token is of a given kind\n */\nfunction peek(lexer, kind) {\n  return lexer.token.kind === kind;\n}\n\n/**\n * If the next token is of the given kind, return true after advancing\n * the lexer. Otherwise, do not change the parser state and return false.\n */\nfunction skip(lexer, kind) {\n  var match = lexer.token.kind === kind;\n  if (match) {\n    lexer.advance();\n  }\n  return match;\n}\n\n/**\n * If the next token is of the given kind, return that token after advancing\n * the lexer. Otherwise, do not change the parser state and throw an error.\n */\nfunction expect(lexer, kind) {\n  var token = lexer.token;\n  if (token.kind === kind) {\n    lexer.advance();\n    return token;\n  }\n  throw (0, _error.syntaxError)(lexer.source, token.start, 'Expected ' + kind + ', found ' + (0, _lexer.getTokenDesc)(token));\n}\n\n/**\n * If the next token is a keyword with the given value, return that token after\n * advancing the lexer. Otherwise, do not change the parser state and return\n * false.\n */\nfunction expectKeyword(lexer, value) {\n  var token = lexer.token;\n  if (token.kind === _lexer.TokenKind.NAME && token.value === value) {\n    lexer.advance();\n    return token;\n  }\n  throw (0, _error.syntaxError)(lexer.source, token.start, 'Expected \"' + value + '\", found ' + (0, _lexer.getTokenDesc)(token));\n}\n\n/**\n * Helper function for creating an error when an unexpected lexed token\n * is encountered.\n */\nfunction unexpected(lexer, atToken) {\n  var token = atToken || lexer.token;\n  return (0, _error.syntaxError)(lexer.source, token.start, 'Unexpected ' + (0, _lexer.getTokenDesc)(token));\n}\n\n/**\n * Returns a possibly empty list of parse nodes, determined by\n * the parseFn. This list begins with a lex token of openKind\n * and ends with a lex token of closeKind. Advances the parser\n * to the next lex token after the closing token.\n */\nfunction any(lexer, openKind, parseFn, closeKind) {\n  expect(lexer, openKind);\n  var nodes = [];\n  while (!skip(lexer, closeKind)) {\n    nodes.push(parseFn(lexer));\n  }\n  return nodes;\n}\n\n/**\n * Returns a non-empty list of parse nodes, determined by\n * the parseFn. This list begins with a lex token of openKind\n * and ends with a lex token of closeKind. Advances the parser\n * to the next lex token after the closing token.\n */\nfunction many(lexer, openKind, parseFn, closeKind) {\n  expect(lexer, openKind);\n  var nodes = [parseFn(lexer)];\n  while (!skip(lexer, closeKind)) {\n    nodes.push(parseFn(lexer));\n  }\n  return nodes;\n}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/language/parser.js\n// module id = ./node_modules/graphql/language/parser.js\n// module chunks = 4016850265702045000 6379530823973858000","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Source = undefined;\n\nvar _invariant = require('../jsutils/invariant');\n\nvar _invariant2 = _interopRequireDefault(_invariant);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n/**\n *  Copyright (c) 2015, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n */\n\n/**\n * A representation of source input to GraphQL.\n * `name` and `locationOffset` are optional. They are useful for clients who\n * store GraphQL documents in source files; for example, if the GraphQL input\n * starts at line 40 in a file named Foo.graphql, it might be useful for name to\n * be \"Foo.graphql\" and location to be `{ line: 40, column: 0 }`.\n * line and column in locationOffset are 1-indexed\n */\nvar Source = exports.Source = function Source(body, name, locationOffset) {\n  _classCallCheck(this, Source);\n\n  this.body = body;\n  this.name = name || 'GraphQL request';\n  this.locationOffset = locationOffset || { line: 1, column: 1 };\n  !(this.locationOffset.line > 0) ? (0, _invariant2.default)(0, 'line in locationOffset is 1-indexed and must be positive') : void 0;\n  !(this.locationOffset.column > 0) ? (0, _invariant2.default)(0, 'column in locationOffset is 1-indexed and must be positive') : void 0;\n};\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/graphql/language/source.js\n// module id = ./node_modules/graphql/language/source.js\n// module chunks = 4016850265702045000 6379530823973858000","import React from 'react';\nimport PropTypes from 'prop-types';\nimport cn from 'classnames';\n\nconst Header = ({ title, byline }) => (\n  <div className=\"header\">\n    <h1 className={cn(\n      'header__title',\n      { 'header__title--with-byline': byline.length })}\n    >\n      {title}\n    </h1>\n    {\n      byline.length && (\n        <p className=\"header__byline\">\n          {byline}\n        </p>\n      )\n    }\n  </div>\n);\n\nHeader.propTypes = {\n  title: PropTypes.string.isRequired,\n  byline: PropTypes.string,\n};\n\nHeader.defaultProps = {\n  byline: '',\n};\n\nexport default Header;\n\n\n\n// WEBPACK FOOTER //\n// ./src/components/Header.js","import React from 'react';\nimport graphql from 'graphql-tag';\nimport PropTypes from 'prop-types';\n\nimport Header from '../components/Header';\n\nconst Index = ({ data }) => (\n  <div className=\"content\">\n    <Header\n      title={data.site.siteMetadata.title}\n      byline={data.site.siteMetadata.description}\n    />\n    <h2>Upcoming Battles</h2>\n    <a href=\"/fl/gnv/discover-gainesville\">Gainesville, FL - August 26, 2017</a>\n    <h2>More Information</h2>\n    <p>\n      Want to host a HackBattle in your area?<br />\n      Visit the <a href=\"https://github.com/HackBattles/hackbattl.es\">HackBattles Github repo</a> for information.\n    </p>\n  </div>\n);\n\nIndex.propTypes = {\n  data: PropTypes.shape({\n    site: PropTypes.shape({\n      siteMetadata: PropTypes.shape({\n        title: PropTypes.string,\n        description: PropTypes.string,\n      }),\n    }),\n  }),\n};\n\nIndex.defaultProps = {\n  data: {\n    site: {\n      siteMetadata: {\n        title: '',\n        description: '',\n      },\n    },\n  },\n};\n\nexport default Index;\n\nexport const pageQuery = graphql`\n    query IndexQuery {\n        site {\n            siteMetadata {\n                title\n                description\n            }\n        }\n    }\n`;\n\n\n\n\n// WEBPACK FOOTER //\n// ./src/pages/index.js"],"sourceRoot":""}